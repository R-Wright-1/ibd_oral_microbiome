---
title: Atlantic PATH IBD analysis 2024 (after frailty)
output:
  html_document:
    toc: yes
    toc_float: yes
    code_folding: hide
  pdf_document:
    toc: yes
---

```{R, results='hide', fig.keep='all', message=FALSE}
library(reticulate)
#library(tidyverse)
#library(kableExtra)
library(knitr)
library(phyloseq)
library(philr)
library(ape)
library(vegan)
library(Maaslin2)
library(ANCOMBC)
library(ALDEx2)
#conda_python(envname = 'r-reticulate', conda = "auto")
#use_python('/opt/miniconda3/envs/update-Jul24-x64/bin/python')

library(reticulate)
#use_python('/Users/robynwright/anaconda3/envs/r-environment/bin/python')
py_require("pandas")
py_require("matplotlib")
py_require("scipy")
py_require("numpy")
py_require("scikit-learn")
py_require("statsmodels")
py_require("scikit-bio")
py_require("Biopython")
py_require("ete3")
py_require("openpyxl")
py_require("deicode")
```

```{python, results='hide', fig.keep='all', message=FALSE}
import matplotlib
import pandas as pd
import math
import matplotlib.pyplot as plt
import os
from matplotlib.patches import Ellipse
import matplotlib.transforms as transforms
from scipy.stats import mannwhitneyu
import matplotlib as mpl
import matplotlib.cm as cm
from matplotlib.lines import Line2D
from matplotlib.offsetbox import AnchoredText
from skbio.diversity import get_alpha_diversity_metrics, get_beta_diversity_metrics, alpha_diversity, beta_diversity
from skbio import read
import skbio
from skbio.tree import TreeNode
import numpy as np
from scipy.stats import ttest_ind
from deicode.preprocessing import rclr
from skbio.stats.composition import clr
from scipy.spatial import distance
from scipy import stats
from skbio.stats import ordination
from sklearn import preprocessing
# from sklearn.metrics import plot_roc_curve
# from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
# from sklearn.model_selection import train_test_split
# from sklearn.metrics import roc_auc_score
# from sklearn.metrics import confusion_matrix
import statsmodels.api as sm
from statsmodels.formula.api import ols
import random
import pickle

folder = '/Users/robynwright/Dropbox/Langille_Lab_postdoc/AtPATH_IBD/'
analysis_folder = folder+'analysis_2024/'
tree_fn = folder+'exports/tree.nwk'
previous_metadata_fn = folder+'metadata/metadata_final_jul22.csv'
metadata_fn = analysis_folder+'files/metadata.csv'
asv_table_fn = analysis_folder+'files/ft.csv'
asv_processed = analysis_folder+'files/asv_table_processed_prev.csv'
species_processed = analysis_folder+'files/species_table_processed_prev.csv'
genus_processed = analysis_folder+'files/genus_table_processed_prev.csv'
color_dict = {'IBD Cases':'#78281F', 'IBD Controls':'#2471A3', 'IBD Crohns':'#F1948A', 'IBD UC':'#CB4335', 'IBD Both':'#78281F'}
color_dict = {'IBD Cases':'#C28BA2', 'IBD Controls':'#FCD1AE', 'IBD Crohns':'#E67E22', 'IBD UC':'#8E44AD', 'IBD Both':'#FCDA02'}
color_dict_pcoa = {0:color_dict['IBD Controls'], 1:color_dict['IBD Cases'], 'crohns':color_dict['IBD Crohns'], 'UC':color_dict['IBD UC'], 'both':color_dict['IBD Both']}
shape_dict = {'IBD Cases':'v', 'IBD Controls':'o', 'IBD Crohns':'s', 'IBD UC':'D', 'IBD Both':'>'}
```

```{python}
def confidence_ellipse(x, y, ax, n_std=2.0, facecolor='none', **kwargs):
    x = np.array(x)
    y = np.array(y)
    if x.size != y.size:
        raise ValueError("x and y must be the same size")
    cov = np.cov(x, y)
    pearson = cov[0, 1]/np.sqrt(cov[0, 0] * cov[1, 1])
    # Using a special case to obtain the eigenvalues of this
    # two-dimensionl dataset.
    ell_radius_x = np.sqrt(1 + pearson)
    ell_radius_y = np.sqrt(1 - pearson)
    ellipse = Ellipse((0, 0), width=ell_radius_x * 2, height=ell_radius_y * 2,
                      facecolor=facecolor, **kwargs)
    # Calculating the stdandard deviation of x from
    # the squareroot of the variance and multiplying
    # with the given number of standard deviations.
    scale_x = np.sqrt(cov[0, 0]) * n_std
    mean_x = np.mean(x)
    # calculating the stdandard deviation of y ...
    scale_y = np.sqrt(cov[1, 1]) * n_std
    mean_y = np.mean(y)
    transf = transforms.Affine2D() \
        .rotate_deg(45) \
        .scale(scale_x, scale_y) \
        .translate(mean_x, mean_y)
    ellipse.set_transform(transf + ax.transData)
    return ax.add_patch(ellipse)
```

```{python}
def draw_tree(tree, orient_tree='horizontal', vert_orient='down', axes=None, label_func=str, span=355, plot_labels=True, end_same=True, fs=10):
    # Arrays that store lines for the plot of clades
    horizontal_linecollections = []
    vertical_linecollections = []
    def get_x_positions(tree):
        """Create a mapping of each clade to its horizontal position.
        Dict of {clade: x-coord}
        """
        depths = tree.depths()
        # If there are no branch lengths, assume unit branch lengths
        if not max(depths.values()):
            depths = tree.depths(unit_branch_lengths=True)
        return depths
    def format_branch_label(clade):
                return None
    def get_y_positions(tree):
        """Create a mapping of each clade to its vertical position.
        Dict of {clade: y-coord}.
        Coordinates are negative, and integers for tips.
        """
        maxheight = tree.count_terminals()
        # Rows are defined by the tips
        heights = {tip: maxheight - i for i, tip in enumerate(reversed(tree.get_terminals()))}
        # Internal nodes: place at midpoint of children
        def calc_row(clade):
            for subclade in clade:
                if subclade not in heights:
                    calc_row(subclade)
            # Closure over heights
            heights[clade] = (
                heights[clade.clades[0]] + heights[clade.clades[-1]]
            ) / 2.0
        if tree.root.clades:
            calc_row(tree.root)
        return heights
    x_posns = get_x_positions(tree)
    y_posns = get_y_positions(tree)
    if axes is None:
        fig = plt.figure()
        if orient_tree == 'circular':
            axes = fig.add_subplot(1, 1, 1, orientation='polar')
        else:
            axes = fig.add_subplot(1, 1, 1)
    elif not isinstance(axes, plt.matplotlib.axes.Axes):
        raise ValueError("Invalid argument for axes: %s" % axes)
    leaves = [['Label', 'x loc', 'y loc', 'rotation', 'va', 'ha']]
    def draw_clade_lines(orientation="horizontal",y_here=0,x_start=0,x_here=0,y_bot=0,y_top=0,color="black",lw=".1", ls='-'):
        """Create a line.
        Graphical formatting of the lines representing clades in the plot can be
        customized by altering this function.
        """
        if orientation == "horizontal":
            axes.hlines(y_here, x_start, x_here, color=color, lw=lw, linestyle=ls)
        elif orientation == "vertical":
            axes.vlines(x_here, y_bot, y_top, color=color, linestyle=ls)
    def draw_clade(clade, x_start, color, lw, orient_tree='horizontal', vert_orient='up'):
        """Recursively draw a tree, down from the given clade."""
        x_here = x_posns[clade]
        y_here = y_posns[clade]
        xmax = max(x_posns.values())+max(x_posns.values())/30
        # phyloXML-only graphics annotations
        if hasattr(clade, "color") and clade.color is not None:
            color = clade.color.to_hex()
        if hasattr(clade, "width") and clade.width is not None:
            lw = clade.width * plt.rcParams["lines.linewidth"]
        if orient_tree == 'horizontal':
            # Draw a horizontal line from start to here
            draw_clade_lines(orientation='horizontal',y_here=y_here,x_start=x_start,x_here=x_here,color=color,lw=lw)
            if clade.name != None and end_same and '__' not in clade.name:
                draw_clade_lines(orientation='horizontal',y_here=y_here,x_start=xmax,x_here=x_here,color=color,lw=lw-1, ls='-.')
            # Add node/taxon labels
            if clade.name not in (None, clade.__class__.__name__):
                label = label_func(clade.name)
                if end_same: xplc = xmax
                else: xplc = x_here
                if plot_labels: axes.text(xplc, y_here, " %s" % label, verticalalignment="center", horizontalalignment='left', color='k', fontsize=fs)
                leaves.append([label, xplc, y_here, 0, 'center', 'left']) 
            if clade.clades:
                # Draw a vertical line connecting all children
                y_top = y_posns[clade.clades[0]]
                y_bot = y_posns[clade.clades[-1]]
                # Only apply widths to horizontal lines, like Archaeopteryx
                draw_clade_lines(orientation='vertical',x_here=x_here,y_bot=y_bot,y_top=y_top,color=color,lw=lw)
                # Draw descendents
                for child in clade:
                    draw_clade(child, x_here, color, lw)
        elif orient_tree == 'vertical':
                draw_clade_lines(orientation='vertical', x_here=y_here, y_bot=x_start, y_top=x_here,color=color,lw=lw)
                if clade.name != None and end_same and '__' not in clade.name:
                    draw_clade_lines(orientation='vertical',x_here=y_here, y_bot=xmax, y_top=x_here,color=color,lw=lw-1, ls='-.')
                if clade.name not in (None, clade.__class__.__name__):
                    label = label_func(clade.name)
                    if end_same: xplc = xmax
                    else: xplc = x_here
                    if vert_orient == 'up':
                        if plot_labels: axes.text(y_here, xplc,  " %s" % label, verticalalignment='bottom', horizontalalignment='center', color='k', rotation=90, fontsize=fs)
                        leaves.append([label, y_here, xplc, 90, 'bottom', 'center']) 
                    elif vert_orient == 'down':
                        if plot_labels: axes.text(y_here, xplc,  " %s" % label, verticalalignment='top', horizontalalignment='center', color='k', rotation=90, fontsize=fs)
                        leaves.append([label, y_here, xplc, 90, 'top', 'center']) 
                if clade.clades:
                    y_top = y_posns[clade.clades[0]]
                    y_bot = y_posns[clade.clades[-1]]
                    draw_clade_lines(orientation='horizontal', y_here=x_here, x_start=y_bot, x_here=y_top, color=color,lw=lw)
                    for child in clade:
                        draw_clade(child, x_here, color, lw, orient_tree='vertical', vert_orient=vert_orient)
    def draw_clade_polar(clade, color, lw, x_start=0.1, y_start=0, span=360):
        ymax = max(y_posns.values())
        yang = span/ymax
        xmax = max(x_posns.values())+max(x_posns.values())/30
        x_here = x_posns[clade]
        y_here = y_posns[clade]
        rad = span*np.pi/180
        rad = rad/ymax
        if y_start == 0:
            y_start = rad*y_start
        y_here = rad*y_here
        if x_here != 0: 
            axes.plot([y_start, y_here], [x_start, x_here], color=color, lw=lw)
            if clade.name != None and end_same and '__' not in clade.name:
                axes.plot([y_start, y_here], [x_here, xmax], color=color, lw=lw-1, linestyle='-.')
        if clade.name not in (None, clade.__class__.__name__):
            label = label_func(clade.name)
            rot = y_here*(180/np.pi)
            if end_same: xplc = xmax
            else: xplc = x_here
            if rot <= 90: va, ha = 'center', 'left'
            elif rot <= 180: va, ha, rot = 'center', 'right', rot-180
            elif rot <= 270: va, ha, rot = 'center', 'right', rot-180
            else: va, ha = 'center', 'left'
            if plot_labels: axes.text(y_here, xplc, label, color='k', rotation=rot, rotation_mode='anchor', va=va, ha=ha, fontsize=fs)
            leaves.append([label, y_here, xplc, rot, va, ha])
        if clade.clades:
            y_top = y_posns[clade.clades[0]]
            y_bot = y_posns[clade.clades[-1]]
            y_top = y_top*yang*np.pi/180
            y_bot = y_bot*yang*np.pi/180
            curve = [[y_bot, y_top], [x_here, x_here]]
            x = np.linspace(curve[0][0], curve[0][1], 500)
            y = interp1d(curve[0], curve[1])(x)
            axes.plot(x, y, color=color, lw=lw)
            ymin, ymax = min(x), max(x)
            ydiff = ymax-ymin
            count = [1 for child in clade]
            count = sum(count)-2
            locs = [ymin]
            for a in range(count):
                locs.append(ydiff/(count+1)+ymin)
            locs.append(ymax)
            count = 0
            for child in clade:
                if child.name != None: 
                    y_start = y_posns[child]*rad
                else:
                    y_start = locs[count]
                draw_clade_polar(child, color, lw, x_start=x_here, y_start=y_start, span=span)
                count += 1
    plt.sca(axes)
    if orient_tree in ['horizontal', 'vertical']:
        draw_clade(tree.root, 0, "k", plt.rcParams["lines.linewidth"], orient_tree=orient_tree, vert_orient=vert_orient)
        if orient_tree == 'horizontal':
            xmax = max(x_posns.values())
            axes.set_xlim(-0.05 * xmax, 1.25 * xmax)
            # Also invert the y-axis (origin at the top)
            # Add a small vertical margin, but avoid including 0 and N+1 on the y axis
            axes.set_ylim(max(y_posns.values()) + 0.8, 0.2)
        elif orient_tree == 'vertical':
            axes.set_xlim(max(y_posns.values()) + 0.8, 0.2)
            xmax = max(x_posns.values())
            if vert_orient == 'up':
                axes.set_ylim(-0.05 * xmax, 1.25 * xmax)
            elif vert_orient == 'down':
                axes.set_ylim(1.25 * xmax, -0.05 * xmax)
        axes.set_xticks([]), axes.set_yticks([])
    elif orient_tree == 'circular':
        print('Note that if you provided an axes for this then it must be polar orientation or it will probably look very strange')
        x_start = 0
        y_start = 0
        draw_clade_polar(tree.root, "k", plt.rcParams["lines.linewidth"], x_start=x_start, y_start=y_start, span=span)
        axes.set_ylim([0, max(x_posns.values())])
        axes.yaxis.grid(False)
        axes.set_xticks([])
        axes.set_yticklabels([])
    return leaves
```

Re-starting this in October 2023. Trying to see if I can use the files that I processed for Vanessa for the frailty project - this only had a subset of participants with IBD, because not all hada frailty index calculated. Checking whether I looked at all participants or only the frailty subset.

# Check for samples

```{python}
ft = pd.read_csv('/Users/robynwright/Dropbox/Langille_Lab_postdoc/AtlanticPATH_frailty/feature_table.tsv', index_col=0, header=0, sep='\t')
metadata = pd.read_csv(metadata_fn, index_col=0, header=0)
sample_ft = list(ft.columns)
sample_md = list(metadata.index.values)
asv = pd.read_csv(asv_processed, index_col=0, header=0)

in_ft, not_in_ft = [], []
for s in sample_md:
  if s in sample_ft:
    in_ft.append(s)
  else:
    not_in_ft.append(s)

in_previous, not_in_previous = [], []
for s in not_in_ft:
  if s in asv.columns:
    in_previous.append(s)
  else:
    not_in_previous.append(s)

for s in not_in_previous:
  print(metadata.loc[s, 'CASEID'])
  
finished = True
```

There are samples missing, so going to restart with classifying them with the HOMD in QIIME2, and then will redo filtering steps etc. 

# Re-classify taxa

QIIME2 objects are on vulcan: /Private/PATH_DATA/IBD_samples/

```{bash, eval=FALSE}
conda activate qiime2-2022.2

qiime feature-classifier classify-sklearn \
  --i-reads merged_representative_sequences.qza \
  --i-classifier /home/shared/taxa_classifiers/qiime2-2022.2_classifiers/HOMD-classifier.qza \
  --p-n-jobs 8 \
  --output-dir taxa
  
######################

qiime tools export \
  --input-path taxa/classification.qza \
  --output-path taxa
  
qiime feature-table summarize \
  --i-table merged_table.qza  \
  --o-visualization merged_table_summary.qzv

#median = 15761
qiime feature-table filter-features \
  --i-table merged_table.qza \
  --p-min-frequency 15 \
  --p-min-samples 1 \
  --o-filtered-table merged_table_filtered.qza
  
qiime taxa filter-table \
  --i-table merged_table_filtered.qza \
  --i-taxonomy taxa/classification.qza \
  --p-include k__ \
  --p-exclude mitochondria,chloroplast \
  --o-filtered-table merged_table_filtered_contamination.qza
  
qiime feature-table summarize \
  --i-table merged_table_filtered_contamination.qza \
  --o-visualization summary_merged_table_filtered_contamination.qzv
  
qiime diversity alpha-rarefaction \
  --i-table merged_table_filtered_contamination.qza \
  --p-max-depth 131941 \
  --p-steps 20 \
  --p-metrics 'observed_features' \
  --o-visualization merged_rarefaction_curves.qzv

qiime diversity alpha-rarefaction \
  --i-table merged_table_filtered_contamination.qza \
  --p-max-depth 50000 \
  --p-steps 50 \
  --p-metrics 'observed_features' \
  --o-visualization merged_rarefaction_curves_50000.qzv
  
qiime diversity alpha-rarefaction \
  --i-table merged_table_filtered_contamination.qza \
  --p-max-depth 10000 \
  --p-steps 20 \
  --p-metrics 'observed_features' \
  --o-visualization merged_rarefaction_curves_10000.qzv
  
qiime feature-table filter-seqs \
  --i-data merged_representative_sequences.qza \
  --i-table merged_table_filtered_contamination.qza \
  --o-filtered-data  representative_sequences_filtered_contamination.qza

qiime fragment-insertion sepp \
  --i-representative-sequences representative_sequences_filtered_contamination.qza \
  --i-reference-database /home/shared/rRNA_db/16S/sepp-refs-gg-13-8.qza \
  --o-tree insertion_tree.qza \
  --o-placements insertion_placements.qza \
  --p-threads 8
  
qiime tools export \
  --input-path representative_sequences_filtered_contamination.qza \
  --output-path exports
  
sed -i -e '1 s/Feature/#Feature/' -e '1 s/Taxon/taxonomy/' taxa/taxonomy.tsv

qiime tools export \
  --input-path merged_table_filtered_contamination.qza \
  --output-path exports
  
biom add-metadata \
  -i exports/feature-table.biom \
  -o exports/feature-table_w_tax.biom \
  --observation-metadata-fp taxa/taxonomy.tsv \
  --sc-separated taxonomy
  
biom convert \
  -i exports/feature-table_w_tax.biom \
  -o exports/feature-table_w_tax.txt \
  --to-tsv \
  --header-key taxonomy
  
qiime tools export \
  --input-path insertion_tree.qza \
  --output-path exports
  

  
#scp robyn@vulcan.pharmacology.dal.ca:/home/robyn/Private/PATH_DATA/IBD_samples/exports/ .
scp robyn@vulcan.pharmacology.dal.ca:/home/robyn/Private/PATH_DATA/IBD_samples/merged_rarefaction_curves_50000.qzv .
```

# Calculate prevalence cutoff

```{python}
ft = pd.read_csv(analysis_folder+'exports/feature-table_w_tax.txt', index_col=0, header=1, sep='\t').drop('taxonomy', axis=1)

ft = ft.transpose()
ft = ft[ft.sum(axis=1) >= 1000]
ft = ft.transpose()

ft_ra = ft.copy(deep=True)
ft_ra = ft_ra.divide(ft_ra.sum(axis=0), axis=1).multiply(100)

ft_prev = ft.copy(deep=True)
ft_prev[ft_prev > 1] = 1
ft_prev['Sum'] = ft_prev.sum(axis=1)

fig = plt.figure(figsize=(15,15))
ax1 = plt.subplot(311)
ax2 = plt.subplot(312, sharex=ax1)
ax3 = plt.subplot(313, sharex=ax1)

cutoffs = [1, 0.99, 0.98, 0.97, 0.96, 0.95, 0.9, 0.85, 0.8, 0.75, 0.7, 0.65, 0.6, 0.55, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05, 0.04, 0.03, 0.02, 0.01, 0]
#seqs = [1000, 2000, 3000, 4000, 5000]
seqs = [2000, 2250, 2500, 2750, 3000]
colors_seqs = ['#FBEC03', '#FBB803', '#FB7803', '#FB1203', '#950A01']
cutoffs.reverse()
for c in range(len(cutoffs)):
  prev = round(ft.shape[1]*cutoffs[c])
  ft_prev_coff = ft_prev.copy(deep=True)
  ft_prev_coff = ft_prev_coff.loc[ft_prev_coff['Sum'] >= prev]
  relabun_range = ft_ra.loc[ft_prev_coff.index, :].sum(axis=0).values
  num_asv_range = ft_prev_coff.drop('Sum', axis=1).sum(axis=0).values
  x = cutoffs[c]*100
  sc = ax1.scatter(np.random.normal(x, scale=0.1, size=len(relabun_range)), relabun_range, marker='o', color='#2471A3', alpha=0.1, s=2)
  box = ax1.boxplot(relabun_range, positions=[x], widths=0.8, showfliers=False)
  for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: bi = plt.setp(box[item], color='k')
  sc = ax2.scatter(np.random.normal(x, scale=0.1, size=len(num_asv_range)), num_asv_range, marker='o', color='#2471A3', alpha=0.1, s=2)
  box = ax2.boxplot(num_asv_range, positions=[x], widths=0.8, showfliers=False)
  for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: bi = plt.setp(box[item], color='k')
  for s in range(len(seqs)):
    ft_red = ft.copy(deep=True)
    ft_red = ft_red.loc[ft_prev_coff.index, :].transpose()
    ft_red = ft_red[ft_red.sum(axis=1) >= seqs[s]]
    ft_red = ft_red.transpose()
    print(cutoffs[c], seqs[s], ft_red.shape[1])
    samples_remaining = ft_red.shape[1]/ft.shape[1]
    sc = ax3.scatter(x, samples_remaining, marker='o', color=colors_seqs[s], s=30, alpha=0.8)

handles = [Line2D([0], [0], marker='s', color='w', label='>'+str(seqs[s])+' sequences', markerfacecolor=colors_seqs[s], markersize=12) for s in range(len(seqs))]
legend = ax3.legend(handles=handles, loc='lower left')

xt = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]
plt.sca(ax1)
ti = plt.xticks(xt, [str(s/100) for s in xt])
yl = plt.ylabel('Relative abundance (%)')
plt.sca(ax2)
yl = plt.ylabel('Number of ASVs')
plt.sca(ax3)
yl = plt.ylabel('Proportion of samples remaining')
xl = plt.xlabel('Prevalence cut-off')

plt.savefig(analysis_folder+'figures/prevalence_cutoff_reduced.png', dpi=600, bbox_inches='tight')
```

## Sorting metadata

```{python}
md = pd.read_csv(previous_metadata_fn, header=0, index_col=0)
samples = list(md.index.values)
future_md = pd.read_csv(folder+'Data_IBD_baseline.csv', index_col=0, header=0)
ibd_md = pd.read_csv(folder+'IBD_STUDY_merge_all.csv', index_col=0, header=0)

rename_future = {'SMK_CIG_CUR_FREQ':'A_SMK_CIG_CUR_FREQ', 'AGE':'F1_SDC_AGE_CALC', 'HS_DENTAL_VISIT_LAST':'A_HS_DENTAL_VISIT_LAST', 'SLE_LIGHT_EXP':'A_SLE_LIGHT_EXP', 'NUT_VEG_QTY':'NUT_VEG_DAY_QTY', 'NUT_JUICE_QTY':'NUT_JUICE_DAY_QTY', 'REFINED_GRAIN_DAY_SERVINGS':'REFINED_GRAIN_SERVINGS_DAY_QTY', 'NUTS_SEEDS_DAY_SERVINGS':'NUTS_SEEDS_SERVINGS_PER_DAY', 'SALT_ADDED':'SALT_SEASONING'}
future_md = future_md.rename(columns=rename_future)
future_md['PM_WAIST_AVG'] = ''
future_md['PM_BIOIMPED_FFM'] = ''

rename_ibd = {'A_SDC_AGE_CALC':'F1_SDC_AGE_CALC', 'ROUNDED_BMI':'PM_BIOIMPED_BMI'}
ibd_md = ibd_md.rename(columns=rename_ibd)

variables_md = ['CASEID', 'PARTICIPANT_CODE', 'SALIVA', 'Sample_collection_year', 'Baseline Completion Date', 'Age_at_sample_collection', 'Time_between_sampling_and_IBD_diagnosis', 'Time_between_sampling_and_UC_diagnosis', 'Time_between_sampling_and_Crohns_diagnosis', 'GROUP', 'SDC_AGE_CALC', 'DIS_UC_EVER', 'DIS_UC_AGE', 'DIS_CROHN_EVER', 'DIS_CROHN_AGE', 'CASE_CONTROL', 'EXTRACTION_NUMBER', 'RUN_NUMBER', 'SDC_GENDER']
variables_bl_md = ['A_SMK_CIG_CUR_FREQ', 'F1_SDC_AGE_CALC', 'A_HS_DENTAL_VISIT_LAST', 'PM_BIOIMPED_BMI', 'PM_BIOIMPED_WEIGHT', 'PM_WAIST_AVG', 'PM_WAIST_HIP_RATIO', 'PM_STANDING_HEIGHT_AVG', 'A_SLE_LIGHT_EXP', 'NUT_VEG_DAY_QTY', 'NUT_JUICE_DAY_QTY', 'REFINED_GRAIN_SERVINGS_DAY_QTY', 'PM_BIOIMPED_FFM', 'SALT_SEASONING', 'NUTS_SEEDS_SERVINGS_PER_DAY']

future_md = future_md.loc[:, variables_bl_md]
ibd_md = ibd_md.loc[:, variables_bl_md+['sample_name']]
md = md.loc[:, variables_md]

# sample_future = [s for s in future_md.index.values if s in md['SALIVA'].values]
# sample_ibd = [s for s in ibd_md.index.values if str(s) in md.index.values]
# future_md = future_md.loc[sample_future, :]
# ibd_md = ibd_md.loc[sample_ibd, :]
ibd_md.index = ibd_md.index.map(str)
#future_md = future_md.set_index('SALIVA')

ibd_md_count, ibd_md_2_count, future_md_count = 0, 0, 0
md[variables_bl_md] = ''
for row in md.index.values:
  found = False
  if row in ibd_md.index.values:
    found = True
    for col in variables_bl_md:
      md.loc[row, col] = ibd_md.loc[row, col]
    ibd_md_count += 1
  elif row in ibd_md.index.values:
    found = True
    for col in variables_bl_md:
      md.loc[row, col] = ibd_md.loc[row, col]
    ibd_md_count += 1
  elif md.loc[row, 'SALIVA'] in future_md.index.values:
    found = True
    for col in variables_bl_md:
      md.loc[row, col] = future_md.loc[md.loc[row, 'SALIVA'], col]
    future_md_count += 1
  if not found:
    for row2 in ibd_md.index.values:
      if ibd_md.loc[row2, 'sample_name'] == row:
        for col in variables_bl_md:
          md.loc[row, col] = ibd_md.loc[row2, col]
        ibd_md_2_count += 1

md.to_csv(analysis_folder+'files/metadata_fixed.csv')
```

## Initial filtering and creation of files

```{python}
ft = pd.read_csv(analysis_folder+'exports/feature-table_w_tax.txt', index_col=0, header=1, sep='\t')
tax = ft.loc[:, ['taxonomy']]
ft = ft.drop(['taxonomy'], axis=1)
md = pd.read_csv(analysis_folder+'files/metadata_fixed.csv', header=0, index_col=0)

#remove samples with <1000 reads
ft = ft.transpose()
ft = ft[ft.sum(axis=1) >= 1000]
ft = ft.transpose()

ft_ra = ft.copy(deep=True)
ft_ra = ft_ra.divide(ft_ra.sum(axis=0), axis=1).multiply(100)

#prevalence filtering
ft_prev = ft.copy(deep=True)
ft_prev[ft_prev > 1] = 1
ft_prev['Sum'] = ft_prev.sum(axis=1)
prev = round(ft.shape[1]*0.1)
ft_prev = ft_prev.loc[ft_prev['Sum'] >= prev]

ft = ft.loc[ft_prev.index, :].transpose()
ft = ft[ft.sum(axis=1) >= 2500]
ft = ft.transpose()

#now get the paired samples - matching them all 1:1 with the match that's closest in age
#md = md.loc[ft.columns, :]
model1 = ['A_SMK_CIG_CUR_FREQ', 'F1_SDC_AGE_CALC', 'SDC_GENDER', 'A_HS_DENTAL_VISIT_LAST', 'PM_BIOIMPED_BMI', 'PM_BIOIMPED_WEIGHT', 'PM_WAIST_AVG', 'PM_WAIST_HIP_RATIO', 'PM_STANDING_HEIGHT_AVG', 'A_SLE_LIGHT_EXP', 'NUT_VEG_DAY_QTY', 'NUT_JUICE_DAY_QTY', 'REFINED_GRAIN_SERVINGS_DAY_QTY', 'PM_BIOIMPED_FFM', 'SALT_SEASONING', 'NUTS_SEEDS_SERVINGS_PER_DAY']
md = md.loc[[f for f in ft.columns if f in md.index.values], :]
md_cases = md[md['CASE_CONTROL'] == 1]
matched_case_control = {}
for row in md_cases.index.values:
  cid = md_cases.loc[row, 'CASEID']
  for row2 in md.index.values:
    if row2 != row and md.loc[row2, 'CASEID'] == cid:
      smk = [md_cases.loc[row, 'A_SMK_CIG_CUR_FREQ'], md.loc[row2, 'A_SMK_CIG_CUR_FREQ']]
      for s in range(len(smk)):
        try:
          smk[s] = float(smk[s])
        except:
          smk[s] = smk[s]
        if isinstance(smk[s], str): 
          if smk[s] == 'N': smk[s] = 0.0
        elif math.isnan(smk[s]):
          smk[s] = 0.0
        elif smk[s] < 0: 
          smk[s] = 0.0
      if md_cases.loc[row, 'SDC_GENDER'] != md.loc[row2, 'SDC_GENDER']:
        # print('Gender', row, row2, cid, md_cases.loc[row, 'SDC_GENDER'], md.loc[row2, 'SDC_GENDER'])
        continue
      elif smk[0] != smk[1]:
        continue
      if row not in matched_case_control:
        matched_case_control[row] = [row2]
      else:
        matched_case_control[row].append(row2)
matched_controls = []
matched_case_control_reduced = {}
for sample in matched_case_control:
  if len(matched_case_control[sample]) == 1:
    matched_controls.append(matched_case_control[sample][0])
    matched_case_control_reduced[sample] = matched_case_control[sample][0]
  else:
    age1 = md.loc[sample, 'Age_at_sample_collection']
    age_md_match, vals_max, diff, best_match = {}, 0, 30, ''
    for match in matched_case_control[sample]:
      md_vals = md.loc[match, model1].values
      md_count = 0
      for m in md_vals:
        if isinstance(m, str): md_count += 1
        elif not np.isnan(m): md_count += 1
      if md_count > vals_max: vals_max = md_count
      age_diff = abs(md.loc[match, 'Age_at_sample_collection']-age1)
      age_md_match[match] = [md_count, age_diff]
    for match in age_md_match:
      if age_md_match[match][0] == vals_max:
        if age_md_match[match][1] < diff:
          best_match = match
          diff = age_md_match[match][1]
    matched_case_control_reduced[sample] = best_match
    matched_controls.append(best_match)
    # diff, second_diff = 30, 30
    # best_match, second_match = '', ''
    # complete_md = []
    # matches_md = {}
    # for match in matched_case_control[sample]:
    #   md_vals = md.loc[match, model1].values
    #   md_count = 0
    #   for m in md_vals:
    #     if isinstance(m, str): md_count += 1
    #     elif not np.isnan(m): md_count += 1
    #   complete_md.append(md_count)
    #   matches_md[match] = md_count
    #   # md_vals = [0 if np.isnan(s) else 1 for s in md_vals]
    #   # complete_md = sum(md_vals)
    #   if abs(md.loc[match, 'Age_at_sample_collection']-age1) < diff:
    #     second_match = best_match
    #     best_match = match
    #     diff = abs(md.loc[match, 'Age_at_sample_collection']-age1)
    # if matches_md[best_match] != max(complete_md):
    #   if matches_md[second_match] != max(complete_md):
    #     print(complete_md, matches_md, best_match)
    # matched_case_control_reduced[sample] = best_match
    # matched_controls.append(best_match)

md_controls = md.loc[matched_controls, :]
removing = []
for row in md_cases.index.values:
  if md_cases.loc[row, 'CASEID'] not in md_controls['CASEID'].values:
    removing.append(row)

md_cases = md_cases.drop(removing, axis=0)
md_reduced = pd.concat([md_cases, md_controls])
md_reduced.to_csv(analysis_folder+'files/metadata.csv')
ft = ft.loc[:, md_reduced.index.values]
ft = ft[ft.max(axis=1) > 0]
ft.to_csv(analysis_folder+'files/asv_table.csv')

tax = pd.read_csv(analysis_folder+'exports/taxonomy.tsv', header=0, index_col=0, sep='\t')
tax = tax.loc[ft.index.values, ['taxonomy']]
tax[['Kingdom', 'Pyhlum', 'Class', 'Order', 'Family', 'Genus', 'Species']] = tax['taxonomy'].str.split(';',expand=True)
for row in tax.index.values:
  previous = tax.loc[row, 'Kingdom']
  for col in ['Pyhlum', 'Class', 'Order', 'Family', 'Genus', 'Species']:
    if tax.loc[row, col] == None:
      tax.loc[row, col] = 'Unclassified '+previous
    else:
      previous = tax.loc[row, col]
tax = tax.drop('taxonomy', axis=1)
tax.to_csv(analysis_folder+'files/taxonomy.csv')
```

Summarise metadata:
```{python}
md = pd.read_csv(analysis_folder+'files/metadata.csv', header=0, index_col=0)
md['Crohn_case_control'] = ''
md['UC_case_control'] = ''
md['Both_case_control'] = ''
md.index = md.index.map(str)

crohn_cases, uc_cases, both_cases = [], [], []
count_both, count_crohns, count_uc = 0, 0, 0
for participant in md.index.values:
  if md.loc[participant, 'DIS_CROHN_EVER'] == 1 and md.loc[participant, 'DIS_UC_EVER'] == 1:
    both_cases.append(md.loc[participant, 'CASEID'])
    md.loc[participant, 'Both_case_control'] = 1
    match = matched_case_control_reduced[participant]
    md.loc[match, 'Both_case_control'] = 0
    count_both += 1
  elif md.loc[participant, 'DIS_CROHN_EVER'] == 1:
    crohn_cases.append(md.loc[participant, 'CASEID'])
    md.loc[participant, 'Crohn_case_control'] = 1
    match = matched_case_control_reduced[participant]
    md.loc[match, 'Crohn_case_control'] = 0
    count_crohns += 1
  elif md.loc[participant, 'DIS_UC_EVER'] == 1:
    uc_cases.append(md.loc[participant, 'CASEID'])
    md.loc[participant, 'UC_case_control'] = 1
    match = matched_case_control_reduced[participant]
    md.loc[match, 'UC_case_control'] = 0
    count_uc += 1

#0=Never;  1= Rarely;  2= Sometimes:  3= At most meals or eating occasions
salt_relabel = {'NEVER':0, 'RARELY':1, 'SOMETIMES':2, 'ALWAYS':3, 'PNA':-7}
for row in md.index.values:
  salt = md.loc[row, 'SALT_SEASONING']
  if isinstance(salt, str):
    try:
      md.loc[row, 'SALT_SEASONING'] = float(salt)
    except:
      md.loc[row, 'SALT_SEASONING'] = salt_relabel[salt]
  if md.loc[row, 'SALT_SEASONING'] == -9: 
    md.loc[row, 'SALT_SEASONING'] = -7

#convert -9 to -7
for row in md.index.values:
  for col in md.columns:
    other = md.loc[row, col]
    if other == -9:
      md.loc[row, col] = -7

#cig relabel
#0=Does not smoke currently;1=Current occasional smoker;2=Current daily smoker;-7=Not Applicable
smoke_relabel = {'Y':2, 'N':0}
for row in md.index.values:
  smoke = md.loc[row, 'A_SMK_CIG_CUR_FREQ']
  if isinstance(smoke, str):
    try:
      md.loc[row, 'A_SMK_CIG_CUR_FREQ'] = float(smoke)
    except:
      md.loc[row, 'A_SMK_CIG_CUR_FREQ'] = smoke_relabel[smoke]
  if md.loc[row, 'A_SMK_CIG_CUR_FREQ'] > 1:
    md.loc[row, 'A_SMK_CIG_CUR_FREQ'] = 1

md.to_csv(analysis_folder+'files/metadata_crohns_UC.csv')
```

Metadata for models:
```{python}
md = pd.read_csv(analysis_folder+'files/metadata_crohns_UC.csv', header=0, index_col=0)
model1 = ['A_SMK_CIG_CUR_FREQ', 'F1_SDC_AGE_CALC', 'SDC_GENDER', 'A_HS_DENTAL_VISIT_LAST', 'PM_BIOIMPED_BMI', 'PM_BIOIMPED_WEIGHT', 'PM_WAIST_AVG', 'PM_WAIST_HIP_RATIO', 'PM_STANDING_HEIGHT_AVG', 'A_SLE_LIGHT_EXP', 'NUT_VEG_DAY_QTY', 'NUT_JUICE_DAY_QTY', 'REFINED_GRAIN_SERVINGS_DAY_QTY', 'PM_BIOIMPED_FFM', 'SALT_SEASONING', 'NUTS_SEEDS_SERVINGS_PER_DAY']
model2 = ['A_SMK_CIG_CUR_FREQ', 'F1_SDC_AGE_CALC', 'SDC_GENDER', 'PM_BIOIMPED_WEIGHT', 'PM_WAIST_AVG', 'PM_WAIST_HIP_RATIO', 'PM_STANDING_HEIGHT_AVG', 'A_SLE_LIGHT_EXP', 'NUT_VEG_DAY_QTY', 'REFINED_GRAIN_SERVINGS_DAY_QTY', 'PM_BIOIMPED_FFM']

keeping_model1 = []
keeping_model2 = []
for row in md.index.values:
  row_model1 = list(md.loc[row, model1].values)
  if not np.isnan(row_model1).any():
    keeping_model1.append(row)
  row_model2 = list(md.loc[row, model2].values)
  if not np.isnan(row_model2).any():
    keeping_model2.append(row)
    
keeping_model1_matched = []
keeping_model2_matched = []

for row in md.index.values:
  if row in matched_case_control_reduced:
    if row in keeping_model1 and matched_case_control_reduced[row] in keeping_model1:
      keeping_model1_matched.append(row)
      keeping_model1_matched.append(matched_case_control_reduced[row])
    if row in keeping_model2 and matched_case_control_reduced[row] in keeping_model2:
      keeping_model2_matched.append(row)
      keeping_model2_matched.append(matched_case_control_reduced[row])

md_model1 = md.loc[keeping_model1_matched, :]
md_model2 = md.loc[keeping_model2_matched, :]
md_model1.to_csv(analysis_folder+'files/metadata_model1.csv')
md_model2.to_csv(analysis_folder+'files/metadata_model2.csv')
```

Get summaries:
```{python, eval=FALSE}
md_model = 'metadata_model1'
md_model = 'metadata_crohns_UC'
md = pd.read_csv(analysis_folder+'files/'+md_model+'.csv', header=0, index_col=0)
md_summary_cols = ['Age_at_sample_collection', 'F1_SDC_AGE_CALC', 'A_SMK_CIG_CUR_FREQ', 'A_HS_DENTAL_VISIT_LAST', 'PM_BIOIMPED_BMI', 'PM_BIOIMPED_WEIGHT', 'PM_WAIST_AVG', 'PM_WAIST_HIP_RATIO', 'PM_STANDING_HEIGHT_AVG', 'A_SLE_LIGHT_EXP', 'NUT_VEG_DAY_QTY', 'NUT_JUICE_DAY_QTY', 'REFINED_GRAIN_SERVINGS_DAY_QTY', 'PM_BIOIMPED_FFM', 'SALT_SEASONING', 'NUTS_SEEDS_SERVINGS_PER_DAY']
groups = ['CASE_CONTROL', 'Crohn_case_control', 'UC_case_control', 'Both_case_control']
#groups = ['SDC_GENDER']

#one gender only
#md = md[md['SDC_GENDER'] == 1]

if md_model == 'metadata_crohns_UC':
  all_groups = ['Normality']
else:
  all_groups = []
for g in groups:
  all_groups.append(g+' cases')
  all_groups.append(g+' controls')
  all_groups.append(g+' test')

summary = [[], []]
rows = ['Counts', 'Proportion female']
for column in md_summary_cols:
  summary.append([])
  rows.append(column)
  
normal_stats = {}
  
if md_model == 'metadata_crohns_UC':
  summary[0].append('NA')
  summary[1].append('NA')
  count = 2
  for column in md_summary_cols:
    all_vals = md.loc[:, column].values
    orig_vals = list(all_vals)
    all_vals = [v for v in all_vals if v != -7 and not math.isnan(v)]
    res = stats.normaltest(all_vals)
    norm_stat = round(res.statistic, 2)
    norm_p = round(res.pvalue, 4)
    summary[count].append('Stat='+str(norm_stat)+', p='+str(norm_p))
    normal_stats[count] = norm_p
    count += 1

categorical_columns = ['A_HS_DENTAL_VISIT_LAST', 'A_SLE_LIGHT_EXP', 'SALT_SEASONING']

for group in groups:
  red_md = md[md[group].notna()]
  cases = red_md[red_md[group] == 1]
  controls = red_md[red_md[group] == 0]
  #controls = red_md[red_md[group] == 2]
  summary[0].append(cases.shape[0])
  summary[0].append(controls.shape[0])
  summary[0].append('NA')
  males_cases, females_cases = list(cases.loc[:, 'SDC_GENDER'].values).count(1), list(cases.loc[:, 'SDC_GENDER'].values).count(2)
  males_controls, females_controls = list(controls.loc[:, 'SDC_GENDER'].values).count(1), list(controls.loc[:, 'SDC_GENDER'].values).count(2)
  summary[1].append(females_cases/(males_cases+females_cases))
  summary[1].append(females_controls/(males_controls+females_controls))
  summary[1].append('NA')
  count = 2
  for column in md_summary_cols:
    case_control_vals = {}
    ccc = 0
    for cc in [cases, controls]:
      ccc += 1
      all_vals = cc.loc[:, column].values
      orig_vals = list(all_vals)
      all_vals = [v for v in all_vals if v != -7 and not math.isnan(v)]
      case_control_vals[ccc] = all_vals
      if 'SMK' in column:
        count_smokers = sum(all_vals)/len(all_vals)
        summary[count].append(str(round(count_smokers, 2))+' ['+str(len(all_vals))+']')
      elif column in categorical_columns:
        unique_vals = list(set(all_vals))
        this_count = ''
        for v in unique_vals:
          cnt = all_vals.count(v)
          cnt = round(cnt/len(all_vals), 2)
          this_count += str(int(v))+': '+str(cnt)
          if v != unique_vals[-1]: this_count += '; '
        summary[count].append(this_count+' ['+str(len(all_vals))+']')
      else:
        try:
          minimum, maximum = round(min(all_vals), 2), round(max(all_vals), 2)
          if normal_stats[count] < 0.05:
            median = round(np.median(all_vals), 2)
            q75, q25 = np.percentile(all_vals, [75 ,25])
            iqr = round(q75 - q25, 2)
            summary[count].append(str(median)+' (IQR: '+str(iqr)+', Range: '+str(minimum)+'-'+str(maximum)+') ['+str(len(all_vals))+']')
          else:
            mean = round(np.mean(all_vals), 2)
            std = round(np.std(all_vals), 2)
            summary[count].append(str(mean)+' (STD: '+str(std)+', Range: '+str(minimum)+'-'+str(maximum)+') ['+str(len(all_vals))+']')
        except:
          print(column, orig_vals)
    if 'SMK' not in column:
      if normal_stats[count] < 0.05: norm = False
      else: norm = True
      if norm:
        res = ttest_ind(case_control_vals[1], case_control_vals[2])
      else:
        res = mannwhitneyu(case_control_vals[1], case_control_vals[2])
      stat = round(res.statistic, 2)
      pval = round(res.pvalue, 4)
      summary[count].append('Stat='+str(stat)+', p='+str(pval))
    else:
      summary[count].append('NA')
    count += 1

summary_df = pd.DataFrame(summary, index=rows, columns=all_groups)
#summary_df.to_csv(analysis_folder+'files/summary_males_'+md_model+'.csv')
summary_df.to_csv(analysis_folder+'files/summary_'+md_model+'.csv')
```

Match number of females to males:
```{python}
groups = ['Crohn_case_control', 'UC_case_control', 'Both_case_control']
metadata = pd.read_csv(analysis_folder+'files/metadata_crohns_UC.csv', index_col=0, header=0)
metadata_model1 = pd.read_csv(analysis_folder+'files/metadata_model1.csv', index_col=0, header=0)
metadata_model2 = pd.read_csv(analysis_folder+'files/metadata_model2.csv', index_col=0, header=0)
females = metadata.loc[metadata['SDC_GENDER'] == 2]
males = metadata.loc[metadata['SDC_GENDER'] == 1]
males_model1 = metadata_model1.loc[metadata_model1['SDC_GENDER'] == 1]
females_model1 = metadata_model1.loc[metadata_model1['SDC_GENDER'] == 2]
#males are the same for model1 and model2, so only need to do this once for all and once for the reduced number. Using model1 for females as this is a slightly smaller number

female_cases_model1 = []
female_cases_all = []

print(females.shape[0], males.shape[0])

for group in groups:
  males_group_model1 = males_model1.loc[males_model1[group] == 1]
  print(males_group_model1.shape[0])
  females_group_model1 = females_model1.loc[females_model1[group] == 1]
  female_random = list(females_group_model1.index.values)
  random.shuffle(female_random)
  females_group_model1 = females_group_model1.loc[female_random[:males_group_model1.shape[0]], :]
  for f in females_group_model1.index.values:
    female_cases_model1.append(f)
  males_group = males.loc[males[group] == 1].drop(males_group_model1.index.values, axis=0)
  females_group = females.loc[females[group] == 1].drop(females_group_model1.index.values, axis=0)
  female_random = list(females_group.index.values)
  random.shuffle(female_random)
  females_group = females_group.loc[female_random[:males_group.shape[0]], :]
  for f in females_group.index.values:
    female_cases_all.append(f)

female_matching = {}
for row in females.index.values:
  if females.loc[row, 'CASE_CONTROL'] != 1: continue
  cid = females.loc[row, 'CASEID']
  for row2 in females.index.values:
    if row != row2 and females.loc[row2, 'CASEID'] == cid:
      female_matching[row] = row2

female_model1 = []
for part in female_cases_model1:
  female_model1.append(part)
  female_model1.append(female_matching[part])

female_all = list(female_model1)
for part in female_cases_all:
  female_all.append(part)
  female_all.append(female_matching[part])

# with open(analysis_folder+'files/female_reduced.list', 'wb') as f:
#     pickle.dump([female_all, female_model1], f)

```

Collapse and rarefy:
```{R}
asv_table <- read.csv(paste(py$analysis_folder, "files/asv_table.csv", sep=""))
taxonomy <- read.csv(paste(py$analysis_folder, "files/taxonomy.csv", sep=""))
phy_tree <- read_tree(paste(py$analysis_folder, "exports/tree.nwk", sep=''))

asv_table_num = data.matrix(asv_table[,2:321]) 
rownames(asv_table_num) = asv_table[,1] 
asv_table = as.matrix(asv_table_num) 

taxmat <- taxonomy[,-1] #remove the OTU ID column from the taxonomy table
rownames(taxmat) <- taxonomy[,1] #and now give the taxonomy table the OTU IDs as row names

ASV = otu_table(asv_table, taxa_are_rows = TRUE)
TAX = tax_table(taxmat)
taxa_names(TAX) <- taxonomy[,1]
physeq = phyloseq(ASV,phy_tree,TAX)
physeq_rare = rarefy_even_depth(physeq, sample.size = min(sample_sums(physeq)), replace = TRUE, trimOTUs = TRUE, verbose = TRUE)
ft_rare = otu_table(physeq_rare)
write.csv(ft_rare, paste(py$analysis_folder, 'files/asv_table_rare.csv', sep=''))

tree_red = phy_tree(physeq)
write.tree(tree_red, paste(py$analysis_folder, 'files/asv_tree.nwk', sep=''))

physeq_species = tax_glom(physeq, taxrank="ta7")
tree_species = phy_tree(physeq_species)
write.tree(tree_species, paste(py$analysis_folder, 'files/species_tree.nwk', sep=''))
ft_species = otu_table(physeq_species)
write.csv(ft_species, paste(py$analysis_folder, 'files/species_table.csv', sep=''))
physeq_rare_species = rarefy_even_depth(physeq_species, sample.size = min(sample_sums(physeq_species)), replace = TRUE, trimOTUs = TRUE, verbose = TRUE)
ft_rare_species = otu_table(physeq_rare_species)
write.csv(ft_rare_species, paste(py$analysis_folder, 'files/species_table_rare.csv', sep=''))

physeq_genus = tax_glom(physeq, taxrank="ta6")
tree_genus = phy_tree(physeq_genus)
write.tree(tree_genus, paste(py$analysis_folder, 'files/genus_tree.nwk', sep=''))
ft_genus = otu_table(physeq_genus)
write.csv(ft_genus, paste(py$analysis_folder, 'files/genus_table.csv', sep=''))
physeq_rare_genus = rarefy_even_depth(physeq_genus, sample.size = min(sample_sums(physeq_genus)), replace = TRUE, trimOTUs = TRUE, verbose = TRUE)
ft_rare_genus = otu_table(physeq_rare_genus)
write.csv(ft_rare_genus, paste(py$analysis_folder, 'files/genus_table_rare.csv', sep=''))

physeq_family = tax_glom(physeq, taxrank="ta5")
tree_family = phy_tree(physeq_family)
write.tree(tree_family, paste(py$analysis_folder, 'files/family_tree.nwk', sep=''))
ft_family = otu_table(physeq_family)
write.csv(ft_family, paste(py$analysis_folder, 'files/family_table.csv', sep=''))
physeq_rare_family = rarefy_even_depth(physeq_family, sample.size = min(sample_sums(physeq_family)), replace = TRUE, trimOTUs = TRUE, verbose = TRUE)
ft_rare_family = otu_table(physeq_rare_family)
write.csv(ft_rare_family, paste(py$analysis_folder, 'files/family_table_rare.csv', sep=''))
```

Now convert sample names back to what they should be (remove X):
```{python}
levels = ['asv', 'species', 'genus', 'family']
rare = ['', '_rare']
for l in levels:
  for r in rare:
    fn = l+'_table'+r+'.csv'
    ft = pd.read_csv(analysis_folder+'files/'+fn, index_col=0, header=0)
    samples = ft.columns
    sample_rename = {}
    for s in samples:
      sample_rename[s] = s.replace('X', '').replace('.', '-')
    ft = ft.rename(columns=sample_rename)
    ft.to_csv(analysis_folder+'files/'+fn)
  
finished = True
```

Robust CLR transformations:
```{python}
levels = ["family", "genus", "species", "asv"]
fts = []
for level in levels:
  fn = analysis_folder+'files/'+level+'_table.csv'
  ft = pd.read_csv(fn, index_col=0, header=0)
  fts.append(ft)
  ft_rclr = ft.copy(deep=True)
  X = ft_rclr.iloc[0:].values
  this_ft_rclr = rclr(X)
  ft_rclr = pd.DataFrame(this_ft_rclr, columns=ft_rclr.columns, index=ft_rclr.index.values).fillna(value=0)
  ft_rclr.to_csv(fn.replace('.csv', '_rclr.csv'))

finished = True
```

CLR transformations:
```{R}
num = 4 #do this for each number in 1-4 for the levels family-asv
ft = py$fts[[num]]

table_num = data.matrix(ft[,1:320]) #convert the ASV table to a numeric matric
rownames(table_num) = rownames(ft)
table = otu_table(table_num, taxa_are_rows = TRUE)
physeq = phyloseq(table)
physeq_clr <- microbiome::transform(physeq, "clr")
table_clr = data.frame(otu_table(physeq_clr))
write.csv(table_clr, paste(py$analysis_folder, 'files/', py$levels[num], '_table_clr.csv', sep=''))
```

Remove X from samples again:
```{python}
levels = ['asv', 'species', 'genus', 'family']
rare = ['_clr']
for l in levels:
  for r in rare:
    fn = l+'_table'+r+'.csv'
    ft = pd.read_csv(analysis_folder+'files/'+fn, index_col=0, header=0)
    samples = ft.columns
    sample_rename = {}
    for s in samples:
      sample_rename[s] = s.replace('X', '').replace('.', '-')
    ft = ft.rename(columns=sample_rename)
    ft.to_csv(analysis_folder+'files/'+fn)
  
finished = True
```

## Calculate alpha diversity

```{python}
metrics = ['chao1', 'faith_pd', 'observed_otus', 'shannon', 'simpson', 'simpson_e']
levels = ["family", "genus", "species", "asv"]
for level in levels:
  all_div = []
  ft_level = pd.read_csv(analysis_folder+'files/'+level+'_table_rare.csv', index_col=0, header=0)
  tree_name = analysis_folder+'files/'+level+'_tree.nwk'
  for m in range(len(metrics)):
    if m == 1:
      tree = read(tree_name, format="newick", into=TreeNode)
      alpha_div = alpha_diversity(metrics[m], ft_level.transpose(), otu_ids=ft_level.index.values, tree=tree, validate=False)
    else:
      alpha_div = alpha_diversity(metrics[m], ft_level.transpose())
    alpha_div = alpha_div.to_frame().rename(columns={0:metrics[m]})
    alpha_div.index = ft_level.columns
    all_div.append(alpha_div)
  all_div = pd.concat(all_div)
  all_div = all_div.fillna(value=0)
  all_div = all_div.groupby(by=all_div.index, axis=0).sum()
  all_div.to_csv(analysis_folder+'diversity/alpha_diversity_'+level+'.csv')

finished = True
```

## Calculate beta diversity

CLR, rCLR and Bray-Curtis distances:
```{python}
fts = ['asv_table', 'species_table', 'genus_table', 'family_table']
levels = ['asv', 'species', 'genus', 'family']

distances = ['clr', 'rclr', 'braycurtis']

for n in range(len(fts)):
  name = fts[n]
  level = levels[n]
  for metric in distances:
    if metric == 'braycurtis': name = name+'_rare'
    ft = pd.read_csv(analysis_folder+'files/'+name+'.csv', index_col=0, header=0)
    sample_df = ft.copy(deep=True)
    if 'clr' not in metric:
      X = sample_df.transpose().iloc[0:].values
    elif metric == 'clr':
      sample_df[sample_df == 0] = 1
      for col in sample_df.columns:
        sample_df.loc[:, col] = clr(sample_df.loc[:, col].values)
      X = sample_df.transpose().iloc[0:].values
    elif metric == 'rclr':
      X = sample_df.iloc[0:].values
      rclr_sample = rclr(X)
      rclr_sample = pd.DataFrame(rclr_sample, columns=sample_df.columns, index=sample_df.index.values).fillna(value=0)
      X = rclr_sample.transpose().iloc[0:].values
    if 'unifrac' not in metric:
      if 'clr' in metric: dist_met = 'euclidean'
      else: dist_met = metric
      similarities = np.nan_to_num(distance.cdist(X, X, dist_met)) 
      similarities = pd.DataFrame(similarities, index=sample_df.columns, columns=sample_df.columns)
    else:
      sample_df.index = sample_df.index.map(str)
      similarities = beta_diversity(metric, X, sample_df.columns, tree=tree, otu_ids=sample_df.index.values, validate=False)
      similarities = similarities.to_data_frame()
    similarities.to_csv(analysis_folder+'diversity/'+metric+'_'+level+'.csv')

finished = True

```

UniFrac distances:
```{R}
for (level in c('family', 'genus', 'species', 'asv')) {
  table <- read.csv(paste(py$analysis_folder, "files/", level, "_table_rare.csv", sep=""))
  phy_tree <- read_tree(paste(py$analysis_folder, "files/", level, "_tree.nwk", sep=""))
  table_num = data.matrix(table[, 2:321])
  rownames(table_num) = table[,1]
  table = as.matrix(table_num)
  
  TABLE = otu_table(table, taxa_are_rows = TRUE)
  physeq = phyloseq(TABLE,phy_tree)
  
  distance <- phyloseq::distance(physeq, method="wunifrac")
  dist_mat = as.matrix(distance)
  write.csv(dist_mat, paste(py$analysis_folder, 'diversity/weighted_unifrac_', level, '.csv', sep=""))

  distance <- phyloseq::distance(physeq, method="unifrac")
  dist_mat = as.matrix(distance)
  write.csv(dist_mat, paste(py$analysis_folder, 'diversity/unweighted_unifrac_', level, '.csv', sep=""))
}
```

Remove X from sample names:
```{python}
levels = ['asv', 'species', 'genus', 'family']
rare = ['weighted_unifrac_', 'unweighted_unifrac_']
for l in levels:
  for r in rare:
    fn = r+l+'.csv'
    ft = pd.read_csv(analysis_folder+'diversity/'+fn, index_col=0, header=0)
    samples = ft.columns
    sample_rename = {}
    for s in samples:
      sample_rename[s] = s.replace('X', '').replace('.', '-')
    ft = ft.rename(columns=sample_rename, index=sample_rename)
    ft.to_csv(analysis_folder+'diversity/'+fn)
  
finished = True
```

Use QIIME2 for phylogenetic RPCA (first test with ASV):
```{bash, eval=FALSE}
cd AtPATH_IBD/analysis_HOMD_2024
conda activate qiime2-2022.11
mkdir phylo-PCA
#table = asv_table.csv
#taxonomy = taxonomy.csv
#tree = asv_tree.nwk
#scp files/taxonomy.csv vulcan:/home/robyn/AtPATH_IBD/analysis_HOMD_2024/phylo-PCA/
#scp files/asv_table.csv vulcan:/home/robyn/AtPATH_IBD/analysis_HOMD_2024/phylo-PCA/
#scp files/asv_tree.nwk vulcan:/home/robyn/AtPATH_IBD/analysis_HOMD_2024/phylo-PCA/
tr ',' '\t' < asv_table.csv > asv_table.tsv
biom convert -i asv_table.tsv -o asv_table.biom --to-hdf5
qiime tools import \
  --type 'FeatureTable[Frequency]' \
  --input-path asv_table.biom \
  --output-path asv_table.qza
  
qiime tools import \
  --input-path asv_tree.nwk \
  --output-path asv_tree.qza \
  --type 'Phylogeny[Rooted]'

python
import pandas as pd
tax = pd.read_csv('taxonomy.csv', index_col=0, header=0)
new_tax = []
for row in tax.index.values:
  new_tax.append([row, '; '.join(tax.loc[row, :].values)])
new_tax = pd.DataFrame(new_tax, columns=['Feature ID', 'Taxon']).set_index('Feature ID')
new_tax.to_csv('taxonomy.tsv', sep='\t')
quit()

qiime tools import \
  --type 'FeatureData[Taxonomy]' \
  --input-path taxonomy.tsv \
  --output-path taxonomy.qza
  
qiime dev refresh-cache
pip install gemelli
qiime gemelli phylogenetic-rpca-with-taxonomy \
    --i-table asv_table.qza \
    --i-phylogeny asv_tree.qza \
    --m-taxonomy-file taxonomy.qza \
    --p-min-feature-count 0 \
    --p-min-sample-count 0 \
    --o-biplot asv-phylo-ordination.qza \
    --o-distance-matrix asv-phylo-distance.qza \
    --o-counts-by-node-tree asv-phylo-tree.qza \
    --o-counts-by-node asv-phylo-table.qza \
    --o-t2t-taxonomy asv-phylo-taxonomy.qza
    
qiime tools export \
  --input-path asv-phylo-ordination.qza \
  --output-path exports
mv exports/ordination.txt exports/asv_ordination.txt 

qiime tools export \
  --input-path asv-phylo-distance.qza \
  --output-path exports
mv exports/distance-matrix.tsv exports/asv-distance-matrix.tsv
#scp -r vulcan:/home/robyn/AtPATH_IBD/analysis_HOMD_2024/phylo-PCA/ .
```

Get taxonomy ready for other levels:
```{python}
taxonomy = pd.read_csv(analysis_folder+'files/taxonomy.csv', index_col=0, header=0)
for level in ['species', 'genus', 'family']:
  ft = pd.read_csv(analysis_folder+'files/'+level+'_table.csv', index_col=0, header=0)
  taxonomy = taxonomy.drop(level.capitalize(), axis=1)
  tax = taxonomy.loc[ft.index.values, :]
  new_tax = []
  for row in tax.index.values:
    new_tax.append([row, '; '.join(tax.loc[row, :].values)])
  new_tax = pd.DataFrame(new_tax, columns=['Feature ID', 'Taxon']).set_index('Feature ID')
  new_tax.to_csv(analysis_folder+'files/'+level+'_taxonomy.tsv', sep='\t')
  #taxonomy = taxonomy.drop(level.capitalize(), axis=1)
finished = True
```

Use QIIME2 for phylogenetic RPCA:
```{bash, eval=FALSE}
#mkdir phylo-PCA-copy
#cp family_taxonomy.tsv phylo-PCA-copy/
#cp family_tree.nwk phylo-PCA-copy/
#cp family_table.csv phylo-PCA-copy/
#cp genus_taxonomy.tsv phylo-PCA-copy/
#cp genus_tree.nwk phylo-PCA-copy/
#cp genus_table.csv phylo-PCA-copy/
#cp species_taxonomy.tsv phylo-PCA-copy/
#cp species_tree.nwk phylo-PCA-copy/
#cp species_table.csv phylo-PCA-copy/
#scp -r phylo-PCA-copy vulcan:/home/robyn/AtPATH_IBD/analysis_HOMD_2024/phylo-PCA/
mv phylo-PCA-copy/* .
rm -r phylo-PCA-copy

tr ',' '\t' < species_table.csv > species_table.tsv
tr ',' '\t' < genus_table.csv > genus_table.tsv
tr ',' '\t' < family_table.csv > family_table.tsv
biom convert -i species_table.tsv -o species_table.biom --to-hdf5
biom convert -i genus_table.tsv -o genus_table.biom --to-hdf5
biom convert -i family_table.tsv -o family_table.biom --to-hdf5
qiime tools import \
  --type 'FeatureTable[Frequency]' \
  --input-path species_table.biom \
  --output-path species_table.qza
  
qiime tools import \
  --type 'FeatureTable[Frequency]' \
  --input-path genus_table.biom \
  --output-path genus_table.qza
  
qiime tools import \
  --type 'FeatureTable[Frequency]' \
  --input-path family_table.biom \
  --output-path family_table.qza
  
qiime tools import \
  --input-path species_tree.nwk \
  --output-path species_tree.qza \
  --type 'Phylogeny[Rooted]'
  
qiime tools import \
  --input-path genus_tree.nwk \
  --output-path genus_tree.qza \
  --type 'Phylogeny[Rooted]'
  
qiime tools import \
  --input-path family_tree.nwk \
  --output-path family_tree.qza \
  --type 'Phylogeny[Rooted]'

qiime tools import \
  --type 'FeatureData[Taxonomy]' \
  --input-path species_taxonomy.tsv \
  --output-path species_taxonomy.qza
  
qiime tools import \
  --type 'FeatureData[Taxonomy]' \
  --input-path genus_taxonomy.tsv \
  --output-path genus_taxonomy.qza
  
qiime tools import \
  --type 'FeatureData[Taxonomy]' \
  --input-path family_taxonomy.tsv \
  --output-path family_taxonomy.qza

#need to come back to this as got an error. Not sure what it doesn't like as the species level should have the same taxonomy as ASV just with less of them? 
qiime gemelli phylogenetic-rpca-with-taxonomy \
    --i-table species_table.qza \
    --i-phylogeny species_tree.qza \
    --m-taxonomy-file species_taxonomy.qza \
    --p-min-feature-count 0 \
    --p-min-sample-count 0 \
    --o-biplot species-phylo-ordination.qza \
    --o-distance-matrix species-phylo-distance.qza \
    --o-counts-by-node-tree species-phylo-tree.qza \
    --o-counts-by-node species-phylo-table.qza \
    --o-t2t-taxonomy species-phylo-taxonomy.qza
    
qiime gemelli phylogenetic-rpca-with-taxonomy \
    --i-table genus_table.qza \
    --i-phylogeny genus_tree.qza \
    --m-taxonomy-file genus_taxonomy.qza \
    --p-min-feature-count 0 \
    --p-min-sample-count 0 \
    --o-biplot genus-phylo-ordination.qza \
    --o-distance-matrix genus-phylo-distance.qza \
    --o-counts-by-node-tree genus-phylo-tree.qza \
    --o-counts-by-node genus-phylo-table.qza \
    --o-t2t-taxonomy genus-phylo-taxonomy.qza
    
qiime gemelli phylogenetic-rpca-with-taxonomy \
    --i-table family_table.qza \
    --i-phylogeny family_tree.qza \
    --m-taxonomy-file family_taxonomy.qza \
    --p-min-feature-count 0 \
    --p-min-sample-count 0 \
    --o-biplot family-phylo-ordination.qza \
    --o-distance-matrix family-phylo-distance.qza \
    --o-counts-by-node-tree family-phylo-tree.qza \
    --o-counts-by-node family-phylo-table.qza \
    --o-t2t-taxonomy family-phylo-taxonomy.qza
    
qiime tools export \
  --input-path species-phylo-ordination.qza \
  --output-path exports
mv exports/ordination.txt exports/species_ordination.txt 

qiime tools export \
  --input-path species-phylo-distance.qza \
  --output-path exports
mv exports/distance-matrix.tsv exports/species-distance-matrix.tsv

qiime tools export \
  --input-path genus-phylo-ordination.qza \
  --output-path exports
mv exports/ordination.txt exports/genus_ordination.txt 

qiime tools export \
  --input-path genus-phylo-distance.qza \
  --output-path exports
mv exports/distance-matrix.tsv exports/genus-distance-matrix.tsv

qiime tools export \
  --input-path family-phylo-ordination.qza \
  --output-path exports
mv exports/ordination.txt exports/family_ordination.txt 

qiime tools export \
  --input-path family-phylo-distance.qza \
  --output-path exports
mv exports/distance-matrix.tsv exports/family-distance-matrix.tsv
#scp -r vulcan:/home/robyn/AtPATH_IBD/analysis_HOMD_2024/phylo-PCA/ .
```

Save distance matrices as csv files:
```{python}
for level in ['asv', 'species', 'genus', 'family']:
  pca = pd.read_csv(analysis_folder+'phylo-PCA/exports/'+level+'-distance-matrix.tsv', sep='\t', index_col=0, header=0)
  pca.to_csv(analysis_folder+'diversity/phylo_pca_'+level+'.csv')
```

# Alpha diversity

## All

```{python}
models = ['', '', '', '']
model1 = ['A_SMK_CIG_CUR_FREQ', 'F1_SDC_AGE_CALC', 'SDC_GENDER', 'A_HS_DENTAL_VISIT_LAST', 'PM_BIOIMPED_BMI', 'PM_BIOIMPED_WEIGHT', 'PM_WAIST_AVG', 'PM_WAIST_HIP_RATIO', 'PM_STANDING_HEIGHT_AVG', 'A_SLE_LIGHT_EXP', 'NUT_VEG_DAY_QTY', 'NUT_JUICE_DAY_QTY', 'REFINED_GRAIN_SERVINGS_DAY_QTY', 'PM_BIOIMPED_FFM', 'SALT_SEASONING', 'NUTS_SEEDS_SERVINGS_PER_DAY']
model2 = ['A_SMK_CIG_CUR_FREQ', 'F1_SDC_AGE_CALC', 'SDC_GENDER', 'PM_BIOIMPED_WEIGHT', 'PM_WAIST_AVG', 'PM_WAIST_HIP_RATIO', 'PM_STANDING_HEIGHT_AVG', 'A_SLE_LIGHT_EXP', 'NUT_VEG_DAY_QTY', 'REFINED_GRAIN_SERVINGS_DAY_QTY', 'PM_BIOIMPED_FFM']
md_variables = [[], [], model1, model2]

def get_diversity(div, md, md_mod1, md_mod2, lvl):
  fig = plt.figure(figsize=(10,20))
  x = [[0, 1], [2.5, 3.5], [5, 6], [7.5, 8.5]]
  on = ['CASE_CONTROL', 'Crohn_case_control', 'UC_case_control', 'Both_case_control']
  on_lab = ['IBD', 'Crohns', 'UC', 'Both']
  names = ['IBD Controls', 'IBD Cases']
  for d in range(len(div.columns)):
    #if d > 0: continue
    ax = plt.subplot(len(div.columns),1,d+1)
    plt.sca(ax)
    ti = plt.title(div.columns[d], fontweight='bold')
    alpha_div = div.loc[:, [div.columns[d]]]
    all_case_control_plot, sig_terms = [], []
    stats_strings = []
    for g in range(len(on)):
      cases = md[md[on[g]] == 1].index.values
      controls = md[md[on[g]] == 0].index.values
      alp = alpha_div.loc[cases, :]
      x1 = np.random.normal(x[g][1], scale=0.075, size=len(cases))
      alp2 = alpha_div.loc[controls, :]
      x2 = np.random.normal(x[g][0], scale=0.075, size=len(controls))
      ax.scatter(x1, alp, color=color_dict[names[1]], alpha=0.5, s=7)
      ax.scatter(x2, alp2, color=color_dict[names[0]], alpha=0.5, s=7)
      case_control_plot = [alp2[div.columns[d]].values, alp[div.columns[d]].values]
      box = ax.boxplot(case_control_plot, positions=x[g], widths=0.6, showfliers=False)
      for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: bi = plt.setp(box[item], color='k')
      all_case_control_plot.append(case_control_plot)
      markers = ['*', '#', '^', '']
      markers = ['1', '2', '3', '4']
      sig_string = ''
      for m in range(len(models)):
        md_var_using = [on[g]]+md_variables[m]
        string = div.columns[d]+' ~ '
        for mdv in md_var_using:
          string += mdv
          if mdv != md_var_using[-1]: string += ' + '
        new_alpha = pd.concat([alp, alp2])
        if m == 0: samples_keep = new_alpha.index.values
        elif m in [1, 2]: samples_keep = [s for s in new_alpha.index.values if s in md_mod1.index.values]
        elif m == 3: samples_keep = [s for s in new_alpha.index.values if s in md_mod2.index.values]
        new_alpha = new_alpha.loc[samples_keep, :]
        new_md = md.copy(deep=True).loc[samples_keep, md_var_using]
        new_md[div.columns[d]] = new_alpha[div.columns[d]]
        model = ols(string, data=new_md).fit()
        result = sm.stats.anova_lm(model, typ=2)
        result.to_csv(analysis_folder+'stats/'+lvl+'_'+div.columns[d]+'_'+on[g]+'_model'+str(m+1)+'.csv')
        pval = result.loc[on[g], 'PR(>F)']
        if pval <= 0.05: sig_string += markers[m]+' '
      stats_strings.append(sig_string)
    high, low = float(ax.get_ylim()[1]), float(ax.get_ylim()[0])
    span = high-low
    diff = span*0.01
    high = high+diff*8
    for c in range(len(all_case_control_plot)):
      li = ax.plot([x[c][0], x[c][0], x[c][1], x[c][1]], [high-diff, high, high, high-diff], color='k')
      tx = ax.text(np.mean(x[c]), high+(diff*0.5), stats_strings[c], va='bottom', ha='center', fontsize=10)
    xtl, xtn = [], []
    for xp in range(len(x)):
      for xp2 in range(len(x[xp])):
        xtl.append(x[xp][xp2])
        if xp2 == 0: xtn.append('Control')
        else: xtn.append(on_lab[xp])
    if d == 5: xt = plt.xticks(xtl, xtn)
    else: xt = plt.xticks(xtl, [])
    yl = ax.set_ylim([low,high+span*0.3])
    yl = plt.ylabel('Diversity index')
    lg = plt.legend(handles=[Line2D([0], [0], marker='s', color='w', label=name.replace('IBD Controls', 'Control').replace('IBD Cases', 'IBD'), markerfacecolor=color_dict[name], markersize=8) for name in ['IBD Controls', 'IBD Cases']], loc='upper right', fontsize=10, ncol=2)
  return

levels = ['family', 'genus', 'species', 'asv']
for level in levels:
  diversity = pd.read_csv(analysis_folder+'diversity/alpha_diversity_'+level+'.csv', index_col=0, header=0)
  metadata = pd.read_csv(analysis_folder+'files/metadata_crohns_UC.csv', index_col=0, header=0)
  metadata_model1 = pd.read_csv(analysis_folder+'files/metadata_model1.csv', index_col=0, header=0)
  metadata_model2 = pd.read_csv(analysis_folder+'files/metadata_model2.csv', index_col=0, header=0)
  get_diversity(diversity, metadata, metadata_model1, metadata_model2, level)
  plt.savefig(analysis_folder+'figures/alpha_overall_'+level+'.png', dpi=600, bbox_inches='tight')

finished = True
```

## Combine all results

```{python}
combined_results = []
for grouping in ['', 'females_', 'females_reduced_', 'males_']:
  for level in ['family', 'genus', 'species', 'asv']:
    for metric in ['chao1', 'faith_pd', 'observed_otus', 'shannon', 'simpson', 'simpson_e']:
      for group in ['CASE_CONTROL', 'Crohn_case_control', 'UC_case_control', 'Both_case_control']:
        this_md = [grouping, level, metric, group]
        for m in [1, 2, 3, 4]:
          try:
            results = pd.read_csv(analysis_folder+'stats/'+level+'_'+grouping+metric+'_'+group+'_model'+str(m)+'.csv', index_col=0, header=0)
            f, p = results.loc[group, 'F'], results.loc[group, 'PR(>F)']
            this_md.append(f)
            this_md.append(p)
          except:
            this_md.append('NA')
            this_md.append('NA')
        combined_results.append(this_md)

combined_results = pd.DataFrame(combined_results, columns=['Grouping', 'Level', 'Metric', 'Comparison', 'Model1 F', 'Model1 p', 'Model2 F', 'Model2 p', 'Model3 F', 'Model3 p', 'Model4 F', 'Model4 p'])
combined_results.set_index('Level').to_csv(analysis_folder+'stats/alpha_diversity_all.csv')
      
```

## Alpha diversity main text plot

```{python}
level = 'asv'
diversity = pd.read_csv(analysis_folder+'diversity/alpha_diversity_'+level+'.csv', index_col=0, header=0)
metrics = ['chao1', 'faith_pd', 'observed_otus', 'shannon', 'simpson', 'simpson_e']
metric_names = ['Chao1 richness', "Faith's phylogenetic diversity", 'Observed taxa', 'Shannon diversity', "Simpson's Index of diversity", "Simpson's evenness"]
md = pd.read_csv(analysis_folder+'files/metadata_crohns_UC.csv', index_col=0, header=0)
fig = plt.figure(figsize=(15,7))
col = [0,5,10,0,5,10]
row = [0,0,0,1,1,1]
y = [[7.5, 8.5], [5, 6], [2.5, 3.5], [0, 1]]
on = ['CASE_CONTROL', 'Crohn_case_control', 'UC_case_control', 'Both_case_control']
on_lab = ['IBD', 'Crohns', 'UC', 'Both']
names = ['IBD Controls', 'IBD Cases']

for m in range(len(metrics)):
  ax1 = plt.subplot2grid((2,14),(row[m], col[m]), colspan=3)
  ax2 = plt.subplot2grid((2,14),(row[m], col[m]+3), sharey=ax1)
  alpha_div = diversity.loc[:, [metrics[m]]]
  for g in range(len(on)):
    cases = md[md[on[g]] == 1].index.values
    controls = md[md[on[g]] == 0].index.values
    alp = alpha_div.loc[cases, :]
    y1 = np.random.normal(y[g][1], scale=0.075, size=len(cases))
    alp2 = alpha_div.loc[controls, :]
    y2 = np.random.normal(y[g][0], scale=0.075, size=len(controls))
    sc = ax1.scatter(alp, y1, color=color_dict[names[1]], alpha=0.5, s=7)
    sc = ax1.scatter(alp2, y2, color=color_dict[names[0]], alpha=0.5, s=7)
    case_control_plot = [alp2[metrics[m]].values, alp[metrics[m]].values]
    box = ax1.boxplot(case_control_plot, positions=y[g], widths=0.6, showfliers=False, vert=False)
    for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: bi = plt.setp(box[item], color='k')
    model_colors = ['w', 'w', 'w', 'w']
    for mod in [1, 2, 3, 4]:
      results = pd.read_csv(analysis_folder+'stats/'+level+'_'+metrics[m]+'_'+on[g]+'_model'+str(mod)+'.csv', index_col=0, header=0)
      p = results.loc[on[g], 'PR(>F)']
      if p <= 0.05: model_colors[mod-1] = '#C0392B'
    bar = ax2.bar([0,1,2,3],[2,2,2,2], bottom=y[g][0]-0.5, color=model_colors, edgecolor='k', width=1)
  plt.sca(ax2)
  plt.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)
  xl = plt.xlim([-0.5, 3.5])
  xt = plt.xticks([0, 1, 2, 3], ['1', '2', '3', '4'])
  xl = plt.xlabel('Model\nsignificance')
  if m == 2:
    lg = plt.legend(handles=[Line2D([0], [0], marker='s', color='w', label=name.replace('IBD Controls', 'Controls').replace('IBD Cases', 'Cases'), markerfacecolor=color_dict[name], markersize=8) for name in ['IBD Controls', 'IBD Cases']], loc='upper left', bbox_to_anchor=(1.05, 1.05), fontsize=10)
  plt.sca(ax1)
  ti = plt.title(metric_names[m], fontweight='bold')
  yt = plt.yticks([8, 5.5, 3, 0.5], on_lab, fontweight='bold')
  xl = plt.xlabel('Diversity')

plt.subplots_adjust(hspace=0.4)
plt.savefig(analysis_folder+'figures/alpha_'+level+'_model_results.png', dpi=600, bbox_inches='tight')
```

Only 3 models:
```{python}
level = 'asv'
diversity = pd.read_csv(analysis_folder+'diversity/alpha_diversity_'+level+'.csv', index_col=0, header=0)
metrics = ['chao1', 'faith_pd', 'observed_otus', 'shannon', 'simpson', 'simpson_e']
metric_names = ['Chao1 richness', "Faith's phylogenetic diversity", 'Observed taxa', 'Shannon diversity', "Simpson's Index of diversity", "Simpson's evenness"]
md = pd.read_csv(analysis_folder+'files/metadata_crohns_UC.csv', index_col=0, header=0)
fig = plt.figure(figsize=(12,11))
col = [0,5,0,5,0,5]
row = [0,0,1,1,2,2]
y = [[7.5, 8.5], [5, 6], [2.5, 3.5], [0, 1]]
on = ['CASE_CONTROL', 'Crohn_case_control', 'UC_case_control']
on_lab = ['IBD', 'Crohns', 'UC', 'Both']
names = ['IBD Controls', 'IBD Cases']

for m in range(len(metrics)):
  ax1 = plt.subplot2grid((3,10),(row[m], col[m]), colspan=3)
  ax2 = plt.subplot2grid((3,10),(row[m], col[m]+3), sharey=ax1)
  alpha_div = diversity.loc[:, [metrics[m]]]
  for g in range(len(on)):
    cases = md[md[on[g]] == 1].index.values
    controls = md[md[on[g]] == 0].index.values
    alp = alpha_div.loc[cases, :]
    y1 = np.random.normal(y[g][1], scale=0.075, size=len(cases))
    alp2 = alpha_div.loc[controls, :]
    y2 = np.random.normal(y[g][0], scale=0.075, size=len(controls))
    sc = ax1.scatter(alp, y1, color=color_dict[names[1]], alpha=0.5, s=7)
    sc = ax1.scatter(alp2, y2, color=color_dict[names[0]], alpha=0.5, s=7)
    case_control_plot = [alp2[metrics[m]].values, alp[metrics[m]].values]
    box = ax1.boxplot(case_control_plot, positions=y[g], widths=0.6, showfliers=False, vert=False)
    for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: bi = plt.setp(box[item], color='k')
    model_colors = ['w', 'w', 'w']
    for mod in [1, 2, 3]:
      results = pd.read_csv(analysis_folder+'stats/'+level+'_'+metrics[m]+'_'+on[g]+'_model'+str(mod)+'.csv', index_col=0, header=0)
      p = results.loc[on[g], 'PR(>F)']
      if p <= 0.05: model_colors[mod-1] = '#C0392B'
    bar = ax2.bar([0,1,2],[2,2,2], bottom=y[g][0]-0.5, color=model_colors, edgecolor='k', width=1)
  plt.sca(ax2)
  plt.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)
  xl = plt.xlim([-0.5, 2.5])
  xt = plt.xticks([0, 1, 2], ['1', '2', '3'])
  xl = plt.xlabel('Statistics\nmodels')
  if m == 4:
    empty_marker = Line2D([0], [0], marker='s', color='w', label='', markerfacecolor='w', markeredgecolor='w', markersize=2)
    handles = [Line2D([0], [0], marker='s', color='w', label=name.replace('IBD Controls', 'Controls').replace('IBD Cases', 'Cases'), markerfacecolor=color_dict[name], markersize=8) for name in ['IBD Cases', 'IBD Controls']]
    handles.append(empty_marker), handles.append(empty_marker)
    handles.append(Line2D([0], [0], marker='s', color='w', label='Significant ($p$<0.05)', markerfacecolor='#C0392B', markersize=8, markeredgecolor='k'))
    handles.append(Line2D([0], [0], marker='s', color='w', label='Not significant', markerfacecolor='w', markersize=8, markeredgecolor='k'))
    handles.append(empty_marker), handles.append(empty_marker)
    handles.append(Line2D([0], [0], marker='s', color='w', label='Statistics models:', markerfacecolor='w', markeredgecolor='w', markersize=2))
    handles.append(Line2D([0], [0], marker='s', color='w', label='1: Cases $vs$ controls ($n$=320)', markerfacecolor='w', markeredgecolor='w', markersize=2))
    handles.append(Line2D([0], [0], marker='s', color='w', label='2: Cases $vs$ controls ($n$=238)', markerfacecolor='w', markeredgecolor='w', markersize=2))
    handles.append(Line2D([0], [0], marker='s', color='w', label='3: Cases $vs$ controls'+'\n'+'   + covariates ($n$=238)', markerfacecolor='w', markeredgecolor='w', markersize=2))
    plt.sca(ax1)
    lg = plt.legend(handles=handles, loc='upper left', bbox_to_anchor=(0, -0.3), fontsize=10, ncols=3)
  plt.sca(ax1)
  ti = plt.title(metric_names[m], fontweight='bold')
  yt = plt.yticks([8, 5.5, 3], on_lab[:3], fontweight='bold')
  xl = plt.xlabel('Diversity')

plt.subplots_adjust(hspace=0.4)
plt.savefig(analysis_folder+'figures/alpha_'+level+'_model_results_3.png', dpi=600, bbox_inches='tight')
```

### Reduced metrics and modified figure, ASV only

```{python}
level = 'asv'
diversity = pd.read_csv(analysis_folder+'diversity/alpha_diversity_'+level+'.csv', index_col=0, header=0)
metrics = ['observed_otus', 'simpson_e', 'shannon']
metric_names = ['Observed taxa', "Simpson's evenness", 'Shannon diversity']
md = pd.read_csv(analysis_folder+'files/metadata_crohns_UC.csv', index_col=0, header=0)
fig = plt.figure(figsize=(12,7))
col = [0,5,0,5]
row = [0,0,1]
y = [[7, 8.5], [3.5, 5], [0, 1.5]]
on = ['CASE_CONTROL', 'Crohn_case_control', 'UC_case_control']
on_lab = ['IBD', 'Crohns', 'UC']
names = ['IBD Controls', 'IBD Cases']

for m in range(len(metrics)):
  ax1 = plt.subplot2grid((2,14),(row[m], col[m]), colspan=3)
  ax2 = plt.subplot2grid((2,14),(row[m], col[m]+3), sharey=ax1)
  alpha_div = diversity.loc[:, [metrics[m]]]
  for g in range(len(on)):
    cases = md[md[on[g]] == 1].index.values
    controls = md[md[on[g]] == 0].index.values
    alp = alpha_div.loc[cases, :]
    y1 = np.random.normal(y[g][1], scale=0.075, size=len(cases))
    alp2 = alpha_div.loc[controls, :]
    y2 = np.random.normal(y[g][0], scale=0.075, size=len(controls))
    sc = ax1.scatter(alp, y1-0.4, color=color_dict[names[1]], alpha=0.5, s=7)
    sc = ax1.scatter(alp2, y2-0.4, color=color_dict[names[0]], alpha=0.5, s=7)
    #sc = ax1.scatter(alp, y1, color=color_dict[names[1]], alpha=0.5, s=7)
    #sc = ax1.scatter(alp2, y2, color=color_dict[names[0]], alpha=0.5, s=7)
    case_control_plot = [alp2[metrics[m]].values, alp[metrics[m]].values]
    #box = ax1.boxplot(case_control_plot, positions=y[g], widths=0.6, showfliers=False, vert=False)
    box = ax1.boxplot(case_control_plot, positions=y[g], widths=0.4, showfliers=False, vert=False)
    for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: bi = plt.setp(box[item], color='k')
    vp = ax1.violinplot(case_control_plot, points=500, positions=y[g], showmeans=False, showextrema=False, showmedians=False, vert=False, side='high', widths=1)
    for idx, b in enumerate(vp['bodies']):
      b.set_color(color_dict[names[idx]])
      b.set_alpha(0.6)
    model_colors = ['w', 'w', 'w']
    for mod in [1, 2, 3]:
      results = pd.read_csv(analysis_folder+'stats/'+level+'_'+metrics[m]+'_'+on[g]+'_model'+str(mod)+'.csv', index_col=0, header=0)
      p = results.loc[on[g], 'PR(>F)']
      if p <= 0.05: model_colors[mod-1] = '#C0392B'
    bar = ax2.bar([0,1,2],[2.5,2.5,2.5], bottom=np.mean(y[g])-1.25, color=model_colors, edgecolor='k', width=1)
  plt.sca(ax2)
  plt.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)
  xl = plt.xlim([-0.5, 2.5])
  xt = plt.xticks([0, 1, 2], ['1', '2', '3'])
  xl = plt.xlabel('Statistics\nmodels')
  if m == 2:
    empty_marker = Line2D([0], [0], marker='s', color='w', label='', markerfacecolor='w', markeredgecolor='w', markersize=2)
    handles = [Line2D([0], [0], marker='s', color='w', label=name.replace('IBD Controls', 'Controls').replace('IBD Cases', 'Cases'), markerfacecolor=color_dict[name], markersize=8) for name in ['IBD Cases', 'IBD Controls']]
    handles.append(empty_marker), handles.append(empty_marker)
    handles.append(Line2D([0], [0], marker='s', color='w', label='Significant ($p$<0.05)', markerfacecolor='#C0392B', markersize=8, markeredgecolor='k'))
    handles.append(Line2D([0], [0], marker='s', color='w', label='Not significant', markerfacecolor='w', markersize=8, markeredgecolor='k'))
    handles.append(empty_marker), handles.append(empty_marker)
    handles.append(Line2D([0], [0], marker='s', color='w', label='Statistics models:', markerfacecolor='w', markeredgecolor='w', markersize=2))
    handles.append(Line2D([0], [0], marker='s', color='w', label='1: Cases $vs$ controls ($n$=320)', markerfacecolor='w', markeredgecolor='w', markersize=2))
    handles.append(Line2D([0], [0], marker='s', color='w', label='2: Cases $vs$ controls ($n$=238)', markerfacecolor='w', markeredgecolor='w', markersize=2))
    handles.append(Line2D([0], [0], marker='s', color='w', label='3: Cases $vs$ controls'+'\n'+'   + covariates ($n$=238)', markerfacecolor='w', markeredgecolor='w', markersize=2))
    lg = plt.legend(handles=handles, loc='upper left', bbox_to_anchor=(2, 1.05), fontsize=10)
  plt.sca(ax1)
  ti = plt.title(metric_names[m], fontweight='bold')
  yt = plt.yticks([np.mean(n) for n in y], on_lab, fontweight='bold')
  xl = plt.xlabel('Diversity')
  yl = plt.ylim([-0.7, 9.2])
# 
plt.subplots_adjust(hspace=0.4)
plt.savefig(analysis_folder+'figures/alpha_simple_violin_'+level+'_model_results.png', dpi=600, bbox_inches='tight')
```

## Females/males

```{python}
models = ['', '', '', '']
model1 = ['A_SMK_CIG_CUR_FREQ', 'F1_SDC_AGE_CALC', 'SDC_GENDER', 'A_HS_DENTAL_VISIT_LAST', 'PM_BIOIMPED_BMI', 'PM_BIOIMPED_WEIGHT', 'PM_WAIST_AVG', 'PM_WAIST_HIP_RATIO', 'PM_STANDING_HEIGHT_AVG', 'A_SLE_LIGHT_EXP', 'NUT_VEG_DAY_QTY', 'NUT_JUICE_DAY_QTY', 'REFINED_GRAIN_SERVINGS_DAY_QTY', 'PM_BIOIMPED_FFM', 'SALT_SEASONING', 'NUTS_SEEDS_SERVINGS_PER_DAY']
model2 = ['A_SMK_CIG_CUR_FREQ', 'F1_SDC_AGE_CALC', 'SDC_GENDER', 'PM_BIOIMPED_WEIGHT', 'PM_WAIST_AVG', 'PM_WAIST_HIP_RATIO', 'PM_STANDING_HEIGHT_AVG', 'A_SLE_LIGHT_EXP', 'NUT_VEG_DAY_QTY', 'REFINED_GRAIN_SERVINGS_DAY_QTY', 'PM_BIOIMPED_FFM']
md_variables = [[], [], model1, model2]

def get_diversity(div, md, md_mod1, md_mod2, lvl, gender):
  fig = plt.figure(figsize=(10,20))
  x = [[0, 1], [2.5, 3.5], [5, 6], [7.5, 8.5]]
  on = ['CASE_CONTROL', 'Crohn_case_control', 'UC_case_control', 'Both_case_control']
  on_lab = ['IBD', 'Crohns', 'UC', 'Both']
  names = ['IBD Controls', 'IBD Cases']
  for d in range(len(div.columns)):
    #if d > 0: continue
    ax = plt.subplot(len(div.columns),1,d+1)
    plt.sca(ax)
    ti = plt.title(div.columns[d], fontweight='bold')
    alpha_div = div.loc[:, [div.columns[d]]]
    all_case_control_plot, sig_terms = [], []
    stats_strings = []
    for g in range(len(on)):
      cases = md[md[on[g]] == 1].index.values
      controls = md[md[on[g]] == 0].index.values
      alp = alpha_div.loc[cases, :]
      x1 = np.random.normal(x[g][1], scale=0.075, size=len(cases))
      alp2 = alpha_div.loc[controls, :]
      x2 = np.random.normal(x[g][0], scale=0.075, size=len(controls))
      ax.scatter(x1, alp, color=color_dict[names[1]], alpha=0.5, s=7)
      ax.scatter(x2, alp2, color=color_dict[names[0]], alpha=0.5, s=7)
      case_control_plot = [alp2[div.columns[d]].values, alp[div.columns[d]].values]
      box = ax.boxplot(case_control_plot, positions=x[g], widths=0.6, showfliers=False)
      for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: bi = plt.setp(box[item], color='k')
      all_case_control_plot.append(case_control_plot)
      markers = ['*', '#', '^', '']
      markers = ['1', '2', '3', '4']
      sig_string = ''
      for m in range(len(models)):
        md_var_using = [on[g]]+md_variables[m]
        string = div.columns[d]+' ~ '
        for mdv in md_var_using:
          string += mdv
          if mdv != md_var_using[-1]: string += ' + '
        new_alpha = pd.concat([alp, alp2])
        if m == 0: samples_keep = new_alpha.index.values
        elif m in [1, 2]: samples_keep = [s for s in new_alpha.index.values if s in md_mod1.index.values]
        elif m == 3: samples_keep = [s for s in new_alpha.index.values if s in md_mod2.index.values]
        new_alpha = new_alpha.loc[samples_keep, :]
        new_md = md.copy(deep=True).loc[samples_keep, md_var_using]
        new_md[div.columns[d]] = new_alpha[div.columns[d]]
        try:
          model = ols(string, data=new_md).fit()
          result = sm.stats.anova_lm(model, typ=2)
          result.to_csv(analysis_folder+'stats/'+lvl+'_'+gender+'_'+div.columns[d]+'_'+on[g]+'_model'+str(m+1)+'.csv')
          pval = result.loc[on[g], 'PR(>F)']
          if pval <= 0.05: sig_string += markers[m]+' '
        except:
          do_nothing = True
      stats_strings.append(sig_string)
    high, low = float(ax.get_ylim()[1]), float(ax.get_ylim()[0])
    span = high-low
    diff = span*0.01
    high = high+diff*8
    for c in range(len(all_case_control_plot)):
      li = ax.plot([x[c][0], x[c][0], x[c][1], x[c][1]], [high-diff, high, high, high-diff], color='k')
      tx = ax.text(np.mean(x[c]), high+(diff*0.5), stats_strings[c], va='bottom', ha='center', fontsize=10)
    xtl, xtn = [], []
    for xp in range(len(x)):
      for xp2 in range(len(x[xp])):
        xtl.append(x[xp][xp2])
        if xp2 == 0: xtn.append('Control')
        else: xtn.append(on_lab[xp])
    if d == 5: xt = plt.xticks(xtl, xtn)
    else: xt = plt.xticks(xtl, [])
    yl = ax.set_ylim([low,high+span*0.3])
    yl = plt.ylabel('Diversity index')
    lg = plt.legend(handles=[Line2D([0], [0], marker='s', color='w', label=name.replace('IBD Controls', 'Control').replace('IBD Cases', 'IBD'), markerfacecolor=color_dict[name], markersize=8) for name in ['IBD Controls', 'IBD Cases']], loc='upper right', fontsize=10, ncol=2)
  return

levels = ['family', 'genus', 'species', 'asv']
for level in levels:
  diversity = pd.read_csv(analysis_folder+'diversity/alpha_diversity_'+level+'.csv', index_col=0, header=0)
  metadata = pd.read_csv(analysis_folder+'files/metadata_crohns_UC.csv', index_col=0, header=0)
  metadata_model1 = pd.read_csv(analysis_folder+'files/metadata_model1.csv', index_col=0, header=0)
  metadata_model2 = pd.read_csv(analysis_folder+'files/metadata_model2.csv', index_col=0, header=0)
  metadata = metadata.loc[metadata['SDC_GENDER'] == 2]
  metadata_model1_keeping = [s for s in metadata_model1.index.values if s in metadata.index.values]
  metadata_model2_keeping = [s for s in metadata_model2.index.values if s in metadata.index.values]
  metadata_model1 = metadata_model1.loc[metadata_model1_keeping, :]
  metadata_model2 = metadata_model2.loc[metadata_model2_keeping, :]
  get_diversity(diversity, metadata, metadata_model1, metadata_model2, level, 'females')
  plt.savefig(analysis_folder+'figures/alpha_females_'+level+'.png', dpi=600, bbox_inches='tight')
#   
# for level in levels:
#   diversity = pd.read_csv(analysis_folder+'diversity/alpha_diversity_'+level+'.csv', index_col=0, header=0)
#   metadata = pd.read_csv(analysis_folder+'files/metadata_crohns_UC.csv', index_col=0, header=0)
#   metadata_model1 = pd.read_csv(analysis_folder+'files/metadata_model1.csv', index_col=0, header=0)
#   metadata_model2 = pd.read_csv(analysis_folder+'files/metadata_model2.csv', index_col=0, header=0)
#   metadata = metadata.loc[metadata['SDC_GENDER'] == 1]
#   metadata_model1_keeping = [s for s in metadata_model1.index.values if s in metadata.index.values]
#   metadata_model2_keeping = [s for s in metadata_model2.index.values if s in metadata.index.values]
#   metadata_model1 = metadata_model1.loc[metadata_model1_keeping, :]
#   metadata_model2 = metadata_model2.loc[metadata_model2_keeping, :]
#   get_diversity(diversity, metadata, metadata_model1, metadata_model2, level, 'males')
#   plt.savefig(analysis_folder+'figures/alpha_males_'+level+'.png', dpi=600, bbox_inches='tight')
 
with open(analysis_folder+'files/female_reduced.list', 'rb') as f:
  females_all, females_model1 = pickle.load(f)

for level in levels:
  diversity = pd.read_csv(analysis_folder+'diversity/alpha_diversity_'+level+'.csv', index_col=0, header=0)
  metadata = pd.read_csv(analysis_folder+'files/metadata_crohns_UC.csv', index_col=0, header=0)
  metadata_model1 = pd.read_csv(analysis_folder+'files/metadata_model1.csv', index_col=0, header=0)
  metadata_model2 = pd.read_csv(analysis_folder+'files/metadata_model2.csv', index_col=0, header=0)
  metadata = metadata.loc[metadata['SDC_GENDER'] == 2]
  metadata = metadata.loc[females_all, :]
  metadata_model1_keeping = [s for s in metadata_model1.index.values if s in metadata.index.values]
  metadata_model2_keeping = [s for s in metadata_model2.index.values if s in metadata.index.values]
  metadata_model1 = metadata_model1.loc[metadata_model1_keeping, :]
  metadata_model2 = metadata_model2.loc[metadata_model2_keeping, :]
  metadata_model1 = metadata_model1.loc[females_model1, :]
  metadata_model2 = metadata_model2.loc[females_model1, :]
  get_diversity(diversity, metadata, metadata_model1, metadata_model2, level, 'females_reduced')
  plt.savefig(analysis_folder+'figures/alpha_females_reduced_'+level+'.png', dpi=600, bbox_inches='tight')

finished = True
```

## Alpha diversity main text plot males/females

```{python}
level = 'family'
gender = 'males'
diversity = pd.read_csv(analysis_folder+'diversity/alpha_diversity_'+level+'.csv', index_col=0, header=0)
metrics = ['chao1', 'faith_pd', 'observed_otus', 'shannon', 'simpson', 'simpson_e']
metric_names = ['Chao1 richness', "Faith's phylogenetic diversity", 'Observed taxa', 'Shannon diversity', "Simpson's Index of diversity", "Simpson's evenness"]
md = pd.read_csv(analysis_folder+'files/metadata_crohns_UC.csv', index_col=0, header=0)
if 'females' in gender: md = md.loc[md['SDC_GENDER'] == 2]
elif 'males' in gender: md = md.loc[md['SDC_GENDER'] == 1]
with open(analysis_folder+'files/female_reduced.list', 'rb') as f:
  females_all, females_model1 = pickle.load(f)
if 'reduced' in gender:
  md = md.loc[females_all, :]
fig = plt.figure(figsize=(15,7))
col = [0,5,10,0,5,10]
row = [0,0,0,1,1,1]
y = [[7.5, 8.5], [5, 6], [2.5, 3.5], [0, 1]]
on = ['CASE_CONTROL', 'Crohn_case_control', 'UC_case_control', 'Both_case_control']
on_lab = ['IBD', 'Crohns', 'UC', 'Both']
names = ['IBD Controls', 'IBD Cases']

for m in range(len(metrics)):
  ax1 = plt.subplot2grid((2,14),(row[m], col[m]), colspan=3)
  ax2 = plt.subplot2grid((2,14),(row[m], col[m]+3), sharey=ax1)
  alpha_div = diversity.loc[md.index.values, [metrics[m]]]
  for g in range(len(on)):
    cases = md[md[on[g]] == 1].index.values
    controls = md[md[on[g]] == 0].index.values
    alp = alpha_div.loc[cases, :]
    y1 = np.random.normal(y[g][1], scale=0.075, size=len(cases))
    alp2 = alpha_div.loc[controls, :]
    y2 = np.random.normal(y[g][0], scale=0.075, size=len(controls))
    sc = ax1.scatter(alp, y1, color=color_dict[names[1]], alpha=0.5, s=7)
    sc = ax1.scatter(alp2, y2, color=color_dict[names[0]], alpha=0.5, s=7)
    case_control_plot = [alp2[metrics[m]].values, alp[metrics[m]].values]
    box = ax1.boxplot(case_control_plot, positions=y[g], widths=0.6, showfliers=False, vert=False)
    for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: bi = plt.setp(box[item], color='k')
    model_colors = ['w', 'w', 'w', 'w']
    for mod in [1, 2, 3, 4]:
      try:
        results = pd.read_csv(analysis_folder+'stats/'+level+'_'+gender+'_'+metrics[m]+'_'+on[g]+'_model'+str(mod)+'.csv', index_col=0, header=0)
        p = results.loc[on[g], 'PR(>F)']
        if p <= 0.05: model_colors[mod-1] = '#C0392B'
      except:
        do_nothing = True
    bar = ax2.bar([0,1,2,3],[2,2,2,2], bottom=y[g][0]-0.5, color=model_colors, edgecolor='k', width=1)
  plt.sca(ax2)
  plt.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)
  xl = plt.xlim([-0.5, 3.5])
  xt = plt.xticks([0, 1, 2, 3], ['1', '2', '3', '4'])
  xl = plt.xlabel('Model\nsignificance')
  if m == 2:
    lg = plt.legend(handles=[Line2D([0], [0], marker='s', color='w', label=name.replace('IBD Controls', 'Controls').replace('IBD Cases', 'Cases'), markerfacecolor=color_dict[name], markersize=8) for name in ['IBD Controls', 'IBD Cases']], loc='upper left', bbox_to_anchor=(1.05, 1.05), fontsize=10)
  plt.sca(ax1)
  ti = plt.title(metric_names[m], fontweight='bold')
  yt = plt.yticks([8, 5.5, 3, 0.5], on_lab, fontweight='bold')
  xl = plt.xlabel('Diversity index')

plt.subplots_adjust(hspace=0.4)
plt.savefig(analysis_folder+'figures/alpha_'+gender+'_'+level+'_model_results.png', dpi=600, bbox_inches='tight')
```

# Beta diversity

## Stats tests

```{python}
matrices = []
metadata = []
names = []
models = []

model1 = ['A_SMK_CIG_CUR_FREQ', 'F1_SDC_AGE_CALC', 'SDC_GENDER', 'A_HS_DENTAL_VISIT_LAST', 'PM_BIOIMPED_BMI', 'PM_BIOIMPED_WEIGHT', 'PM_WAIST_AVG', 'PM_WAIST_HIP_RATIO', 'PM_STANDING_HEIGHT_AVG', 'A_SLE_LIGHT_EXP', 'NUT_VEG_DAY_QTY', 'NUT_JUICE_DAY_QTY', 'REFINED_GRAIN_SERVINGS_DAY_QTY', 'PM_BIOIMPED_FFM', 'SALT_SEASONING', 'NUTS_SEEDS_SERVINGS_PER_DAY']
model2 = ['A_SMK_CIG_CUR_FREQ', 'F1_SDC_AGE_CALC', 'SDC_GENDER', 'PM_BIOIMPED_WEIGHT', 'PM_WAIST_AVG', 'PM_WAIST_HIP_RATIO', 'PM_STANDING_HEIGHT_AVG', 'A_SLE_LIGHT_EXP', 'NUT_VEG_DAY_QTY', 'REFINED_GRAIN_SERVINGS_DAY_QTY', 'PM_BIOIMPED_FFM']
md_variables = [[], [], model1, model2, [], [], model1, model2, [], [], model1, model2, [], [], model1, model2]
levels = ['family', 'genus', 'species', 'asv']
distances = ['braycurtis', 'clr', 'rclr', 'unweighted_unifrac', 'weighted_unifrac', 'phylo_pca']
data_split = ['CASE_CONTROL', 'Crohn_case_control', 'UC_case_control', 'Both_case_control']
md = pd.read_csv(analysis_folder+'files/metadata_crohns_UC.csv', index_col=0, header=0)
md_mod1 = pd.read_csv(analysis_folder+'files/metadata_model1.csv', index_col=0, header=0)
md_mod2 = pd.read_csv(analysis_folder+'files/metadata_model2.csv', index_col=0, header=0)
with open(analysis_folder+'files/female_reduced.list', 'rb') as f:
  females_all, females_model1 = pickle.load(f)
md_females = md.loc[md['SDC_GENDER'] == 2]
md_females_reduced = md.loc[females_all, :]
md_females_mod1 = md_mod1.loc[md_mod1['SDC_GENDER'] == 2]
md_females_mod2 = md_mod2.loc[md_mod2['SDC_GENDER'] == 2]
md_females_reduced_mod1 = md_mod1.loc[females_model1, :]
md_females_reduced_mod2 = md_mod2.loc[females_model1, :]
md_males = md.loc[md['SDC_GENDER'] == 1]
md_males_mod1 = md_mod1.loc[md_mod1['SDC_GENDER'] == 1]
md_males_mod2 = md_mod2.loc[md_mod2['SDC_GENDER'] == 1]
md_using = [md, md_mod1, md_mod1, md_mod2, md_females, md_females_mod1, md_females_mod1, md_females_mod2, md_females_reduced, md_females_reduced_mod1, md_females_reduced_mod1, md_females_reduced_mod2, md_males, md_males_mod1, md_males_mod1, md_males_mod2]
names_adding = ['', '', '', '', 'females_', 'females_', 'females_', 'females_', 'females_reduced_', 'females_reduced_', 'females_reduced_', 'females_reduced_', 'males_', 'males_', 'males_', 'males_']
model_num = [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3]

for level in levels: 
  #if level != levels[0]: continue
  for dist in distances:
    #if dist != distances[0]: continue
    #if dist == 'phylo_pca' and level != 'asv': continue
    this_dist = pd.read_csv(analysis_folder+'diversity/'+dist+'_'+level+'.csv', index_col=0, header=0)
    for ds in data_split:
      for m in range(len(md_using)):
        mdu = md_using[m]
        this_md_case = mdu[mdu[ds] == 1].index.values
        this_md_control = mdu[mdu[ds] == 0].index.values
        samples = list(this_md_case)+list(this_md_control)
        this_md = mdu.copy(deep=True).loc[samples, :]
        matrices.append(this_dist.loc[samples, samples])
        metadata.append(this_md.loc[:, [ds]+md_variables[m]])
        string = ''
        for v in [ds]+md_variables[m]:
          if v != ds: string += '*'
          string += 'md$'+v
        models.append(string)
        names.append(dist+'_'+names_adding[m]+level+'_'+ds+'_model'+str(model_num[m]))

finished = True
#md[md[on[g]] == 1].index.values
```

PERMANOVA:
```{R}
names = py$names
tables = py$matrices
metadata = py$metadata
stats_models = py$models

saveRDS(names, paste(py$analysis_folder, 'vulcan_stats_objects/names.rds', sep=''))
saveRDS(tables, paste(py$analysis_folder, 'vulcan_stats_objects/tables.rds', sep=''))
saveRDS(metadata, paste(py$analysis_folder, 'vulcan_stats_objects/metadata.rds', sep=''))
saveRDS(stats_models, paste(py$analysis_folder, 'vulcan_stats_objects/stats_models.rds', sep=''))

```

Copy:
```{bash}
scp -r vulcan_stats_objects kronos:/home/robyn/vulcan_copy/

#scp -r robyn@kronos.pharmacology.dal.ca:/home/robyn/vulcan_copy/vulcan_stats_objects/ .
#initially tried on kronos, but need to wait for vulcan as vegan doesn't have adonis - must be an older version
#trying again on kronos

cd AtPATH_IBD/
mkdir analysis_HOMD_2024
cd analysis_HOMD_2024
mv /home/robyn/vulcan_copy/vulcan_stats_objects/ .
mkdir stats
```

Kronos:
```{bash, eval=FALSE}
conda create -n R-update
conda activate R-update
conda update -n base conda
conda install conda-forge::r-base
```

Test:
```{R}
# R
# install.packages('vegan')
#cran mirror 74
library(vegan)

names = readRDS('vulcan_stats_objects/names.rds')
tables = readRDS('vulcan_stats_objects/tables.rds')
metadata = readRDS('vulcan_stats_objects/metadata.rds')
stats_models = readRDS('vulcan_stats_objects/stats_models.rds')

for (a in 1:length(names)) {
  if (file.exists(paste('stats/permanova_', names[a], '.csv', sep=''))) {
    print(paste(names[a], 'exists'))
  } else {
    print(names[a])
    mat_df = as.data.frame(tables[a])
    mat = data.matrix(mat_df)
    colnames(mat) = rownames(mat)
    md = metadata[a][[1]]
    sm = eval(parse(text=paste("mat_df ~ ", stats_models[a])))
    permanova <- adonis2(sm, data=mat_df, parallel=12)
    write.csv(permanova, paste('stats/permanova_', names[a], '.csv', sep=''))
  }
}

```

Kronos with parallel:
```{R}
install.packages("vegan")
#cran mirror: 64
install.packages("foreach")
install.packages("doParallel")
#install.packages("palmerpenguins")
#install.packages("tidyverse")
#install.packages("kableExtra")

#install.packages("ranger")

library(vegan)
library(foreach)
library(doParallel)

names = readRDS('vulcan_stats_objects/names.rds')
tables = readRDS('vulcan_stats_objects/tables.rds')
metadata = readRDS('vulcan_stats_objects/metadata.rds')
stats_models = readRDS('vulcan_stats_objects/stats_models.rds')

my.cluster <- parallel::makeCluster(
  12, 
  type = "PSOCK"
  )

registerDoParallel(cores=12)
#Rgui.exe --max-ppsize=5000000 #this didn't work. I've also seen rstudio.exe which I didn't try, just used the options command below
options(expressions = 5e5) #note that this is the max allowed - tried doing 5e6 and got an error


foreach (a = 3:length(names)) %dopar% {
  if (file.exists(paste('stats/permanova_', names[a], '.csv', sep=''))) {
    n = names[a]
    print(paste(names[a], 'exists'))
  } else {
    print(names[a])
    mat_df = as.data.frame(tables[a])
    mat = data.matrix(mat_df)
    colnames(mat) = rownames(mat)
    md = metadata[a][[1]]
    sm = eval(parse(text=paste("mat_df ~ ", stats_models[a])))
    permanova <- adonis2(sm, data=mat_df, parallel=12)
    table = permanova$aov.tab
    write.csv(table, paste('stats/permanova_', names[a], '.csv', sep=''))
  }
}

parallel::stopCluster(cl = my.cluster)
```
Didn't ever all work. Copied across to vulcan and resuming there.

Vulcan with parallel:
```{R}
#note that this is what actually worked!!
#scp -r vulcan_stats_objects vulcan:/home/robyn/AtPATH_IBD/analysis_HOMD_2024/

library(vegan) #version 2.5-6
library(foreach)
library(doParallel)

names = readRDS('vulcan_stats_objects/names.rds')
tables = readRDS('vulcan_stats_objects/tables.rds')
metadata = readRDS('vulcan_stats_objects/metadata.rds')
stats_models = readRDS('vulcan_stats_objects/stats_models.rds')

my.cluster <- parallel::makeCluster(
  24, 
  type = "PSOCK"
  )

foreach (a = 1:length(names)) %dopar% {
  if (file.exists(paste('stats/permanova_', names[a], '.csv', sep=''))) {
    n = names[a]
  } else {
    if  (grepl("females", names[a], fixed = TRUE) & grepl("model2", names[a], fixed = TRUE)) {
    print(names[a])
    # mat_df = as.data.frame(tables[a])
    # mat = data.matrix(mat_df)
    # colnames(mat) = rownames(mat)
    # md = metadata[a][[1]]
    # sm = eval(parse(text=paste("mat_df ~ ", stats_models[a])))
    # permanova <- adonis(sm, data=mat_df, parallel=12)
    # table = permanova$aov.tab
    # write.csv(table, paste('stats/permanova_', names[a], '.csv', sep=''))
  }
  }
}

for (a in 1:length(names)) {
  if (file.exists(paste('stats/permanova_', names[a], '.csv', sep=''))) {
    n = names[a]
  } else {
    if  (grepl("females", names[a], fixed = TRUE) & grepl("model2", names[a], fixed = TRUE)) {
    mat_df = as.data.frame(tables[a])
    mat = data.matrix(mat_df)
    colnames(mat) = rownames(mat)
    colnames(mat_df) = rownames(mat_df)
    md = metadata[a][[1]]
    sm = eval(parse(text=paste("mat_df ~ ", stats_models[a])))
    print(names[a])
    print(sm)
    permanova <- adonis(sm, data=mat_df, parallel=12)
    table = permanova$aov.tab
    write.csv(table, paste('stats/permanova_', names[a], '.csv', sep=''))
  }
  }
}

quit()
```
It still isn't running things. Will try running this locally, too.

```{bash, eval=FALSE}
#scp -r stats/ robyn@kronos.pharmacology.dal.ca:/home/robyn/vulcan_copy/
#scp -r kronos:/home/robyn/vulcan_copy/stats/ .
scp -r vulcan:/home/robyn/AtPATH_IBD/analysis_HOMD_2024/stats/ .
```

Local running for the last few results that haven't finished:
```{R}
library(vegan) #version 2.5-6
#library(foreach)
#library(doParallel)

names = readRDS(paste(py$analysis_folder, 'vulcan_stats_objects/names.rds', sep=''))
tables = readRDS(paste(py$analysis_folder, 'vulcan_stats_objects/tables.rds', sep=''))
metadata = readRDS(paste(py$analysis_folder, 'vulcan_stats_objects/metadata.rds', sep=''))
stats_models = readRDS(paste(py$analysis_folder, 'vulcan_stats_objects/stats_models.rds', sep=''))

for (a in 1:length(names)) {
  if (file.exists(paste(py$analysis_folder, 'stats/permanova_', names[a], '.csv', sep=''))) {
    n = names[a]
  } else {
    if  (grepl("females", names[a], fixed = TRUE) & grepl("model2", names[a], fixed = TRUE)) {
    mat_df = as.data.frame(tables[a])
    mat = data.matrix(mat_df)
    colnames(mat) = rownames(mat)
    md = metadata[a][[1]]
    sm = eval(parse(text=paste("mat_df ~ ", stats_models[a])))
    print(names[a])
    print(sm)
    permanova <- adonis2(sm, data=mat_df, parallel=12)
    table = permanova$aov.tab
    write.csv(table, paste(py$analysis_folder, 'stats/permanova_', names[a], '.csv', sep=''))
  }
  }
}

```

Try to troubleshoot:
```{python}
#names, metadata, models
samples = []
for a in range(len(names)):
  if not os.path.exists(analysis_folder+'stats/permanova_'+names[a]+'.csv'):
    models[a] = models[a].replace('*md$SDC_GENDER', '')
    case_control = models[a].split('*')[0].replace('md$', '')
    #print(metadata[a][case_control].values)
    for col in metadata[a].columns:
      na_rows = metadata[a][metadata[a][col].isnull()]
      if na_rows.shape[0] > 0:
        rows = na_rows.index.values
        samples.append(rows[0])
    #metadata[a].isnull().values.any()

samples = set(samples)
print(samples)
for sample in samples:
  print(md.loc[sample, :])
finished = True
```

Save again and try to run again:
```{R}
names = py$names
tables = py$matrices
metadata = py$metadata
stats_models = py$models

saveRDS(names, paste(py$analysis_folder, 'vulcan_stats_objects/names.rds', sep=''))
saveRDS(tables, paste(py$analysis_folder, 'vulcan_stats_objects/tables.rds', sep=''))
saveRDS(metadata, paste(py$analysis_folder, 'vulcan_stats_objects/metadata.rds', sep=''))
saveRDS(stats_models, paste(py$analysis_folder, 'vulcan_stats_objects/stats_models.rds', sep=''))

library(vegan)

for (a in 1:length(names)) {
  if (file.exists(paste(py$analysis_folder, 'stats/permanova_', names[a], '.csv', sep=''))) {
    n = names[a]
  } else {
    if  (grepl("females", names[a], fixed = TRUE) & grepl("model2", names[a], fixed = TRUE)) {
    mat_df = as.data.frame(tables[a])
    colnames(mat_df) = rownames(mat_df)
    #mat = data.matrix(mat_df)
    #colnames(mat) = rownames(mat)
    md = metadata[a][[1]]
    sm = eval(parse(text=paste("mat_df ~ ", stats_models[a])))
    print(names[a])
    print(sm)
    permanova <- adonis2(sm, data=mat_df, parallel=12)
    table = permanova$aov.tab
    write.csv(table, paste(py$analysis_folder, 'stats/permanova_', names[a], '.csv', sep=''))
  }
  }
}
```
Didn't need to use this in the end as figured out that it was an issue when making the data frames for stats. I was using the wrong ones for only the females + model2. Instead of full, model 1, model 1, model 2, I was using full, model 1, model 2, model 2 for females only. All others were fine! Made these again, uploaded to vulcan and ran again.

### Rerun these with matched cases

Also investigate whether there is an impact of +/* for the

```{python}
matrices = []
metadata = []
names = []
models = []

model1 = ['CASEID', 'A_SMK_CIG_CUR_FREQ', 'F1_SDC_AGE_CALC', 'SDC_GENDER', 'A_HS_DENTAL_VISIT_LAST', 'PM_BIOIMPED_BMI', 'PM_BIOIMPED_WEIGHT', 'PM_WAIST_AVG', 'PM_WAIST_HIP_RATIO', 'PM_STANDING_HEIGHT_AVG', 'A_SLE_LIGHT_EXP', 'NUT_VEG_DAY_QTY', 'NUT_JUICE_DAY_QTY', 'REFINED_GRAIN_SERVINGS_DAY_QTY', 'PM_BIOIMPED_FFM', 'SALT_SEASONING', 'NUTS_SEEDS_SERVINGS_PER_DAY']
model2 = ['CASEID', 'A_SMK_CIG_CUR_FREQ', 'F1_SDC_AGE_CALC', 'SDC_GENDER', 'PM_BIOIMPED_WEIGHT', 'PM_WAIST_AVG', 'PM_WAIST_HIP_RATIO', 'PM_STANDING_HEIGHT_AVG', 'A_SLE_LIGHT_EXP', 'NUT_VEG_DAY_QTY', 'REFINED_GRAIN_SERVINGS_DAY_QTY', 'PM_BIOIMPED_FFM']
md_variables = [['CASEID'], ['CASEID'], model1, model2, ['CASEID'], ['CASEID'], model1, model2, ['CASEID'], ['CASEID'], model1, model2, ['CASEID'], ['CASEID'], model1, model2]
levels = ['family', 'genus', 'species', 'asv']
distances = ['braycurtis', 'clr', 'rclr', 'unweighted_unifrac', 'weighted_unifrac', 'phylo_pca']
data_split = ['CASE_CONTROL', 'Crohn_case_control', 'UC_case_control', 'Both_case_control']
md = pd.read_csv(analysis_folder+'files/metadata_crohns_UC.csv', index_col=0, header=0)
md_mod1 = pd.read_csv(analysis_folder+'files/metadata_model1.csv', index_col=0, header=0)
md_mod2 = pd.read_csv(analysis_folder+'files/metadata_model2.csv', index_col=0, header=0)
with open(analysis_folder+'files/female_reduced.list', 'rb') as f:
  females_all, females_model1 = pickle.load(f)
md_females = md.loc[md['SDC_GENDER'] == 2]
md_females_reduced = md.loc[females_all, :]
md_females_mod1 = md_mod1.loc[md_mod1['SDC_GENDER'] == 2]
md_females_mod2 = md_mod2.loc[md_mod2['SDC_GENDER'] == 2]
md_females_reduced_mod1 = md_mod1.loc[females_model1, :]
md_females_reduced_mod2 = md_mod2.loc[females_model1, :]
md_males = md.loc[md['SDC_GENDER'] == 1]
md_males_mod1 = md_mod1.loc[md_mod1['SDC_GENDER'] == 1]
md_males_mod2 = md_mod2.loc[md_mod2['SDC_GENDER'] == 1]
md_using = [md, md_mod1, md_mod1, md_mod2, md_females, md_females_mod1, md_females_mod1, md_females_mod2, md_females_reduced, md_females_reduced_mod1, md_females_reduced_mod1, md_females_reduced_mod2, md_males, md_males_mod1, md_males_mod1, md_males_mod2]
names_adding = ['', '', '', '', 'females_', 'females_', 'females_', 'females_', 'females_reduced_', 'females_reduced_', 'females_reduced_', 'females_reduced_', 'males_', 'males_', 'males_', 'males_']
model_num = [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3]

for level in levels: 
  if level != levels[3]: continue
  for dist in distances:
    #if dist != distances[0]: continue
    #if dist == 'phylo_pca' and level != 'asv': continue
    this_dist = pd.read_csv(analysis_folder+'diversity/'+dist+'_'+level+'.csv', index_col=0, header=0)
    for ds in data_split:
      for m in range(len(md_using)):
        mdu = md_using[m]
        this_md_case = mdu[mdu[ds] == 1].index.values
        this_md_control = mdu[mdu[ds] == 0].index.values
        samples = list(this_md_case)+list(this_md_control)
        this_md = mdu.copy(deep=True).loc[samples, :]
        matrices.append(this_dist.loc[samples, samples])
        metadata.append(this_md.loc[:, [ds]+md_variables[m]])
        string = ''
        for v in [ds]+md_variables[m]:
          if v != ds: string += '*'
          string += 'md$'+v
        models.append(string.replace('*md$CASEID', ''))
        names.append(dist+'_'+names_adding[m]+level+'_'+ds+'_model'+str(model_num[m]))
        
models_plus = []
for model in models:
  models_plus.append(model.replace('*', '+'))

finished = True
#md[md[on[g]] == 1].index.values
```

```{R}
tables = py$matrices
metadata = py$metadata
names = py$names
stats_models = py$models

saveRDS(tables, paste(py$analysis_folder, 'vulcan_stats_objects/tables_caseid.rds', sep=''))
saveRDS(metadata, paste(py$analysis_folder, 'vulcan_stats_objects/metadata_caseid.rds', sep=''))
saveRDS(names, paste(py$analysis_folder, 'vulcan_stats_objects/names_caseid.rds', sep=''))
saveRDS(stats_models, paste(py$analysis_folder, 'vulcan_stats_objects/models_caseid.rds', sep=''))
```

```{bash}
scp vulcan_stats_objects/*caseid.rds vulcan:/home/robyn/AtPATH_IBD/analysis_HOMD_2024/vulcan_stats_objects/
```

Run PERMANOVA (upload to vulcan):
```{r}
library(vegan) #version 2.6.4 (vulcan)
#library(foreach)
#library(doParallel)

names = readRDS(paste('vulcan_stats_objects/names_caseid.rds', sep=''))
tables = readRDS(paste('vulcan_stats_objects/tables_caseid.rds', sep=''))
metadata = readRDS(paste('vulcan_stats_objects/metadata_caseid.rds', sep=''))
stats_models = readRDS(paste('vulcan_stats_objects/models_caseid.rds', sep=''))

options(expressions = 5e5)

for (a in 1:4) {
  print(names[a])
  mat_df = as.data.frame(tables[a])
  mat = data.matrix(mat_df)
  colnames(mat) = rownames(mat)
  md = metadata[a][[1]]
  new_model = gsub("\\*", " + ", stats_models[a])
  sm = eval(parse(text=paste("mat_df ~ ", stats_models[a])))
  # if (file.exists(paste('stats/permanova_caseid_plus_', names[a], '.csv', sep=''))) {
  #   n = names[a]
  # } else {
  #   permanova <- adonis2(sm, data=mat_df, parallel=24, strata=md$CASEID)
  #   #table = permanova$aov.tab
  #   write.csv(permanova, paste('stats/permanova_caseid_plus_', names[a], '.csv', sep=''))
  # }
  if (file.exists(paste('stats/permanova_plus_', names[a], '.csv', sep=''))) {
    n = names[a]
  } else {
    permanova <- adonis2(sm, data=mat_df, parallel=24)#, strata=md$CASEID)
    #table = permanova$aov.tab
    write.csv(permanova, paste('stats/permanova_plus_', names[a], '.csv', sep=''))
  }
}

# a = 3
# mat_df = as.data.frame(tables[a])
# mat = data.matrix(mat_df)
# colnames(mat) = rownames(mat)
# md = metadata[a][[1]]
# sm = eval(parse(text=paste("mat_df ~ ", stats_models[a])))
# permanova <- adonis2(sm, data=mat_df, parallel=12, strata=md$CASEID)
# write.csv(permanova, paste(py$analysis_folder, 'stats/permanova_caseid_', names[a], '.csv', sep=''))
```



## Summarise PERMANOVA results

```{python}
# matrices = []
# metadata = []
# names = []
# models = []
# model1 = ['A_SMK_CIG_CUR_FREQ', 'F1_SDC_AGE_CALC', 'SDC_GENDER', 'A_HS_DENTAL_VISIT_LAST', 'PM_BIOIMPED_BMI', 'PM_BIOIMPED_WEIGHT', 'PM_WAIST_AVG', 'PM_WAIST_HIP_RATIO', 'PM_STANDING_HEIGHT_AVG', 'A_SLE_LIGHT_EXP', 'NUT_VEG_DAY_QTY', 'NUT_JUICE_DAY_QTY', 'REFINED_GRAIN_SERVINGS_DAY_QTY', 'PM_BIOIMPED_FFM', 'SALT_SEASONING', 'NUTS_SEEDS_SERVINGS_PER_DAY']
# model2 = ['A_SMK_CIG_CUR_FREQ', 'F1_SDC_AGE_CALC', 'SDC_GENDER', 'PM_BIOIMPED_WEIGHT', 'PM_WAIST_AVG', 'PM_WAIST_HIP_RATIO', 'PM_STANDING_HEIGHT_AVG', 'A_SLE_LIGHT_EXP', 'NUT_VEG_DAY_QTY', 'REFINED_GRAIN_SERVINGS_DAY_QTY', 'PM_BIOIMPED_FFM']
# md_variables = [[], [], model1, model2]
levels = ['family', 'genus', 'species', 'asv']
distances = ['braycurtis', 'clr', 'rclr', 'unweighted_unifrac', 'weighted_unifrac', 'phylo_pca']
data_split = ['CASE_CONTROL', 'Crohn_case_control', 'UC_case_control', 'Both_case_control']
# md = pd.read_csv(analysis_folder+'files/metadata_crohns_UC.csv', index_col=0, header=0)
# md_mod1 = pd.read_csv(analysis_folder+'files/metadata_model1.csv', index_col=0, header=0)
# md_mod2 = pd.read_csv(analysis_folder+'files/metadata_model2.csv', index_col=0, header=0)
# md_using = [md, md_mod1, md_mod1, md_mod2]
# md_using = [md, md_mod1, md_mod1, md_mod2, md_females, md_females_mod1, md_females_mod2, md_females_mod2, md_females_reduced, md_females_reduced_mod1, md_females_reduced_mod1, md_females_reduced_mod2, md_males, md_males_mod1, md_males_mod1, md_males_mod2]
names_adding = ['', '', '', '', 'females_', 'females_', 'females_', 'females_', 'females_reduced_', 'females_reduced_', 'females_reduced_', 'females_reduced_', 'males_', 'males_', 'males_', 'males_']
model_num = [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3]

columns = ['Level', 'Metric', 'Comparison']
for n in range(len(names_adding)):
  string = names_adding[n].replace('_', ' ')+' '+'Model'+str(model_num[n]+1)
  columns.append(string.replace('  ', ' ')+ ' R2')
  columns.append(string.replace('  ', ' ')+ ' p')

combined_results = []
for level in levels:
  for dist in distances:
    #if dist == 'phylo_pca' and level != 'asv': continue
    for ds in data_split:
      this_md = [level, dist, ds]
      for m in range(len(names_adding)):
        try:
          results = pd.read_csv(folder+'analysis_2024/stats/permanova_'+dist+'_'+names_adding[m]+level+'_'+ds+'_model'+str(model_num[m])+'.csv', index_col=0, header=0)
          r2 = results.loc['md$'+ds, 'R2']
          p = results.loc['md$'+ds, 'Pr(>F)']
          this_md.append(r2)
          this_md.append(p)
          if m in [2, 3]:
            p_sig = results.loc[results['Pr(>F)'] <= 0.05]
            if p_sig.shape[0] > 0:
              print(dist+'_'+level+'_'+ds+'_model'+str(model_num[m]), p_sig)
        except:
          this_md.append('NA')
          this_md.append('NA')
      combined_results.append(this_md)

combined_results = pd.DataFrame(combined_results, columns=columns)
combined_results.set_index('Level').to_csv(folder+'analysis_2024/stats/permanova_all_combined.csv')

finished = True
```

## Plot figures

```{python}
def plot_beta_diversity(div, lvl):
  dist_mat = pd.read_csv(analysis_folder+'diversity/'+div+'_'+lvl+'.csv', index_col=0, header=0)
  md = pd.read_csv(analysis_folder+'files/metadata_crohns_UC.csv', index_col=0, header=0)
  fig = plt.figure(figsize=(15,15))
  axes = [[plt.subplot2grid((20,20),(0,0), colspan=6, rowspan=6), plt.subplot2grid((20,20),(0,6), colspan=2, rowspan=6), plt.subplot2grid((20,20),(6,0), colspan=6, rowspan=2)], 
  [plt.subplot2grid((20,20),(0,9), colspan=6, rowspan=6), plt.subplot2grid((20,20),(0,15), colspan=2, rowspan=6), plt.subplot2grid((20,20),(6,9), colspan=6, rowspan=2)],
  [plt.subplot2grid((20,20),(9,0), colspan=6, rowspan=6), plt.subplot2grid((20,20),(9,6), colspan=2, rowspan=6), plt.subplot2grid((20,20),(15,0), colspan=6, rowspan=2)],
  [plt.subplot2grid((20,20),(9,9), colspan=6, rowspan=6), plt.subplot2grid((20,20),(9,15), colspan=2, rowspan=6), plt.subplot2grid((20,20),(15,9), colspan=6, rowspan=2)]]
  on = ['CASE_CONTROL', 'Crohn_case_control', 'UC_case_control', 'Both_case_control']
  on_lab = ['IBD', 'Crohns', 'UC', 'Both']
  names = ['IBD Controls', 'IBD Cases']
  for a in range(len(axes)):
    axes[a][0].set_title(on_lab[a]+' $vs$ controls', fontweight='bold', fontsize=12)
    cases = list(md[md[on[a]] == 1].index.values)
    controls = list(md[md[on[a]] == 0].index.values)
    this_dm = dist_mat.loc[cases+controls, cases+controls]
    pcoa_results = ordination.pcoa(this_dm)
    PC1, PC2 = pcoa_results.samples.loc[:, 'PC1'].values, pcoa_results.samples.loc[:, 'PC2'].values
    prop_explain1, prop_explain2 = pcoa_results.proportion_explained[0], pcoa_results.proportion_explained[1]
    groups_x, groups_y = {0:[], 1:[]}, {0:[], 1:[]}
    for b in range(len(this_dm.index)):
      cc = int(md.loc[this_dm.index[b], on[a]])
      sc = axes[a][0].scatter(PC1[b], PC2[b], color=color_dict[names[cc]], alpha=0.5, edgecolor='gray')
      sc = axes[a][1].scatter(np.random.normal(cc, 0.12, 1)[0], PC2[b], color=color_dict[names[cc]], alpha=0.5, edgecolor='gray')
      sc = axes[a][2].scatter(PC1[b], np.random.normal(cc, 0.12, 1)[0], color=color_dict[names[cc]], alpha=0.5, edgecolor='gray')
      groups_x[cc].append(PC1[b])
      groups_y[cc].append(PC2[b])
    stats_string = ''
    for c in range(4):
      stats = pd.read_csv(analysis_folder+'stats/permanova_'+div+'_'+lvl+'_'+on[a]+'_model'+str(c)+'.csv', index_col=0, header=0)
      try:
        r2, p = stats.iloc[0,4], stats.iloc[0,5]
      except:
        r2, p = stats.iloc[0,3], stats.iloc[0,4]
      stats_string += '('+str(c+1)+') R$^{2}$='+str(round(r2,2))+', $p$='+str(round(p,3))
      if c != 3: stats_string += '\n'
    st = axes[a][0].text(0.97, 0.97, stats_string, ha='right', va='top', transform=axes[a][0].transAxes, bbox=dict(boxstyle='round', facecolor='white', alpha=0.7), linespacing=0.8)
    box = axes[a][1].boxplot([groups_y[0], groups_y[1]], positions=[0,1], widths=0.6, showfliers=False)
    for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: bi = plt.setp(box[item], color='k')
    box = axes[a][2].boxplot([groups_x[0], groups_x[1]], positions=[0,1], widths=0.6, vert=False, showfliers=False)
    for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: bi = plt.setp(box[item], color='k')
    ce = confidence_ellipse(np.asarray(groups_x[0]), np.asarray(groups_y[0]), ax=axes[a][0], edgecolor=color_dict[names[0]])
    ce = confidence_ellipse(np.asarray(groups_x[1]), np.asarray(groups_y[1]), ax=axes[a][0], edgecolor=color_dict[names[1]])
    plt.sca(axes[a][2])
    xt = plt.xlabel('PCOA1 ('+str(round(prop_explain1*100,2))+'%)', fontweight='bold')
    yt = plt.yticks([0, 1], ['Control', on_lab[a]], rotation=90, va='center')
    plt.sca(axes[a][1])
    xt = plt.xticks([0, 1], ['Control', on_lab[a]])
    yt = plt.yticks([])
    plt.sca(axes[a][0])
    yt = plt.ylabel('PCOA2 ('+str(round(prop_explain2*100,2))+'%)', fontweight='bold')
    xt = plt.xticks([])
  return
```

### Plot all

```{python}
for diversity in ['braycurtis', 'clr', 'rclr', 'weighted_unifrac', 'unweighted_unifrac', 'phylo_pca']:
  if diversity != 'phylo_pca': continue
  for level in ['asv', 'species', 'genus', 'family']:
    #if diversity == 'phylo_pca' and level != 'asv': continue
    plot_beta_diversity(diversity, level)
    plt.subplots_adjust(hspace=0.8, wspace=0.8)
    plt.savefig(analysis_folder+'figures/beta_'+diversity+'_'+level+'.png', bbox_inches='tight', dpi=600)

finished = True
```

## Reduced plot

Also includes the ordination for Phylo-RPCA!! Manually saving the results from /Users/robynwright/Dropbox/Langille_Lab_postdoc/AtPATH_IBD/analysis_2024/phylo-PCA/exports/asv_ordination.txt
Saving to: phylo_pca_asv_ordination.csv

```{python}
div = 'phylo_pca'
lvl = 'asv'

pcoa_results = pd.read_csv(analysis_folder+'diversity/phylo_pca_asv_ordination.csv', index_col=0, header=0)
md = pd.read_csv(analysis_folder+'files/metadata_crohns_UC.csv', index_col=0, header=0)
fig = plt.figure(figsize=(7,7))
axes = [plt.subplot2grid((10,10),(0,0), colspan=6, rowspan=6), plt.subplot2grid((10,10),(0,6), colspan=4, rowspan=6), plt.subplot2grid((10,10),(6,0), colspan=6, rowspan=4)]
on = ['CASE_CONTROL', 'Crohn_case_control', 'UC_case_control']
on_lab = ['IBD', 'Crohns', 'UC']
names = ['IBD Controls', 'IBD Cases']

ti = axes[0].set_title(on_lab[0]+' $vs$ controls', fontweight='bold', fontsize=12)
cases = list(md[md[on[0]] == 1].index.values)
controls = list(md[md[on[0]] == 0].index.values)
#this_dm = dist_mat.loc[cases+controls, cases+controls]
#pcoa_results = ordination.pcoa(this_dm)
pcoa_results = pcoa_results.loc[cases+controls, :]
PC1, PC2 = pcoa_results.loc[:, 'PC1'].values, pcoa_results.loc[:, 'PC2'].values
prop_explain1, prop_explain2 = 0.596346630872256, 0.3403835285446023
groups_x, groups_y = {0:[], 1:[]}, {0:[], 1:[]}
crohns_x, crohns_y = {0:[], 1:[]}, {0:[], 1:[]}
uc_x, uc_y = {0:[], 1:[]}, {0:[], 1:[]}
for b in range(len(pcoa_results.index)):
  cc = int(md.loc[pcoa_results.index[b], on[0]])
  sc = axes[0].scatter(PC1[b], PC2[b], color=color_dict[names[cc]], alpha=0.5, edgecolor='gray', s=50)
  groups_x[cc].append(PC1[b]), groups_y[cc].append(PC2[b])
  try:
    crohns = int(md.loc[pcoa_results.index[b], on[1]])
    crohns_x[crohns].append(PC1[b]), crohns_y[crohns].append(PC2[b])
  except:
    skip = True
  try:
    uc = int(md.loc[pcoa_results.index[b], on[2]])
    uc_x[uc].append(PC1[b]), uc_y[uc].append(PC2[b])
  except:
    skip = True

yvals = [groups_y, crohns_y, uc_y]
xvals = [groups_x, crohns_x, uc_x]
xv = [[1, 0], [3.5, 2.5], [6, 5]]
yv = [[5, 6], [2.5, 3.5], [0, 1]]
for y in range(len(yvals)):
  sc = axes[1].scatter(np.random.normal(xv[y][0], 0.12, len(yvals[y][0])), yvals[y][0], color=color_dict[names[0]], alpha=0.5, edgecolor='gray')
  sc = axes[1].scatter(np.random.normal(xv[y][1], 0.12, len(yvals[y][1])), yvals[y][1], color=color_dict[names[1]], alpha=0.5, edgecolor='gray')
  box = axes[1].boxplot([yvals[y][0], yvals[y][1]], positions=xv[y], widths=0.6, showfliers=False)
  for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: bi = plt.setp(box[item], color='k')
  sc = axes[2].scatter(xvals[y][0], np.random.normal(yv[y][0], 0.12, len(xvals[y][0])), color=color_dict[names[0]], alpha=0.5, edgecolor='gray')
  sc = axes[2].scatter(xvals[y][1], np.random.normal(yv[y][1], 0.12, len(xvals[y][1])), color=color_dict[names[1]], alpha=0.5, edgecolor='gray')
  box = axes[2].boxplot([xvals[y][0], xvals[y][1]], positions=yv[y], widths=0.6, showfliers=False, vert=False)
  for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: bi = plt.setp(box[item], color='k')

stats_string = ''
for c in range(3):
  stats_string += on_lab[c]+': '
  for d in range(3):
    stats = pd.read_csv(analysis_folder+'stats/permanova_'+div+'_'+lvl+'_'+on[c]+'_model'+str(d)+'.csv', index_col=0, header=0)
    try:
      r2, p = stats.iloc[0,4], stats.iloc[0,5]
    except:
      r2, p = stats.iloc[0,3], stats.iloc[0,4]
    stats_string += '('+str(d+1)+') $p$='+str(round(p,3))
    if d != 2: stats_string += '; '
  if c != 2: stats_string += '\n'

empty_marker = Line2D([0], [0], marker='s', color='w', label='', markerfacecolor='w', markeredgecolor='w', markersize=2)
handles = [Line2D([0], [0], marker='s', color='w', label=name.replace('IBD Controls', 'Controls').replace('IBD Cases', 'Cases'), markerfacecolor=color_dict[name], markersize=8) for name in ['IBD Cases', 'IBD Controls']]
# handles.append(empty_marker)
# handles.append(Line2D([0], [0], marker='s', color='w', label='Statistics models:', markerfacecolor='w', markeredgecolor='w', markersize=2))
# handles.append(Line2D([0], [0], marker='s', color='w', label='1: Cases $vs$ controls ($n$=320)', markerfacecolor='w', markeredgecolor='w', markersize=2))
# handles.append(Line2D([0], [0], marker='s', color='w', label='2: Cases $vs$ controls ($n$=238)', markerfacecolor='w', markeredgecolor='w', markersize=2))
# handles.append(Line2D([0], [0], marker='s', color='w', label='3: Cases $vs$ controls'+'\n'+'   + covariates ($n$=238)', markerfacecolor='w', markeredgecolor='w', markersize=2))
plt.sca(axes[1])
lg = plt.legend(handles=handles, loc='upper left', bbox_to_anchor=(0, -0.1), fontsize=10)

text_box = 'Statistics models:\n1: Cases $vs$ controls ($n$=320)\n2: Cases $vs$ controls ($n$=238)\n3: Cases $vs$ controls + covariates ($n$=238)\n\n'
text_box += stats_string
#axes[1].text(0, -0.3, text_box, ha='left', va='top', transform=axes[1].transAxes, bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))#, linespacing=0.9)


ce = confidence_ellipse(np.asarray(groups_x[0]), np.asarray(groups_y[0]), ax=axes[0], edgecolor=color_dict[names[0]])
ce = confidence_ellipse(np.asarray(groups_x[1]), np.asarray(groups_y[1]), ax=axes[0], edgecolor=color_dict[names[1]])
plt.sca(axes[2])
xt = plt.xlabel('PCA1 ('+str(round(prop_explain1*100,2))+'%)', fontweight='bold')
yt = plt.yticks([5.5, 3, 0.5], ['IBD','Crohns', "UC"], fontweight='bold')
xl = plt.xlim(axes[0].get_xlim())
plt.sca(axes[1])
#xt = plt.xticks([0, 1], ['Control', on_lab[a]])
xt = plt.xticks([0.5, 3, 5.5], ['IBD','Crohns', "UC"], fontweight='bold')
yt = plt.yticks([])
yl = plt.ylim(axes[0].get_ylim())
plt.sca(axes[0])
yt = plt.ylabel('PCA2 ('+str(round(prop_explain2*100,2))+'%)', fontweight='bold')
xt = plt.xticks([])


# 
plt.savefig(analysis_folder+'figures/beta_simple_'+div+'_'+lvl+'.png', bbox_inches='tight', dpi=600)

```

```{python}

# def plot_beta_diversity(div, lvl):
#   dist_mat = pd.read_csv(analysis_folder+'diversity/'+div+'_'+lvl+'.csv', index_col=0, header=0)
#   md = pd.read_csv(analysis_folder+'files/metadata_crohns_UC.csv', index_col=0, header=0)
#   fig = plt.figure(figsize=(15,15))
#   axes = [[plt.subplot2grid((20,20),(0,0), colspan=6, rowspan=6), plt.subplot2grid((20,20),(0,6), colspan=2, rowspan=6), plt.subplot2grid((20,20),(6,0), colspan=6, rowspan=2)], 
#   [plt.subplot2grid((20,20),(0,9), colspan=6, rowspan=6), plt.subplot2grid((20,20),(0,15), colspan=2, rowspan=6), plt.subplot2grid((20,20),(6,9), colspan=6, rowspan=2)],
#   [plt.subplot2grid((20,20),(9,0), colspan=6, rowspan=6), plt.subplot2grid((20,20),(9,6), colspan=2, rowspan=6), plt.subplot2grid((20,20),(15,0), colspan=6, rowspan=2)],
#   [plt.subplot2grid((20,20),(9,9), colspan=6, rowspan=6), plt.subplot2grid((20,20),(9,15), colspan=2, rowspan=6), plt.subplot2grid((20,20),(15,9), colspan=6, rowspan=2)]]
#   on = ['CASE_CONTROL', 'Crohn_case_control', 'UC_case_control', 'Both_case_control']
#   on_lab = ['IBD', 'Crohns', 'UC', 'Both']
#   names = ['IBD Controls', 'IBD Cases']
#   for a in range(len(axes)):
#     axes[a][0].set_title(on_lab[a]+' $vs$ controls', fontweight='bold', fontsize=12)
#     cases = list(md[md[on[a]] == 1].index.values)
#     controls = list(md[md[on[a]] == 0].index.values)
#     this_dm = dist_mat.loc[cases+controls, cases+controls]
#     pcoa_results = ordination.pcoa(this_dm)
#     PC1, PC2 = pcoa_results.samples.loc[:, 'PC1'].values, pcoa_results.samples.loc[:, 'PC2'].values
#     prop_explain1, prop_explain2 = pcoa_results.proportion_explained[0], pcoa_results.proportion_explained[1]
#     groups_x, groups_y = {0:[], 1:[]}, {0:[], 1:[]}
#     for b in range(len(this_dm.index)):
#       cc = int(md.loc[this_dm.index[b], on[a]])
#       sc = axes[a][0].scatter(PC1[b], PC2[b], color=color_dict[names[cc]], alpha=0.5, edgecolor='gray')
#       sc = axes[a][1].scatter(np.random.normal(cc, 0.12, 1)[0], PC2[b], color=color_dict[names[cc]], alpha=0.5, edgecolor='gray')
#       sc = axes[a][2].scatter(PC1[b], np.random.normal(cc, 0.12, 1)[0], color=color_dict[names[cc]], alpha=0.5, edgecolor='gray')
#       groups_x[cc].append(PC1[b])
#       groups_y[cc].append(PC2[b])
#     stats_string = ''
#     for c in range(4):
#       stats = pd.read_csv(analysis_folder+'stats/permanova_'+div+'_'+lvl+'_'+on[a]+'_model'+str(c)+'.csv', index_col=0, header=0)
#       try:
#         r2, p = stats.iloc[0,4], stats.iloc[0,5]
#       except:
#         r2, p = stats.iloc[0,3], stats.iloc[0,4]
#       stats_string += '('+str(c+1)+') R$^{2}$='+str(round(r2,2))+', $p$='+str(round(p,3))
#       if c != 3: stats_string += '\n'
#     st = axes[a][0].text(0.97, 0.97, stats_string, ha='right', va='top', transform=axes[a][0].transAxes, bbox=dict(boxstyle='round', facecolor='white', alpha=0.7), linespacing=0.8)
#     box = axes[a][1].boxplot([groups_y[0], groups_y[1]], positions=[0,1], widths=0.6, showfliers=False)
#     for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: bi = plt.setp(box[item], color='k')
#     box = axes[a][2].boxplot([groups_x[0], groups_x[1]], positions=[0,1], widths=0.6, vert=False, showfliers=False)
#     for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: bi = plt.setp(box[item], color='k')
#     ce = confidence_ellipse(np.asarray(groups_x[0]), np.asarray(groups_y[0]), ax=axes[a][0], edgecolor=color_dict[names[0]])
#     ce = confidence_ellipse(np.asarray(groups_x[1]), np.asarray(groups_y[1]), ax=axes[a][0], edgecolor=color_dict[names[1]])
#     plt.sca(axes[a][2])
#     xt = plt.xlabel('PCOA1 ('+str(round(prop_explain1*100,2))+'%)', fontweight='bold')
#     yt = plt.yticks([0, 1], ['Control', on_lab[a]], rotation=90, va='center')
#     plt.sca(axes[a][1])
#     xt = plt.xticks([0, 1], ['Control', on_lab[a]])
#     yt = plt.yticks([])
#     plt.sca(axes[a][0])
#     yt = plt.ylabel('PCOA2 ('+str(round(prop_explain2*100,2))+'%)', fontweight='bold')
#     xt = plt.xticks([])
#   return
```


# Differential abundance testing

Need to run all of the different tools with all of the different models, probably just at genus level? But with different case control groups and all/females/males/females reduced

```{python}
raw, rare, ancom = [], [], []
metadata = []
names = []
models = []
models_physeq = []

model1 = ['A_SMK_CIG_CUR_FREQ', 'F1_SDC_AGE_CALC', 'SDC_GENDER', 'A_HS_DENTAL_VISIT_LAST', 'PM_BIOIMPED_BMI', 'PM_BIOIMPED_WEIGHT', 'PM_WAIST_AVG', 'PM_WAIST_HIP_RATIO', 'PM_STANDING_HEIGHT_AVG', 'A_SLE_LIGHT_EXP', 'NUT_VEG_DAY_QTY', 'NUT_JUICE_DAY_QTY', 'REFINED_GRAIN_SERVINGS_DAY_QTY', 'PM_BIOIMPED_FFM', 'SALT_SEASONING', 'NUTS_SEEDS_SERVINGS_PER_DAY']
model2 = ['A_SMK_CIG_CUR_FREQ', 'F1_SDC_AGE_CALC', 'SDC_GENDER', 'PM_BIOIMPED_WEIGHT', 'PM_WAIST_AVG', 'PM_WAIST_HIP_RATIO', 'PM_STANDING_HEIGHT_AVG', 'A_SLE_LIGHT_EXP', 'NUT_VEG_DAY_QTY', 'REFINED_GRAIN_SERVINGS_DAY_QTY', 'PM_BIOIMPED_FFM']
md_variables = [[], [], model1, model2, [], [], model1, model2, [], [], model1, model2, [], [], model1, model2]
# levels = ['family', 'genus', 'species', 'asv']
# distances = ['braycurtis', 'clr', 'rclr', 'unweighted_unifrac', 'weighted_unifrac', 'phylo_pca']
data_split = ['CASE_CONTROL', 'Crohn_case_control', 'UC_case_control', 'Both_case_control']
md = pd.read_csv(analysis_folder+'files/metadata_crohns_UC.csv', index_col=0, header=0)
md_mod1 = pd.read_csv(analysis_folder+'files/metadata_model1.csv', index_col=0, header=0)
md_mod2 = pd.read_csv(analysis_folder+'files/metadata_model2.csv', index_col=0, header=0)
with open(analysis_folder+'files/female_reduced.list', 'rb') as f:
  females_all, females_model1 = pickle.load(f)
md_females = md.loc[md['SDC_GENDER'] == 2]
md_females_reduced = md.loc[females_all, :]
md_females_mod1 = md_mod1.loc[md_mod1['SDC_GENDER'] == 2]
md_females_mod2 = md_mod2.loc[md_mod2['SDC_GENDER'] == 2]
md_females_reduced_mod1 = md_mod1.loc[females_model1, :]
md_females_reduced_mod2 = md_mod2.loc[females_model1, :]
md_males = md.loc[md['SDC_GENDER'] == 1]
md_males_mod1 = md_mod1.loc[md_mod1['SDC_GENDER'] == 1]
md_males_mod2 = md_mod2.loc[md_mod2['SDC_GENDER'] == 1]
md_using = [md, md_mod1, md_mod1, md_mod2, md_females, md_females_mod1, md_females_mod1, md_females_mod2, md_females_reduced, md_females_reduced_mod1, md_females_reduced_mod1, md_females_reduced_mod2, md_males, md_males_mod1, md_males_mod1, md_males_mod2]
names_adding = ['', '', '', '', 'females_', 'females_', 'females_', 'females_', 'females_reduced_', 'females_reduced_', 'females_reduced_', 'females_reduced_', 'males_', 'males_', 'males_', 'males_']
model_num = [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3]

full_ft_raw = pd.read_csv(analysis_folder+'files/genus_table.csv', index_col=0, header=0)
full_ft_rare = pd.read_csv(analysis_folder+'files/genus_table_rare.csv', index_col=0, header=0)
count = 0
structural_zeroes = []
for ds in data_split:
  for m in range(len(md_using)):
    #if count > 2: break
    mdu = md_using[m]
    this_md_case = mdu[mdu[ds] == 1].index.values
    this_md_control = mdu[mdu[ds] == 0].index.values
    samples = list(this_md_case)+list(this_md_control)
    this_md = mdu.copy(deep=True).loc[samples, :]
    col_keeping = []
    for col in md_variables[m]:
      unique_vals = list(set(this_md[col].values))
      if len(unique_vals) > 1:
        col_keeping.append(col)
    #this_md = this_md.loc[:, col_keeping]
    #check for structural zeroes
    raw_rename = full_ft_raw.copy(deep=True)
    raw_rename = raw_rename.loc[:, samples]
    rename_cc = {}
    for row in this_md.index.values:
      rename_cc[row] = this_md.loc[row, ds]
    raw_rename = raw_rename.rename(columns=rename_cc)
    raw_rename = raw_rename.groupby(by=raw_rename.columns, axis=1).max()
    drop = raw_rename[raw_rename.min(axis=1) == 0]
    raw.append(full_ft_raw.loc[:, samples])
    rare.append(full_ft_rare.loc[:, samples])
    if drop.shape[0] != 0:
      ancom.append(full_ft_raw.loc[:, samples].drop(drop.index.values, axis=0))
      structural_zeroes.append(names_adding[m]+ds+'_model'+str(model_num[m]))
    else:
      ancom.append(full_ft_raw.loc[:, samples])
    metadata.append(this_md.loc[:, [ds]+col_keeping])
    string = ''
    string2 = ''
    for v in [ds]+col_keeping:
      if v != ds: 
        string += '*'
        string2 += '*'
      string += 'md$'+v
      string2 += v
    models.append(string)
    models_physeq.append(string2)
    names.append(names_adding[m]+ds+'_model'+str(model_num[m]))
    count += 1

# num = 6
# print(metadata[num], names[num], models[num], models_physeq[num])

with open(analysis_folder+'files/structural_zeroes.csv', 'w') as f:
  for name in structural_zeroes:
    w = f.write(name+'\n')

finished = True
```

Read into R:
```{R}
names = py$names
raw = py$raw
rare = py$rare
ancom = py$ancom
metadata = py$metadata
stats_models = py$models
stats_models_physeq = py$models_physeq

saveRDS(names, paste(py$analysis_folder, 'differential_abundance/names.rds', sep=''))
saveRDS(raw, paste(py$analysis_folder, 'differential_abundance/raw.rds', sep=''))
saveRDS(ancom, paste(py$analysis_folder, 'differential_abundance/ancom.rds', sep=''))
saveRDS(rare, paste(py$analysis_folder, 'differential_abundance/rare.rds', sep=''))
saveRDS(metadata, paste(py$analysis_folder, 'differential_abundance/metadata.rds', sep=''))
saveRDS(stats_models, paste(py$analysis_folder, 'differential_abundance/stats_models.rds', sep=''))
saveRDS(stats_models_physeq, paste(py$analysis_folder, 'differential_abundance/stats_models_physeq.rds', sep=''))

names = readRDS(paste(py$analysis_folder, 'differential_abundance/names.rds', sep=''))
raw = readRDS(paste(py$analysis_folder, 'differential_abundance/raw.rds', sep=''))
rare = readRDS(paste(py$analysis_folder, 'differential_abundance/rare.rds', sep=''))
ancom = readRDS(paste(py$analysis_folder, 'differential_abundance/ancom.rds', sep=''))
metadata = readRDS(paste(py$analysis_folder, 'differential_abundance/metadata.rds', sep=''))
stats_models = readRDS(paste(py$analysis_folder, 'differential_abundance/stats_models.rds', sep=''))
stats_models_physeq = readRDS(paste(py$analysis_folder, 'differential_abundance/stats_models_physeq.rds', sep=''))
#copied these into AtPATH_IBD/analysis_2024/vulcan_stats_objects/differential_abundance_June25_2024/ - copied to vulcan and copied into AtPATH_IBD/analysis_HOMD_2024/differential_abundance/
```


MaAslin2:
```{R}
#Initial run:
#can't easily add interactions in Maaslin, so for now just doing the case/control comparisons
# for (a in 1:length(names)) {
#   if (grepl("model2", names[a], fixed = TRUE) | grepl("model3", names[a], fixed = TRUE)) {
#     n = names[a]
#   } else {
#     print(names[a])
#     ft_rare = as.data.frame(rare[a])
#     fname = paste(py$analysis_folder, "differential_abundance/maaslin2_", names[a], sep="")
#     md = data.frame(metadata[a][[1]])
#     colnames(ft_rare) = rownames(md)
#     feat_table = data.frame(t(ft_rare), check.rows=F, check.names=F, stringsAsFactors=F)
#     results_all <- Maaslin2(feat_table, md, fname, transform = "AST", fixed_effects = c(stats_models_physeq[a]), reference=paste(stats_models_physeq[a], "0", sep=','), standardize = FALSE, plot_heatmap = T, plot_scatter = T)
#   }
# }

#with other models:
for (a in 1:length(names)) {
  if (file.exists(paste(py$analysis_folder, 'differential_abundance/maaslin2_', names[a], '/all_results.tsv', sep=''))) {
    n = names[a]
  } else {
    print(names[a])
    ft_rare = as.data.frame(rare[a])
    fname = paste(py$analysis_folder, "differential_abundance/maaslin2_", names[a], sep="")
    md = data.frame(metadata[a][[1]])
    colnames(ft_rare) = rownames(md)
    feat_table = data.frame(t(ft_rare), check.rows=F, check.names=F, stringsAsFactors=F)
    if (grepl("Crohn_case_control", names[a], fixed=TRUE)) {
      cc_str = "Crohn_case_control"
    } else if (grepl("UC_case_control", names[a], fixed=TRUE)) {
      cc_str = "UC_case_control"
    } else if (grepl("Both_case_control", names[a], fixed=TRUE)) {
      cc_str = "Both_case_control"
    } else {
      cc_str = "CASE_CONTROL"
    }
    if (grepl("model2", names[a], fixed = TRUE)) {
      results_all <- Maaslin2(feat_table, md, fname, transform = "AST", fixed_effects = c(cc_str, 'A_SMK_CIG_CUR_FREQ', 'F1_SDC_AGE_CALC', 'SDC_GENDER', 'A_HS_DENTAL_VISIT_LAST', 'PM_BIOIMPED_BMI', 'PM_BIOIMPED_WEIGHT', 'PM_WAIST_AVG', 'PM_WAIST_HIP_RATIO', 'PM_STANDING_HEIGHT_AVG', 'A_SLE_LIGHT_EXP', 'NUT_VEG_DAY_QTY', 'NUT_JUICE_DAY_QTY', 'REFINED_GRAIN_SERVINGS_DAY_QTY', 'PM_BIOIMPED_FFM', 'SALT_SEASONING', 'NUTS_SEEDS_SERVINGS_PER_DAY'), standardize = FALSE, plot_heatmap = T, plot_scatter = T)
    } else {
      results_all <- Maaslin2(feat_table, md, fname, transform = "AST", fixed_effects = c(cc_str, 'A_SMK_CIG_CUR_FREQ', 'F1_SDC_AGE_CALC', 'SDC_GENDER', 'PM_BIOIMPED_WEIGHT', 'PM_WAIST_AVG', 'PM_WAIST_HIP_RATIO', 'PM_STANDING_HEIGHT_AVG', 'A_SLE_LIGHT_EXP', 'NUT_VEG_DAY_QTY', 'REFINED_GRAIN_SERVINGS_DAY_QTY', 'PM_BIOIMPED_FFM'), standardize = FALSE, plot_heatmap = T, plot_scatter = T)
    }
  }
}
```

ANCOM:
```{R}
for (a in 1:length(names)) {
  if (file.exists(paste(py$analysis_folder, 'differential_abundance/ancom_', names[a], '.rds', sep=''))) {
    n = names[a]
  } else if (grepl("model2", names[a], fixed = TRUE) | grepl("model3", names[a], fixed = TRUE)) {
    n = names[a]
  } else {
    print(names[a])
    ft_raw = as.data.frame(raw[a])
    md = metadata[a][[1]]
    colnames(ft_raw) = rownames(md)
    table = otu_table(ft_raw, taxa_are_rows = TRUE)
    samples = sample_data(md)
    physeq_raw = phyloseq(table, samples)
    ancom_out = ancombc(phyloseq=physeq_raw, formula=stats_models_physeq[a], alpha=0.1)
    saveRDS(ancom_out, paste(py$analysis_folder, 'differential_abundance/ancom_', names[a], '.rds', sep=''))
    w = ancom_out$res$W
    q = ancom_out$res$q_val
    p = ancom_out$res$p_val
    colnames(w) = c("W")
    a_out = w
    a_out["q-value"] = q
    a_out["p-value"] = p
    write.csv(a_out, paste(py$analysis_folder, 'differential_abundance/ancom_', names[a], '.csv', sep=""))
  }
}

# ?ancombc
# test_model = 'CASE_CONTROL*F1_SDC_AGE_CALC*SDC_GENDER'
# ancom_out = ancombc(phyloseq=physeq_raw, formula=test_model, alpha=0.1)
# ancom_out$res
```

Run out of memory locally for models 3 and 4, so trying on vulcan:
```{bash, eval=FALSE}
conda create -n r-phyloseq
conda activate r-phyloseq
conda install bioconda::bioconductor-phyloseq
conda install bioconda::bioconductor-ancombc
```

```{R}
# install.packages("BiocManager")
# BiocManager::install("phyloseq")
# BiocManager::install("ANCOMBC")
library(phyloseq)
library(ANCOMBC)

names = readRDS('differential_abundance/names.rds')
raw = readRDS('differential_abundance/raw.rds')
rare = readRDS('differential_abundance/rare.rds')
metadata = readRDS('differential_abundance/metadata.rds')
stats_models = readRDS('differential_abundance/stats_models.rds')
stats_models_physeq = readRDS('differential_abundance/stats_models_physeq.rds')

options(expressions = 5e5)

for (a in 1:length(names)) {
  if (file.exists(paste('differential_abundance/ancom_', names[a], '.rds', sep=''))) {
    n = names[a]
  } else {
    print(names[a])
    ft_raw = as.data.frame(raw[a])
    md = metadata[a][[1]]
    colnames(ft_raw) = rownames(md)
    table = otu_table(ft_raw, taxa_are_rows = TRUE)
    samples = sample_data(md)
    physeq_raw = phyloseq(table, samples)
    print(stats_models_physeq[a])
    ancom_out = ancombc(phyloseq=physeq_raw, formula=stats_models_physeq[a], alpha=0.1)
    saveRDS(ancom_out, paste('differential_abundance/ancom_', names[a], '.rds', sep=''))
  }
}

?ancombc2

#and then as above
```

Above was previous. Trying again with R studio server:
```{R}
setwd('/home/robyn/AtPATH_IBD/analysis_HOMD_2024/')
install.packages('reticulate')
library(reticulate)
install.packages('rappdirs')
conda_python(envname = 'r-phyloseq', conda = "auto")

install.packages('magrittr')
install.packages('stringr')
install.packages('reshape2')
install.packages('R6')
install.packages('scales')
install.packages('pkgconfig')
install.packages('tibble')
install.packages('ggplot2')
install.packages('igraph')
BiocManager::install("phyloseq")
library(phyloseq)

install.packages('mime')
install.packages('xtable')
install.packages('shiny')
install.packages('bit64')
install.packages('memoise')
install.packages('cellranger')
install.packages('readxl')
install.packages('rex')
install.packages('lazyeval')
install.packages('RColorBrewer')
install.packages('jquerylib')
install.packages('base64enc')
install.packages('assertthat')

#sudo apt-get install libmpfr-dev
install.packages('Rmpfr')
install.packages('CVXR')
#install.packages('Matrix') #r version too old, needs 4.4 or above
#install.packages('lme4') #alternative install from source
#utils::install.packages("lme4", type = "source")
install.packages("remotes")
remotes::install_version("Matrix", version = "1.6-2")
oo <- options(repos = "https://cran.r-project.org/")
utils::install.packages("lme4")
install.packages('lmerTest')


install.packages('lazyeval')
install.packages('lazyeval')
install.packages('lazyeval')
install.packages('lazyeval')


BiocManager::install("ANCOMBC")
library(ANCOMBC)


BiocManager::install("ALDEx2")
library(ALDEx2)

??ancombc
```

```{R}
names = readRDS('differential_abundance/names.rds')
raw = readRDS('differential_abundance/raw.rds')
rare = readRDS('differential_abundance/rare.rds')
ancom = readRDS('differential_abundance/ancom.rds')
metadata = readRDS('differential_abundance/metadata.rds')
stats_models = readRDS('differential_abundance/stats_models.rds')
stats_models_physeq = readRDS('differential_abundance/stats_models_physeq.rds')

options(expressions = 5e5)

# for (a in 1:length(names)) {
#   if (file.exists(paste('differential_abundance/ancombc2_', names[a], '.rds', sep=''))) {
#     n = names[a]
#     #print(paste('Already have: ', names[a], sep=''))
#   } else if (file.exists(paste('differential_abundance/ancombc2_0.5_', names[a], '.rds', sep=''))) {
#     n = names[a]
#   } else {
#     print(names[a])
#     ft_raw = as.data.frame(raw[a])
#     md = metadata[a][[1]]
#     colnames(ft_raw) = rownames(md)
#     if (length(colnames(ft_raw)) < 10) {
#       n = names[a]
#     } else {
#     table = otu_table(ft_raw, taxa_are_rows = TRUE)
#     samples = sample_data(md)
#     physeq_raw = phyloseq(table, samples)
#     new_model = gsub("\\*", " + ", stats_models_physeq[a])
#     #print(new_model)
#     #ancom_out = ancombc(phyloseq=physeq_raw, formula=new_model, alpha=0.1)
#     ancom_out = ancombc2(data=physeq_raw, fix_formula=new_model, alpha=0.1)
#     saveRDS(ancom_out, paste('differential_abundance/ancombc2_', names[a], '.rds', sep=''))
#     #ancom_out = ancombc2(data=physeq_raw, fix_formula=new_model, alpha=0.1, verbose=TRUE, prv_cut=0.5) #using this only when it fails with the default prv_cut of 0.1
#     #saveRDS(ancom_out, paste('differential_abundance/ancombc2_0.5_', names[a], '.rds', sep=''))
#     }
#   }
# }

for (a in 1:length(names)) {
  if (file.exists(paste('differential_abundance/ancombc2_structzero_', names[a], '.rds', sep=''))) {
    n = names[a]
    #print(paste('Already have: ', names[a], sep=''))
  } else {
    print(names[a])
    ft_raw = as.data.frame(ancom[a])
    md = metadata[a][[1]]
    colnames(ft_raw) = rownames(md)
    if (length(colnames(ft_raw)) <= 10) {
      n = names[a]
    } else {
    table = otu_table(ft_raw, taxa_are_rows = TRUE)
    samples = sample_data(md)
    physeq_raw = phyloseq(table, samples)
    new_model = gsub("\\*", " + ", stats_models_physeq[a])
    ancom_out = ancombc2(data=physeq_raw, fix_formula=new_model, alpha=0.1,  verbose=TRUE)
    saveRDS(ancom_out, paste('differential_abundance/ancombc2_structzero_', names[a], '.rds', sep=''))
    }
  }
}
```

Aldex2:
```{R}
#models 0 and 1
#initial local run
for (a in 1:length(names)) {
  if (file.exists(paste(py$analysis_folder, 'differential_abundance/aldex_', names[a], '.csv', sep=''))) {
    n = names[a]
  } else if (grepl("model2", names[a], fixed = TRUE) | grepl("model3", names[a], fixed = TRUE)) {
    n = names[a]
  } else if (grepl("CASE_CONTROL", names[a], fixed = TRUE)) {
    print(names[a])
    ft_raw = as.data.frame(raw[a])
    md = data.frame(metadata[a][[1]])
    colnames(ft_raw) = rownames(md)
    x <- aldex.clr(ft_raw, md$CASE_CONTROL, mc.samples = 128, verbose=F, denom="all")
    kw.test <- aldex.kw(x, useMC=4, verbose=FALSE)
    # glm.test <- aldex.glm(x, md$CASE_CONTROL)
    # glm.effect <- aldex.glm.effect(x)
    # aldex_out <- data.frame(glm.test, glm.effect)
    write.csv(kw.test, paste(py$analysis_folder, 'differential_abundance/aldex_', names[a], '.csv', sep=""))
  } else if (grepl("Crohn_case_control", names[a], fixed = TRUE)) {
    ft_raw = as.data.frame(raw[a])
    md = data.frame(metadata[a][[1]])
    colnames(ft_raw) = rownames(md)
    x <- aldex.clr(ft_raw, md$Crohn_case_control, mc.samples = 128, verbose=F, denom="all")
    kw.test <- aldex.kw(x, useMC=4, verbose=FALSE)
    write.csv(kw.test, paste(py$analysis_folder, 'differential_abundance/aldex_', names[a], '.csv', sep=""))
  } else if (grepl("UC_case_control", names[a], fixed = TRUE)) {
    ft_raw = as.data.frame(raw[a])
    md = data.frame(metadata[a][[1]])
    colnames(ft_raw) = rownames(md)
    x <- aldex.clr(ft_raw, md$UC_case_control, mc.samples = 128, verbose=F, denom="all")
    kw.test <- aldex.kw(x, useMC=4, verbose=FALSE)
    write.csv(kw.test, paste(py$analysis_folder, 'differential_abundance/aldex_', names[a], '.csv', sep=""))
  } else if (grepl("Both_case_control", names[a], fixed = TRUE)) {
    ft_raw = as.data.frame(raw[a])
    md = data.frame(metadata[a][[1]])
    colnames(ft_raw) = rownames(md)
    x <- aldex.clr(ft_raw, md$Both_case_control, mc.samples = 128, verbose=F, denom="all")
    kw.test <- aldex.kw(x, useMC=4, verbose=FALSE)
    write.csv(kw.test, paste(py$analysis_folder, 'differential_abundance/aldex_', names[a], '.csv', sep=""))
  }
}

#models 2 and 3 running on vulcan
for (a in 1:length(names)) {
  if (file.exists(paste('differential_abundance/aldex_', names[a], '.csv', sep=''))) {
    n = names[a]
  } else if (grepl("model0", names[a], fixed = TRUE) | grepl("model1", names[a], fixed = TRUE)) {
    n = names[a]
  } else {
    print(names[a])
    ft_raw = as.data.frame(raw[a])
    md = data.frame(metadata[a][[1]])
    colnames(ft_raw) = rownames(md)
    new_model = gsub("\\$", "", stats_models[a])
    new_model = gsub("md", "", new_model)
    new_model = gsub("\\*", " + ", new_model)
    mm <- model.matrix(formula(paste('~', new_model)), md)
    x <- aldex.clr(ft_raw, mm, mc.samples = 128, verbose=F, denom="all")
    #kw.test <- aldex.kw(x, useMC=12, verbose=FALSE)
    glm.test <- aldex.glm(x, mm)
    glm.effect <- aldex.glm.effect(x)
    aldex_out <- data.frame(glm.test, glm.effect)
    write.csv(aldex_out, paste('differential_abundance/aldex_', names[a], '.csv', sep=""))
  } 
}

# ?aldex.clr
# ?aldex.glm
```

Copied results back to local:
```{bash}
scp -r vulcan:/home/robyn/AtPATH_IBD/analysis_HOMD_2024/differential_abundance/ differential_abundance_June25_2024/
#and copied what was in differential_abundance to the main folder
```

Save Ancom .rds files:
```{R}
# for (a in 1:length(names)) {
#   if (file.exists(paste(py$analysis_folder, 'differential_abundance/ancombc2_', names[a], '.rds', sep=''))) {
#     n = names[a]
#     #print(paste('Already have: ', names[a], sep=''))
#     ancom_out = readRDS(paste(py$analysis_folder, 'differential_abundance/ancombc2_', names[a], '.rds', sep=''))
#     results = ancom_out$res
#     write.csv(results, paste(py$analysis_folder, 'differential_abundance/ancombc2_', names[a], '.csv', sep=''))
#   } else if (file.exists(paste(py$analysis_folder, 'differential_abundance/ancombc2_0.5_', names[a], '.rds', sep=''))) {
#     n = names[a]
#     #print(paste('Already have: ', names[a], sep=''))
#     ancom_out = readRDS(paste(py$analysis_folder, 'differential_abundance/ancombc2_0.5_', names[a], '.rds', sep=''))
#     results = ancom_out$res
#     write.csv(results, paste(py$analysis_folder, 'differential_abundance/ancombc2_0.5_', names[a], '.csv', sep=''))
#   }
# }

for (a in 1:length(names)) {
  if (file.exists(paste(py$analysis_folder, 'differential_abundance/ancombc2_structzero_', names[a], '.rds', sep=''))) {
    n = names[a]
    #print(paste('Already have: ', names[a], sep=''))
    ancom_out = readRDS(paste(py$analysis_folder, 'differential_abundance/ancombc2_structzero_', names[a], '.rds', sep=''))
    results = ancom_out$res
    write.csv(results, paste(py$analysis_folder, 'differential_abundance/ancombc2_structzero_', names[a], '.csv', sep=''))
  } 
}
```

Look at which we needed to do 0.5 for:
```{python}
# names = py$names
# raw = py$raw
# rare = py$rare
# metadata = py$metadata
# stats_models = py$models
# stats_models_physeq = py$models_physeq

# for a in range(len(names)):
#   if not os.path.exists(analysis_folder+'differential_abundance/ancombc2_'+names[a]+'.csv'):
#     if not os.path.exists(analysis_folder+'differential_abundance/ancombc2_0.5_'+names[a]+'.csv'):
#       print(names[a])
#       ft = raw[a][raw[a].max(axis=1) > 0]
#       print('samples=', len(metadata[a].index.values), '; taxa=', len(ft.index.values))
#   # #if 'model0' in names[a] or 'model1' in names[a]: continue
#   # if os.path.exists(analysis_folder+'differential_abundance/ancombc2_0.5_'+names[a]+'.csv'):
#   #   #print('0.5 '+names[a]+' samples=', len(metadata[a].index.values), '; taxa=', len(raw[a].index.values))
#   #   print(names[a])
#   # else:
#   #   #print(names[a]+' samples=', len(metadata[a].index.values), '; taxa=', len(raw[a].index.values))
#   #   do_nothing = True

struct_zero = pd.read_csv(analysis_folder+'files/structural_zeroes.csv', index_col=0, header=0).index.values

for a in range(len(names)):
  if not os.path.exists(analysis_folder+'differential_abundance/ancombc2_structzero_'+names[a]+'.csv'):
    print(names[a], len(metadata[a].index.values))
    
finished = True
```
OR: if we have fewer samples per group than metadata variables then we just don't include these for DA tests? 

```{python}
for a in range(len(names)):
  if len(metadata[a].index.values)/2 <= 17:
    dont_need = names[a]
  elif not os.path.exists(analysis_folder+'differential_abundance/ancombc2_'+names[a]+'.csv'):
    ft = raw[a][raw[a].max(axis=1) > 1]
    print(names[a], len(metadata[a].index.values), len(ft.index.values))

finished = True
```

Try and rerun ANCOM locally for these that didn't work?
Can't get same version to install locally, so will just do this on vulcan again:
```{R}
library(ANCOMBC)

names = readRDS(paste('differential_abundance/names.rds', sep=''))
raw = readRDS(paste('differential_abundance/raw.rds', sep=''))
rare = readRDS(paste('differential_abundance/rare.rds', sep=''))
metadata = readRDS(paste('differential_abundance/metadata.rds', sep=''))
stats_models = readRDS(paste('differential_abundance/stats_models.rds', sep=''))
stats_models_physeq = readRDS(paste('differential_abundance/stats_models_physeq.rds', sep=''))

options(expressions = 5e5)

for (a in 1:length(names)) {
  if (file.exists(paste('differential_abundance/ancombc2_', names[a], '.rds', sep=''))) {
    n = names[a]
    #print(paste('Already have: ', names[a], sep=''))
  } else {
    print(names[a])
    ft_raw = as.data.frame(raw[a])
    md = metadata[a][[1]]
    colnames(ft_raw) = rownames(md)
    table = otu_table(ft_raw, taxa_are_rows = TRUE)
    samples = sample_data(md)
    physeq_raw = phyloseq(table, samples)
    new_model = gsub("\\*", " + ", stats_models_physeq[a])
    #print(new_model)
    #ancom_out = ancombc(phyloseq=physeq_raw, formula=new_model, alpha=0.1)
    ancom_out = ancombc2(data=physeq_raw, fix_formula=new_model, alpha=0.1)
    saveRDS(ancom_out, paste('differential_abundance/ancombc2_', names[a], '.rds', sep=''))
    ancom_out = ancombc(phyloseq=physeq_raw, formula=new_model, alpha=0.1)
    #ancom_out = ancombc2(data=physeq_raw, fix_formula=new_model, alpha=0.1, verbose=TRUE, prv_cut=0.5) #using this only when it fails with the default prv_cut of 0.1
    #saveRDS(ancom_out, paste('differential_abundance/ancombc2_0.5_', names[a], '.rds', sep=''))
    }
}

#ancombc seems to work for these. Run ancombc with everything?
# for (a in 1:length(names)) {
#   if (file.exists(paste('differential_abundance/ancombc_', names[a], '.rds', sep=''))) {
#     n = names[a]
#     #print(paste('Already have: ', names[a], sep=''))
#   } else {
#     print(names[a])
#     ft_raw = as.data.frame(raw[a])
#     md = metadata[a][[1]]
#     colnames(ft_raw) = rownames(md)
#     table = otu_table(ft_raw, taxa_are_rows = TRUE)
#     samples = sample_data(md)
#     physeq_raw = phyloseq(table, samples)
#     new_model = gsub("\\*", " + ", stats_models_physeq[a])
#     #print(new_model)
#     #ancom_out = ancombc(phyloseq=physeq_raw, formula=new_model, alpha=0.1)
#     # ancom_out = ancombc2(data=physeq_raw, fix_formula=new_model, alpha=0.1)
#     # saveRDS(ancom_out, paste('differential_abundance/ancombc2_', names[a], '.rds', sep=''))
#     ancom_out = ancombc(phyloseq=physeq_raw, formula=new_model, alpha=0.1)
#     #ancom_out = ancombc2(data=physeq_raw, fix_formula=new_model, alpha=0.1, verbose=TRUE, prv_cut=0.5) #using this only when it fails with the default prv_cut of 0.1
#     #saveRDS(ancom_out, paste('differential_abundance/ancombc2_0.5_', names[a], '.rds', sep=''))
#     saveRDS(ancom_out, paste('differential_abundance/ancombc_', names[a], '.rds', sep=''))
#     }
# }
#nope, don't do this. It doesn't seem like it would do such a good job with controlling FDR: https://github.com/FrederickHuangLin/ANCOMBC/issues/64. Go back to what I was looking at above!

```

Trying out radEMU instead of ANCOM:
```{r, eval=FALSE}
#initially locally
install.packages("devtools")
#install.packages("gert")
install.packages("gert", repos = c(
    ropensci = 'https://ropensci.r-universe.dev',
    CRAN = 'https://cloud.r-project.org'))
library(gert)
install.packages("usethis")
library(usethis)
Sys.getenv("GITHUB_PAT")
#[1] ""
Sys.unsetenv("GITHUB_PAT")
devtools::install_github("statdivlab/radEmu")

#not working so trying on vulcan
#first: conda create -n r-radEMU
#conda activate r-radEMU
#R
install.packages("devtools")
devtools::install_github("statdivlab/radEmu")
library(radEmu) #didn't initially load, but quit R and restarted and it loaded fine!
library(phyloseq)

names = readRDS(paste('differential_abundance/names.rds', sep=''))
raw = readRDS(paste('differential_abundance/raw.rds', sep=''))
metadata = readRDS(paste('differential_abundance/metadata.rds', sep=''))
stats_models = readRDS(paste('differential_abundance/stats_models.rds', sep=''))
stats_models_physeq = readRDS(paste('differential_abundance/stats_models_physeq.rds', sep=''))

couldnt_run = c()

for (a in 1:length(names)) {
  if (file.exists(paste('differential_abundance/radEMU_', names[a], '.rds', sep=''))) {
    n = names[a]
  } else {
    print(names[a])
    ft_raw = as.data.frame(raw[a])
    md = metadata[a][[1]]
    colnames(ft_raw) = rownames(md)
    table = otu_table(ft_raw, taxa_are_rows = TRUE)
    samples = sample_data(md)
    physeq_raw = phyloseq(table, samples)
    physeq_filter <- filter_taxa(physeq_raw, function(x) sum(x) > 0, TRUE)
    new_model = formula(paste('~', gsub("\\*", " + ", stats_models_physeq[a]), sep=' '))
    print(new_model)
    tryCatch(
      expr = {
        radEMU_out <- emuFit(formula = new_model, Y = physeq_filter)
        rE_out = radEMU_out$coef
        saveRDS(rE_out, paste('differential_abundance/radEMU_', names[a], '.rds', sep=''))
        message("Successfully ran radEMU")
      },
      error = function(e){
        message("Uh oh! This one didn't work out")
        couldnt_run = c(couldnt_run, names[a])
      },
      warning = function(e){
        message("I think this ran, but there were some warnings")
        message(conditionMessage(e))
      },
      finally = {
        message("This is just the final part, I assume it is necessary but there's nothing that we want to do for everything...")
      }
    )
    }
}
```

Copied these results across from Vulcan. Now read them in here:
```{python}
file_list = os.listdir(analysis_folder+'differential_abundance_June25_2024/')
file_list = [f.replace('.rds', '') for f in file_list if 'radEMU' in f]
```


```{R}
files = py$file_list

for (f in 1:length(files)) {
  file = readRDS(paste(py$analysis_folder, "differential_abundance_June25_2024/", files[f], '.rds', sep=""))
  write.csv(file, paste(py$analysis_folder, "differential_abundance_June25_2024/", files[f], '.csv', sep=""))
}
```

Do the same for the ANCOM ones:
```{python}
file_list = os.listdir(analysis_folder+'differential_abundance_June25_2024/')
file_list = list(set([f.replace('.rds', '') for f in file_list if 'ancombc' in f and '.rds' in f]))
```


```{R}
files = py$file_list

for (f in 1:length(files)) {
  file = readRDS(paste(py$analysis_folder, "differential_abundance_June25_2024/", files[f], '.rds', sep=""))
  write.csv(file$res, paste(py$analysis_folder, "differential_abundance_June25_2024/", files[f], '.csv', sep=""))
}
```

## Read in results

```{python}
#we only have models 1 and 2 at the moment, so not reading in everything
md = pd.read_csv(analysis_folder+'files/metadata_crohns_UC.csv', index_col=0, header=0)
md_mod1 = pd.read_csv(analysis_folder+'files/metadata_model1.csv', index_col=0, header=0)
data_split = ['CASE_CONTROL', 'Crohn_case_control', 'UC_case_control', 'Both_case_control']
with open(analysis_folder+'files/female_reduced.list', 'rb') as f:
  females_all, females_model1 = pickle.load(f)
md_females = md.loc[md['SDC_GENDER'] == 2]
md_females_reduced = md.loc[females_all, :]
md_females_mod1 = md_mod1.loc[md_mod1['SDC_GENDER'] == 2]
md_females_reduced_mod1 = md_mod1.loc[females_model1, :]
md_males = md.loc[md['SDC_GENDER'] == 1]
md_males_mod1 = md_mod1.loc[md_mod1['SDC_GENDER'] == 1]
md_using = [md, md_mod1, md_females, md_females_mod1, md_females_reduced, md_females_reduced_mod1, md_males, md_males_mod1]
names_adding = ['', '', 'females_', 'females_', 'females_reduced_', 'females_reduced_', 'males_', 'males_']
model_num = [0, 1, 0, 1, 0, 1, 0, 1]
full_ft_raw = pd.read_csv(analysis_folder+'files/genus_table.csv', index_col=0, header=0)
full_ft_rare = pd.read_csv(analysis_folder+'files/genus_table_rare.csv', index_col=0, header=0)

names, da_tables, abun_tables, all_sig, sig_2 = [], [], [], [], []
genus_rename = {}
tax = pd.read_csv(analysis_folder+'files/taxonomy.csv', index_col=0, header=0)
for row in tax.index.values:
  genus_rename[row] = tax.loc[row, 'Genus'].replace('g__', '')

count = 0
for ds in data_split:
  for m in range(len(md_using)):
    #if count > 0: break
    name = names_adding[m]+ds+'_model'+str(model_num[m])
    aldex = pd.read_csv(analysis_folder+'differential_abundance/aldex_'+name+'.csv', index_col=0, header=0).loc[:, ['glm.eBH']].rename(columns={'glm.eBH':'aldex'})
    ancom = pd.read_csv(analysis_folder+'differential_abundance/ancom_'+name+'.csv', index_col=0, header=0).loc[:, ['q-value']].rename(columns={'q-value':'ancom'})
    maaslin = pd.read_csv(analysis_folder+'differential_abundance/maaslin2_'+name+'/all_results.tsv', index_col=0, header=0, sep='\t').loc[:, ['qval']].rename(columns={'qval':'maaslin'})
    rename_features = {}
    for row in maaslin.index.values:
      if row[0] == 'X': rename_features[row] = row[1:]
    maaslin = maaslin.rename(index=rename_features)
    diff_abun = pd.concat([aldex, ancom, maaslin], axis=1, join='outer').fillna(value=0)
    diff_abun = diff_abun.rename(index=genus_rename)
    for row in diff_abun.index.values:
      for col in diff_abun.columns:
        if diff_abun.loc[row, col] > 0.1: diff_abun.loc[row, col] = 0
        else: diff_abun.loc[row, col] = 1
    diff_abun_sig = diff_abun[diff_abun.max(axis=1) > 0]
    diff_abun_sig_2 = diff_abun[diff_abun.sum(axis=1) > 1]
    d = [all_sig.append(da) for da in diff_abun_sig.index.values]
    d = [sig_2.append(da) for da in diff_abun_sig_2.index.values]
    this_ft = full_ft_rare.copy(deep=True)#.loc[diff_abun.index.values, :]
    mdu = md_using[m]
    this_md_case = mdu[mdu[ds] == 1].index.values
    this_md_control = mdu[mdu[ds] == 0].index.values
    samples = list(this_md_case)+list(this_md_control)
    rename_ft = {}
    for case in this_md_case:
      rename_ft[case] = 'Case'
    for control in this_md_control:
      rename_ft[control] = 'Control'
    this_ft = this_ft.divide(this_ft.sum(axis=0), axis=1).multiply(100)
    this_ft = this_ft.loc[:, samples]
    this_ft = this_ft.rename(columns=rename_ft).transpose()
    this_ft = this_ft.groupby(by=this_ft.index, axis=0).mean().transpose()
    this_ft = this_ft.rename(index=genus_rename)
    names.append(name)
    for row in this_ft.index.values:
      if row not in diff_abun.index.values:
        diff_abun.loc[row, :] = 0
    da_tables.append(diff_abun)
    abun_tables.append(this_ft)
    count += 1

all_sig = sorted(list(set(all_sig)))
all_sig.reverse()
sig_2 = sorted(list(set(sig_2)))
finished = True
#md[md[on[g]] == 1].index.values
```

Now plot:
```{python}
fig = plt.figure(figsize=(15,10))
da_df = []
axes = []

#all #if 'males' not in name #if c > 0: c = n
#females #if 'females' in name and '_males_' not in name and 'reduced' not in name #if c > 0: c = n-2
#females reduced #if 'females' in name and '_males_' not in name and 'reduced' in name #c = n-4
#males #if 'males' in name and 'females' not in name #c = n-6

for n in range(len(names)):
  name = names[n]
  c = n-6
  if 'males' in name and 'females' not in name and n % 2 == 0:
    if c > 0: c = int(c/4)
    print(c, n, names[n])
    ax_abun, ax_da = plt.subplot2grid((1,8),(0,c)), plt.subplot2grid((1,8),(0,c+1))
    axes.append(ax_abun)
    this_da, this_abun = da_tables[n].loc[all_sig, :], abun_tables[n].loc[all_sig, :]
    da_sum = pd.DataFrame(this_da.sum(axis=1))
    da_sum.columns = ['Model 1']
    da_df = da_sum
  elif 'males' in name and 'females' not in name:
    this_da, this_abun = da_tables[n].loc[all_sig, :], abun_tables[n].loc[all_sig, :]
    m1, m2 = da_tables[n-1].loc[all_sig, :], this_da
    da_sum = pd.DataFrame(this_da.sum(axis=1))
    da_sum.columns = ['Model 2']
    da_df = pd.concat([da_df, da_sum], axis=1, join='outer')
    plt.sca(ax_abun)
    hm = plt.pcolor(this_abun, cmap='hot', edgecolor='k', vmax=5)
    for r in range(len(this_abun.index.values)):
      for c in range(len(this_abun.columns)):
        val = this_abun.iloc[r, c]
        if val < 2.5: fc = 'w'
        else: fc = 'k'
        if val < 1: val = round(val, 2)
        elif val < 10: val = round(val, 1)
        else: val = int(val)
        tx = plt.text(c+0.5, r+0.5, str(val), color=fc, fontsize=8, ha='center', va='center')
    xt = plt.xticks([0.5, 1.5], ['Cases', 'Controls'], rotation=90)
    tt = ax_abun.xaxis.tick_top()
    if 'CASE_CONTROL' in name: yt = plt.yticks([x+0.5 for x in range(len(this_abun.index.values))], this_abun.index.values)
    else: yt = plt.yticks([])
    plt.sca(ax_da)
    hm = plt.pcolor(da_df, cmap='Blues', edgecolor='k', vmax=3)
    xt = plt.xticks([0.5, 1.5], ['Model 1', 'Model 2'], rotation=90)
    tt = ax_da.xaxis.tick_top()
    yt = plt.yticks([])
    tests, markers, adding = ['ancom', 'aldex', 'maaslin'], ['*', '^', 's'], [-0.25, 0, 0.25]
    for r in range(len(m1.index.values)):
      genus = m1.index.values[r]
      for t in range(len(tests)):
        if m1.loc[genus, tests[t]] > 0:
          if da_df.loc[genus, 'Model 1'] > 1: mc = 'w'
          else: mc = 'k'
          sc = ax_da.scatter(0.5+adding[t], r+0.5, marker=markers[t], color=mc, s=20)
        if m2.loc[genus, tests[t]] > 0:
          if da_df.loc[genus, 'Model 2'] > 1: mc = 'w'
          else: mc = 'k'
          sc = ax_da.scatter(1.5+adding[t], r+0.5, marker=markers[t], color=mc, s=20)

plot_names = ['IBD', 'Crohns', 'UC', 'Both']
for a in range(len(axes)):
  tx = axes[a].text(1.1, 1.1, plot_names[a], fontweight='bold', ha='center', va='bottom', fontsize=14, transform=axes[a].transAxes)

plt.savefig(analysis_folder+'figures/differential_abundance_genus_males.png', dpi=600, bbox_inches='tight')

finished = True
```

Plot those that were significant with 2+ tests:
```{python}
fig = plt.figure(figsize=(20,10))
genus_ft = full_ft_rare.rename(index=genus_rename)
genus_ft = genus_ft.divide(genus_ft.sum(axis=0), axis=1).multiply(100)
cases = md[md['CASE_CONTROL'] == 1].index.values
controls = md[md['CASE_CONTROL'] == 0].index.values

for a in range(len(sig_2)):
  ax = plt.subplot(3,6,a+1)
  ti = plt.title(sig_2[a], fontweight='bold')
  cases_vals = genus_ft.loc[sig_2[a], cases].values
  controls_vals = genus_ft.loc[sig_2[a], controls].values
  sc = ax.scatter(np.random.normal(0, scale=0.1, size=len(cases_vals)), cases_vals, marker='o', color=color_dict['IBD Cases'], alpha=0.5, s=20)
  box = ax.boxplot(cases_vals, positions=[0], widths=0.8, showfliers=False)
  for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: bi = plt.setp(box[item], color='k')
  sc = ax.scatter(np.random.normal(1, scale=0.1, size=len(controls_vals)), cases_vals, marker='o', color=color_dict['IBD Controls'], alpha=0.5, s=20)
  box = ax.boxplot(controls_vals, positions=[1], widths=0.8, showfliers=False)
  for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: bi = plt.setp(box[item], color='k')
  if a in [0,6,12]: yl = plt.ylabel('Relative abundance (%)')
  if a > 11: xt = plt.xticks([0, 1], ['Cases', 'Controls'], rotation=90)
  else: xt = plt.xticks([0, 1], [])

plt.savefig(analysis_folder+'figures/differential_abundance_genus_2+_tests_significant.png', dpi=600, bbox_inches='tight')
plt.show()
```

### All DA for models 1 and 2

```{python}

```

### All models

Now reading in everything:
```{python}
data_split = ['CASE_CONTROL', 'Crohn_case_control', 'UC_case_control', 'Both_case_control']
with open(analysis_folder+'files/female_reduced.list', 'rb') as f:
  females_all, females_model1 = pickle.load(f)
  
md = pd.read_csv(analysis_folder+'files/metadata_crohns_UC.csv', index_col=0, header=0)
md_mod1 = pd.read_csv(analysis_folder+'files/metadata_model1.csv', index_col=0, header=0)
md_mod2 = pd.read_csv(analysis_folder+'files/metadata_model2.csv', index_col=0, header=0)
md_females = md.loc[md['SDC_GENDER'] == 2]
md_females_reduced = md.loc[females_all, :]
md_females_mod1 = md_mod1.loc[md_mod1['SDC_GENDER'] == 2]
md_females_mod2 = md_mod2.loc[md_mod2['SDC_GENDER'] == 2]
md_females_reduced_mod1 = md_mod1.loc[females_model1, :]
md_females_reduced_mod2 = md_mod2.loc[females_model1, :]
md_males = md.loc[md['SDC_GENDER'] == 1]
md_males_mod1 = md_mod1.loc[md_mod1['SDC_GENDER'] == 1]
md_males_mod2 = md_mod2.loc[md_mod2['SDC_GENDER'] == 1]
  
md_using = [md, md_mod1, md_mod1, md_mod2, md_females, md_females_mod1, md_females_mod1, md_females_mod2, md_females_reduced, md_females_reduced_mod1, md_females_reduced_mod1, md_females_reduced_mod2, md_males, md_males_mod1, md_males_mod1, md_males_mod2]
names_adding = ['', '', '', '', 'females_', 'females_', 'females_', 'females_', 'females_reduced_', 'females_reduced_', 'females_reduced_', 'females_reduced_', 'males_', 'males_', 'males_', 'males_']
model_num = [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3]
full_ft_raw = pd.read_csv(analysis_folder+'files/genus_table.csv', index_col=0, header=0)
full_ft_rare = pd.read_csv(analysis_folder+'files/genus_table_rare.csv', index_col=0, header=0)

names, da_tables, abun_tables, all_sig, sig_2 = [], [], [], [], []
genus_rename = {}
tax = pd.read_csv(analysis_folder+'files/taxonomy.csv', index_col=0, header=0)
for row in tax.index.values:
  genus_rename[row] = tax.loc[row, 'Genus'].replace('g__', '')

count = 0
no_ancom, no_maaslin = [], []
for ds in data_split:
  for m in range(len(md_using)):
    #if count > 0: break
    name = names_adding[m]+ds+'_model'+str(model_num[m])
    if model_num[m] in [0, 1]:
      aldex = pd.read_csv(analysis_folder+'differential_abundance/aldex_'+name+'.csv', index_col=0, header=0).loc[:, ['glm.eBH']].rename(columns={'glm.eBH':'aldex'})
      maaslin = pd.read_csv(analysis_folder+'differential_abundance/maaslin2_'+name+'/all_results.tsv', index_col=0, header=0, sep='\t').loc[:, ['qval']].rename(columns={'qval':'maaslin'})
      try:
        ancom = pd.read_csv(analysis_folder+'differential_abundance/ancombc2_structzero_'+name+'.csv', index_col=1, header=0).loc[:, ['q_'+ds]].rename(columns={'q_'+ds:'ancom'})
      except:
        ancom = pd.DataFrame(1, index=aldex.index.values, columns=['ancom']) 
        no_ancom.append(name)
      rename_features = {}
      for row in maaslin.index.values:
        if row[0] == 'X': rename_features[row] = row[1:]
      maaslin = maaslin.rename(index=rename_features)
    else:
      aldex = pd.read_csv(analysis_folder+'differential_abundance/aldex_'+name+'.csv', index_col=0, header=0).loc[:, [ds+'.pval.holm']].rename(columns={ds+'.pval.holm':'aldex'})
      maaslin = pd.read_csv(analysis_folder+'differential_abundance/maaslin2_'+name+'/all_results.tsv', index_col=0, header=0, sep='\t')
      maaslin = maaslin[maaslin['metadata'] == ds]
      if maaslin.shape[0] == 0:
        no_maaslin.append(name)
      maaslin = maaslin.loc[:, ['qval']].rename(columns={'qval':'maaslin'})
      rename_features = {}
      for row in maaslin.index.values:
        if row[0] == 'X': rename_features[row] = row[1:]
      maaslin = maaslin.rename(index=rename_features)
      try:
        ancom = pd.read_csv(analysis_folder+'differential_abundance/ancombc2_structzero_'+name+'.csv', index_col=1, header=0).loc[:, ['q_'+ds]].rename(columns={'q_'+ds:'ancom'})
      except:
        ancom = pd.DataFrame(1, index=aldex.index.values, columns=['ancom']) 
        no_ancom.append(name)
    diff_abun = pd.concat([aldex, ancom, maaslin], axis=1, join='outer').fillna(value=1)
    diff_abun = diff_abun.rename(index=genus_rename)
    for row in diff_abun.index.values:
      for col in diff_abun.columns:
        if diff_abun.loc[row, col] > 0.1: diff_abun.loc[row, col] = 0
        else: diff_abun.loc[row, col] = 1
    diff_abun_sig = diff_abun[diff_abun.max(axis=1) > 0]
    diff_abun_sig_2 = diff_abun[diff_abun.sum(axis=1) > 1]
    d = [all_sig.append(da) for da in diff_abun_sig.index.values]
    d = [sig_2.append(da) for da in diff_abun_sig_2.index.values]
    this_ft = full_ft_rare.copy(deep=True)#.loc[diff_abun.index.values, :]
    mdu = md_using[m]
    this_md_case = mdu[mdu[ds] == 1].index.values
    this_md_control = mdu[mdu[ds] == 0].index.values
    samples = list(this_md_case)+list(this_md_control)
    rename_ft = {}
    for case in this_md_case:
      rename_ft[case] = 'Case'
    for control in this_md_control:
      rename_ft[control] = 'Control'
    this_ft = this_ft.divide(this_ft.sum(axis=0), axis=1).multiply(100)
    this_ft = this_ft.loc[:, samples]
    this_ft = this_ft.rename(columns=rename_ft).transpose()
    this_ft = this_ft.groupby(by=this_ft.index, axis=0).mean().transpose()
    this_ft = this_ft.rename(index=genus_rename)
    names.append(name)
    for row in this_ft.index.values:
      if row not in diff_abun.index.values:
        diff_abun.loc[row, :] = 0
    da_tables.append(diff_abun)
    abun_tables.append(this_ft)
    count += 1

all_sig = sorted(list(set(all_sig)))
all_sig.reverse()
sig_2 = sorted(list(set(sig_2)))
finished = True
#md[md[on[g]] == 1].index.values

#print(no_ancom)
#print(no_maaslin)
```

Now plot:
```{python}
#print(no_ancom)
#print(no_maaslin)
struct_zero = pd.read_csv(analysis_folder+'files/structural_zeroes.csv', index_col=0, header=0).index.values

save_names = ['differential_abundance_all_models_genus.png', 'differential_abundance_all_models_genus_females.png', 'differential_abundance_all_models_genus_males.png', 'differential_abundance_all_models_genus_females_reduced.png']
#confused by my previous plotting script!!
for a in range(4):
  #if a > 0: continue
  fig = plt.figure(figsize=(15,10))
  da_df = []
  axes = []
  co = 0
  for n in range(len(names)):
    name = names[n]
    if a == 0:
      if 'males' in name: continue
    elif a == 1:
      if 'females' not in name or 'reduced' in name: continue
    elif a == 2:
      if 'females' in name or 'males' not in name: continue
    elif a == 3:
      if 'reduced' not in name: continue
    if 'model0' in name:
      ax_abun, ax_da = plt.subplot2grid((1,8),(0,co)), plt.subplot2grid((1,8),(0,co+1))
      plot_da, adding_name = [], ['', '', '', '']
      co += 2
      axes.append(ax_abun)
      this_abun = abun_tables[n].loc[all_sig, :]
      plt.sca(ax_abun)
      hm = plt.pcolor(this_abun, cmap='hot', edgecolor='k', vmax=5)
      for r in range(len(this_abun.index.values)):
        for c in range(len(this_abun.columns)):
          val = this_abun.iloc[r, c]
          if val < 2.5: fc = 'w'
          else: fc = 'k'
          if val < 1: val = round(val, 2)
          elif val < 10: val = round(val, 1)
          else: val = int(val)
          tx = plt.text(c+0.5, r+0.5, str(val), color=fc, fontsize=8, ha='center', va='center')
      xt = plt.xticks([0.5, 1.5], ['Cases', 'Controls'], rotation=90)
      tt = ax_abun.xaxis.tick_top()
      if 'CASE_CONTROL' in name: yt = plt.yticks([x+0.5 for x in range(len(this_abun.index.values))], this_abun.index.values)
      else: plt.yticks([])
    this_da = da_tables[n].loc[all_sig, :]
    plot_da.append(this_da)
    da_sum = pd.DataFrame(this_da.sum(axis=1))
    mod_num = int(name.split('model')[1])
    da_sum.columns = ['Model ' +str(mod_num+1)]
    if mod_num == 0: da_df = da_sum
    else: da_df = pd.concat([da_df, da_sum], axis=1, join='outer')
    model_names = ['Model 1', 'Model 2', 'Model 3', 'Model 4']
    if name in struct_zero: adding_name[mod_num] += '<'
    elif name in no_ancom: adding_name[mod_num] += '>'
    if name in no_maaslin: adding_name[mod_num] += '^'
    if mod_num == 3:
      plt.sca(ax_da)
      hm = plt.pcolor(da_df, cmap='Blues', edgecolor='k', vmax=3)
      for q in range(len(adding_name)): model_names[q] += adding_name[q]
      xt = plt.xticks([0.5, 1.5, 2.5, 3.5], model_names, rotation=90)
      tt = ax_da.xaxis.tick_top()
      yt = plt.yticks([])
      tests, markers, adding = ['ancom', 'aldex', 'maaslin'], ['*', '^', 's'], [-0.25, 0, 0.25]
      for z in range(len(plot_da)):
        for y in range(len(plot_da[z].index.values)):
          genus = plot_da[z].index.values[y]
          for t in range(len(tests)):
            if plot_da[z].loc[genus, tests[t]] > 0:
              if da_df.loc[genus, 'Model '+str(z+1)] > 1: mc = 'w'
              else: mc = 'k'
              sc = ax_da.scatter(z+0.5+adding[t], y+0.5, marker=markers[t], color=mc, s=15)
  plot_names = ['IBD', 'Crohns', 'UC', 'Both']
  for h in range(len(axes)):
    tx = axes[h].text(1.1, 1.1, plot_names[h], fontweight='bold', ha='center', va='bottom', fontsize=14, transform=axes[h].transAxes)
  plt.savefig(analysis_folder+'figures/'+save_names[a], dpi=600, bbox_inches='tight')
  plt.close()

finished = True
```

## Compare results of DA on model 0 3rd October 2024

Just overall to begin with:
```{python}
data_split = ['CASE_CONTROL', 'Crohn_case_control', 'UC_case_control', 'Both_case_control']
titles = ['Overall', "Crohn's disease", "Ulcerative colitis", "Both"]
all_results = os.listdir(analysis_folder+'differential_abundance_June25_2024/')
maaslin = [f for f in all_results if 'maaslin' in f]
maaslin = [f for f in maaslin if 'males' not in f]
maaslin = [f+'/all_results.tsv' for f in maaslin if 'model0' in f]
all_results = [f for f in all_results if '.csv' in f]
all_results = sorted([f for f in all_results if 'males' not in f])
all_results = [f for f in all_results if 'model0' in f]
all_results = sorted(all_results+maaslin)

da_test = ['aldex', 'ancombc2', 'ancombc2_structzero', 'ancombc', 'maaslin2', 'radEMU']
tax = pd.read_csv(analysis_folder+'files/taxonomy.csv', index_col=0, header=0)
tax_rename = {}
for row in tax.index.values:
  tax_rename[row] = tax.loc[row, 'Genus']

results_df = []
for ds in data_split:
  this_df = []
  for da in da_test:
    for r in all_results:
      if da+'_'+ds in r:
        if '.tsv' in r: 
          print(r)
          df = pd.read_csv(analysis_folder+'differential_abundance_June25_2024/'+r, sep='\t', index_col=0, header=0)
          df.rename(index=tax_rename).to_csv(analysis_folder+'differential_abundance_summary/'+r.replace('/all_results.tsv', '.csv'))
          rename = {}
          for row in df.index.values:
            if row[0] == 'X': rename[row] = row[1:]
          df = df.rename(index=rename)
          df.rename(index=tax_rename).to_csv(analysis_folder+'differential_abundance_summary/'+r.replace('/all_results.tsv', '.csv'))
          df = df.loc[:, ['qval']]
          df = df.rename(columns={'qval':da})
        elif da == 'aldex':
          df = pd.read_csv(analysis_folder+'differential_abundance_June25_2024/'+r, index_col=0, header=0)
          df.rename(index=tax_rename).to_csv(analysis_folder+'differential_abundance_summary/'+r)
          df = df.loc[:, ['glm.eBH']]
          df = df.rename(columns={'glm.eBH':da})
        elif 'ancombc2' in da:
          df = pd.read_csv(analysis_folder+'differential_abundance_June25_2024/'+r, index_col=1, header=0)
          df.rename(index=tax_rename).to_csv(analysis_folder+'differential_abundance_summary/'+r.replace('tsv', 'csv'))
          df = df.loc[:, ['q_'+ds]]
          df = df.rename(columns={'q_'+ds:da})
        elif da == 'ancombc':
          df = pd.read_csv(analysis_folder+'differential_abundance_June25_2024/'+r, index_col=1, header=0)
          df.rename(index=tax_rename).to_csv(analysis_folder+'differential_abundance_summary/'+r.replace('tsv', 'csv'))
          df = df.loc[:, ['q_val.'+ds]]
          df = df.rename(columns={'q_val.'+ds:da})
        elif da == 'radEMU':
          df = pd.read_csv(analysis_folder+'differential_abundance_June25_2024/'+r, index_col=2, header=0)
          df.rename(index=tax_rename).to_csv(analysis_folder+'differential_abundance_summary/'+r.replace('tsv', 'csv'))
          df = df.loc[:, ['pval']]
          df = df.rename(columns={'pval':da})
        this_df.append(df)
  print(this_df)
  new_df = this_df[0]
  for a in range(1, len(this_df)):
    new_df[this_df[a].columns[0]] = ''
    for row in this_df[a].index.values:
      new_df.loc[row, this_df[a].columns[0]] = this_df[a].loc[row, this_df[a].columns[0]]
  new_df = new_df.replace('',1)
  results_df.append(new_df)
  
tax = pd.read_csv(analysis_folder+'files/taxonomy.csv', index_col=0, header=0)
tax_rename = {}
for row in tax.index.values:
  tax_rename[row] = tax.loc[row, 'Genus']

for d in range(len(results_df)):
  results_df[d] = results_df[d].rename(index=tax_rename)
  results_df[d] = results_df[d].sort_index(axis=0, ascending=False)
  results_df[d] = results_df[d].apply(pd.to_numeric)

fig = plt.figure(figsize=(20,20))
for d in range(len(results_df)):
  ax = plt.subplot2grid((1,4),(0,d))
  plt.sca(ax)
  hm = plt.pcolor(results_df[d], vmin=0, vmax=0.1, cmap='viridis_r', edgecolor='k')
  for r in range(len(results_df[d].index.values)):
    for c in range(len(results_df[d].columns)):
      val = results_df[d].iloc[r, c]
      if val < 0.05: fc = 'k'
      else: fc = 'w'
      if val < 0.1: val = round(val, 3)
      else: val = round(val, 2)
      tx = plt.text(c+0.5, r+0.5, str(val), color=fc, fontsize=8, ha='center', va='center')
  xt = plt.xticks([a+0.5 for a in range(len(da_test))], da_test, rotation=90)
  tt = ax.xaxis.tick_top()
  if d == 0:
    t = plt.yticks([x+0.5 for x in range(len(results_df[d].index.values))], results_df[d].index.values)
  else:
    t = plt.yticks([x+0.5 for x in range(len(results_df[d].index.values))], [])
  ti = plt.title(titles[d], fontweight='bold')
  
plt.savefig(analysis_folder+'figures/differential_abundance_comparison_overall.png', dpi=600, bbox_inches='tight')

      
          

```

Overall just showing significant or not:
```{python}
data_split = ['CASE_CONTROL', 'Crohn_case_control', 'UC_case_control', 'Both_case_control']
titles = ['Overall', "Crohn's disease", "Ulcerative colitis", "Both"]
all_results = os.listdir(analysis_folder+'differential_abundance_June25_2024/')
maaslin = [f for f in all_results if 'maaslin' in f]
maaslin = [f for f in maaslin if 'males' not in f]
maaslin = [f+'/all_results.tsv' for f in maaslin if 'model0' in f]
all_results = [f for f in all_results if '.csv' in f]
all_results = sorted([f for f in all_results if 'males' not in f])
all_results = [f for f in all_results if 'model0' in f]
all_results = sorted(all_results+maaslin)

da_test = ['aldex', 'ancombc2', 'ancombc', 'maaslin2', 'radEMU']
results_df = []
for ds in data_split:
  this_df = []
  for da in da_test:
    for r in all_results:
      if da+'_'+ds in r:
        if '.tsv' in r: 
          df = pd.read_csv(analysis_folder+'differential_abundance_June25_2024/'+r, sep='\t', index_col=0, header=0)
          df = df.loc[:, ['qval']]
          rename = {}
          for row in df.index.values:
            if row[0] == 'X': rename[row] = row[1:]
          df = df.rename(index=rename).rename(columns={'qval':da})
        elif da == 'aldex':
          df = pd.read_csv(analysis_folder+'differential_abundance_June25_2024/'+r, index_col=0, header=0)
          df = df.loc[:, ['glm.eBH']]
          df = df.rename(columns={'glm.eBH':da})
        elif 'ancombc2' in da:
          df = pd.read_csv(analysis_folder+'differential_abundance_June25_2024/'+r, index_col=1, header=0)
          df = df.loc[:, ['q_'+ds]]
          df = df.rename(columns={'q_'+ds:da})
        elif da == 'ancombc':
          df = pd.read_csv(analysis_folder+'differential_abundance_June25_2024/'+r, index_col=1, header=0)
          df = df.loc[:, ['q_val.'+ds]]
          df = df.rename(columns={'q_val.'+ds:da})
        elif da == 'radEMU':
          df = pd.read_csv(analysis_folder+'differential_abundance_June25_2024/'+r, index_col=2, header=0)
          df = df.loc[:, ['pval']]
          df = df.rename(columns={'pval':da})
        this_df.append(df)
  new_df = this_df[0]
  for a in range(1, len(this_df)):
    new_df[this_df[a].columns[0]] = ''
    for row in this_df[a].index.values:
      new_df.loc[row, this_df[a].columns[0]] = this_df[a].loc[row, this_df[a].columns[0]]
  new_df = new_df.replace('',1)
  results_df.append(new_df)
  
tax = pd.read_csv(analysis_folder+'files/taxonomy.csv', index_col=0, header=0)
tax_rename = {}
for row in tax.index.values:
  tax_rename[row] = tax.loc[row, 'Genus']
  
taxa_to_include = []

results_df_for_next = list(results_df)

for d in range(len(results_df)):
  results_df[d] = results_df[d].rename(index=tax_rename)
  results_df[d] = results_df[d].sort_index(axis=0, ascending=False)
  results_df[d] = results_df[d].apply(pd.to_numeric)
  results_df[d][results_df[d] <= 0.1] = 0
  results_df[d][results_df[d] > 0.1] = 1
  red_df = results_df[d].copy(deep=True)
  red_df = red_df[red_df.min(axis=1) < 1]
  for row in red_df.index.values:
    if row not in taxa_to_include:
      taxa_to_include.append(row)

taxa_to_include = sorted(taxa_to_include)

for d in range(len(results_df)):
  results_df[d] = results_df[d].loc[taxa_to_include, :]
  results_df[d] = results_df[d].sort_index(axis=0, ascending=False)

fig = plt.figure(figsize=(10,6))
for d in range(len(results_df)):
  ax = plt.subplot2grid((1,4),(0,d))
  plt.sca(ax)
  hm = plt.pcolor(results_df[d], vmin=0, vmax=1, cmap='viridis_r', edgecolor='k')
  for r in range(len(results_df[d].index.values)):
    for c in range(len(results_df[d].columns)):
      val = results_df[d].iloc[r, c]
      if val <= 1: fc = 'k'
      else: fc = 'w'
      # if val <=  0.1: val = round(val, 3)
      # else: val = round(val, 2)
      # tx = plt.text(c+0.5, r+0.5, str(val), color=fc, fontsize=8, ha='center', va='center')
      if val <= 0.1:
        sc = plt.scatter(c+0.5, r+0.5, marker='*', color='k', s=60)
  xt = plt.xticks([a+0.5 for a in range(len(da_test))], da_test, rotation=90)
  tt = ax.xaxis.tick_top()
  if d == 0:
    t = plt.yticks([x+0.5 for x in range(len(results_df[d].index.values))], results_df[d].index.values)
  else:
    t = plt.yticks([x+0.5 for x in range(len(results_df[d].index.values))], [])
  ti = plt.title(titles[d], fontweight='bold')

plt.savefig(analysis_folder+'figures/differential_abundance_comparison_overall_reduced.png', dpi=600, bbox_inches='tight')

      
          

```

## Make abundance and DA plots

This will use the results_df that has been generated in the code chunk above!

Top 20 genera with those that are significant and relative abundance:
```{python}
ft = pd.read_csv(analysis_folder+'files/genus_table_rare.csv', index_col=0, header=0)
tax = pd.read_csv(analysis_folder+'files/genus_taxonomy.tsv', index_col=0, header=0)
tree_name = analysis_folder+'files/genus_tree.nwk'
md = pd.read_csv(analysis_folder+'files/metadata_crohns_UC.csv', index_col=0, header=0)

results_df = list(results_df_for_next[:3])
names = ['IBD', 'Crohns', 'UC']
for r in range(len(results_df)):
  results_df[r][results_df[r] <= 0.1] = 0
  results_df[r][results_df[r] > 0.1] = 1
  results_df[r] = 1-results_df[r]
  results_df[r][names[r]] = results_df[r].sum(axis=1)
  results_df[r] = results_df[r].loc[:, [names[r]]]

da_results = pd.concat(results_df).fillna(value=0)
da_results = da_results.groupby(by=da_results.index, axis=0).sum()
#da_results = da_results.rename(index=tax_rename)

all_results = list(results_df_for_next[:3])

ft_ra = ft.copy(deep=True)
ft_ra = ft_ra.divide(ft_ra.sum(axis=0), axis=1).multiply(100)
ft_ra['Mean'] = ft_ra.mean(axis=1)
ft_ra = ft_ra.sort_values(by=['Mean'], ascending=False)
ft_ra = ft_ra.iloc[:20, :]

#axes
fig = plt.figure(figsize=(15,7))
#order_ax = plt.subplot2grid((20,34),(2,0), rowspan=18, colspan=1)
tree_ax = plt.subplot2grid((20,34),(2,1), rowspan=18, colspan=6, frameon=False)
ibd_prev = plt.subplot2grid((20,34),(2,10), rowspan=18, colspan=3)
ibd_abun = plt.subplot2grid((20,34),(2,13), rowspan=18, colspan=3)
crohns_prev = plt.subplot2grid((20,34),(2,17), rowspan=18, colspan=3)
crohns_abun = plt.subplot2grid((20,34),(2,20), rowspan=18, colspan=3)
uc_prev = plt.subplot2grid((20,34),(2,24), rowspan=18, colspan=3)
uc_abun = plt.subplot2grid((20,34),(2,27), rowspan=18, colspan=3)
da_ax = plt.subplot2grid((20,34),(2,31), rowspan=18, colspan=3)
vals = [[10, 13], [17, 20], [24, 27]]

tree = Tree(tree_name, format=1)
tree.prune(ft_ra.index.values)
tree_name = tree_name.replace('.nwk', '_reduced.nwk')
tree.write(outfile=tree_name, format=1)
tree = Phylo.read(tree_name, "newick")
leaves = draw_tree(tree, axes=tree_ax, end_same=True, plot_labels=False)

ordering = []
#print(leaves)

for leaf in leaves[1:]:
  if leaf[0] in ft_ra.index.values:
    tx = tree_ax.text(leaf[1], leaf[2], '  $'+tax_rename[leaf[0]].replace('g__', '')+'$', ha='left', va='center')
    ordering.append(leaf[0])

plt.sca(tree_ax)
yl = plt.ylim([leaves[1][2]-0.5, leaves[-1][2]+0.5])

da_results = da_results.loc[ordering, :]
da_hm = da_ax.pcolor(da_results, edgecolor='k', cmap='Blues', vmin=0, vmax=3)
plt.sca(da_ax)
yt = plt.yticks([])
xt = plt.xticks([0.5, 1.5, 2.5], ['IBD', 'Crohns', 'UC'], fontweight='bold', rotation=90)
#ti = plt.title('Differential\nabundance', fontweight='bold')
tx = plt.text(0.5, 1.17, 'Differential\nabundance', fontweight='bold', transform=da_ax.transAxes, ha='center', va='center')
tt = da_ax.xaxis.tick_top()

markers = ['o', '>', '<', 's', 'P']
tests = ['aldex', 'ancombc2', 'ancombc', 'maaslin2', 'radEMU']
locs = [0.1, 0.3, 0.5, 0.7, 0.9]
test_names = ['ALDEx2', 'ANCOM-BC2', 'ANCOM-BC', 'MaAsLin2', 'radEmu']
for a in range(len(all_results)):
  all_results[a] = 1-all_results[a]
  all_results[a] = all_results[a].loc[ordering, :]
  for r in range(len(all_results[a].index.values)):
    for c in range(len(all_results[a].columns)):
      if all_results[a].iloc[r, c] in [1, 1.0, '1']:
        if sum(all_results[a].iloc[r, :].values) > 2: mc = 'w'
        else: mc = 'k'
        sc = da_ax.scatter(a+locs[c], r+0.5, marker=markers[c], color=mc, s=10)

handles = [Line2D([0], [0], marker=markers[h], color='w', label=test_names[h], markerfacecolor='k', markersize=8) for h in range(len(test_names))]
handles += [Line2D([0], [0], marker='s', color='w', label=name.replace('IBD Controls', 'Controls').replace('IBD Cases', 'Cases'), markerfacecolor=color_dict[name], markersize=8) for name in ['IBD Cases', 'IBD Controls']]
empty_marker = Line2D([0], [0], marker='s', color='w', label='', markerfacecolor='w', markeredgecolor='w', markersize=2)
handles.append(empty_marker), handles.append(empty_marker), handles.append(empty_marker)

tree_ax.legend(handles=handles, loc='upper left', bbox_to_anchor=(0,1.2), ncols=2, fontsize=8)

axes = [[ibd_prev, ibd_abun], [crohns_prev, crohns_abun], [uc_prev, uc_abun]]
on = ['CASE_CONTROL', 'Crohn_case_control', 'UC_case_control']
names = ['IBD', 'Crohns', 'UC']

ft_ra = ft_ra.loc[ordering, :].drop('Mean', axis=1)

for a in range(len(axes)):
  cases = md[md[on[a]] == 1].index.values
  controls = md[md[on[a]] == 0].index.values
  ft_ra_red = ft_ra.copy(deep=True)
  ft_ra_red_cases = ft_ra_red.loc[:, cases]
  ft_ra_red_controls = ft_ra_red.loc[:, controls]
  cases_prev = ft_ra_red_cases.copy(deep=True)
  controls_prev = ft_ra_red_controls.copy(deep=True)
  cases_prev[cases_prev > 0] = 1
  controls_prev[controls_prev > 0] = 1
  cases_prev['Cases'] = cases_prev.mean(axis=1)
  controls_prev['Controls'] = controls_prev.mean(axis=1)
  prev = pd.concat([cases_prev.loc[:, ['Cases']], controls_prev.loc[:, ['Controls']]]).fillna(value=0)
  prev = prev.groupby(by=prev.index, axis=0).sum().loc[ordering, :]
  ft_ra_red_cases['Cases'] = ft_ra_red_cases.mean(axis=1)
  ft_ra_red_controls['Controls'] = ft_ra_red_controls.mean(axis=1)
  relabun = pd.concat([ft_ra_red_cases.loc[:, ['Cases']], ft_ra_red_controls.loc[:, ['Controls']]]).fillna(value=0)
  relabun = relabun.groupby(by=relabun.index, axis=0).sum().loc[ordering, :]
  prev_hm = axes[a][0].pcolor(prev, edgecolor='k', cmap='Oranges', vmin=0.7, vmax=1)
  abun_hm = axes[a][1].pcolor(relabun, edgecolor='k', cmap='viridis', vmin=0, vmax=15)
  for r in range(len(prev.index.values)):
    for c in range(len(prev.columns)):
      prev_val = prev.iloc[r, c]
      abun_val = relabun.iloc[r, c]
      if prev_val < 0.85: pc = 'k'
      else: pc = 'w'
      if abun_val < 7.5: ac = 'w'
      else: ac = 'k'
      if abun_val < 1: abun_val = round(abun_val, 2)
      elif abun_val < 10: abun_val = round(abun_val, 1)
      else: abun_val = int(abun_val)
      tx = axes[a][0].text(c+0.5, r+0.5, str(round(prev_val, 2)), ha='center', va='center', color=pc)
      tx = axes[a][1].text(c+0.5, r+0.5, str(abun_val), ha='center', va='center', color=ac)
  names_titles = ['Prevalence', 'Relative\nabundance (%)']
  for b in range(2):
    plt.sca(axes[a][b])
    #xt = plt.xticks([0.5, 1.5], ['Cases', 'Controls'], fontweight='bold', rotation=90)
    xt = plt.xticks([])
    yt = plt.yticks([])
    if b == 0:
      tx = plt.text(1.05, 1.17, names[a], fontweight='bold', transform=axes[a][b].transAxes, ha='center', va='center')
    ax = plt.subplot2grid((20,34),(1,vals[a][b]), rowspan=1, colspan=3)
    plt.sca(ax)
    ti = plt.title(names_titles[b], fontweight='bold', fontsize=8)
    xl = plt.xticks([])
    yl = plt.yticks([])
    ba = ax.bar([0,1], [1,1], color=[color_dict['IBD Cases'], color_dict['IBD Controls']], width=1, edgecolor='k')
    xl = plt.xlim([-0.5, 1.5])
    yl = plt.ylim([0, 1])

plt.savefig(analysis_folder+'figures/differential_abundance_and_abundance.png', dpi=600, bbox_inches='tight')

```

Just plotting abundance of top 20 genera:
```{python}
ft = pd.read_csv(analysis_folder+'files/genus_table_rare.csv', index_col=0, header=0)
tax = pd.read_csv(analysis_folder+'files/genus_taxonomy.tsv', index_col=0, header=0)
tree_name = analysis_folder+'files/genus_tree.nwk'
md = pd.read_csv(analysis_folder+'files/metadata_crohns_UC.csv', index_col=0, header=0)

ft_ra = ft.copy(deep=True)
ft_ra = ft_ra.divide(ft_ra.sum(axis=0), axis=1).multiply(100)
ft_ra['Mean'] = ft_ra.mean(axis=1)
ft_ra = ft_ra.sort_values(by=['Mean'], ascending=False)
ft_ra = ft_ra.iloc[:20, :]

#axes
fig = plt.figure(figsize=(17,7))
tree_ax = plt.subplot2grid((20,40),(2,1), rowspan=18, colspan=6, frameon=False)
ibd_prev = plt.subplot2grid((20,40),(2,10), rowspan=18, colspan=2)
ibd_abun = plt.subplot2grid((20,40),(2,12), rowspan=18, colspan=2)
ibd_abun_box = plt.subplot2grid((20,40),(2,14), rowspan=18, colspan=5)
ibd_label = plt.subplot2grid((30,40),(0,10), rowspan=1, colspan=9, frameon=False)
crohns_prev = plt.subplot2grid((20,40),(2,20), rowspan=18, colspan=2)
crohns_abun = plt.subplot2grid((20,40),(2,22), rowspan=18, colspan=2)
crohns_abun_box = plt.subplot2grid((20,40),(2,24), rowspan=18, colspan=5)
crohns_label = plt.subplot2grid((30,40),(0,20), rowspan=1, colspan=9, frameon=False)
uc_prev = plt.subplot2grid((20,40),(2,30), rowspan=18, colspan=2)
uc_abun = plt.subplot2grid((20,40),(2,32), rowspan=18, colspan=2)
uc_abun_box = plt.subplot2grid((20,40),(2,34), rowspan=18, colspan=5)
uc_label = plt.subplot2grid((30,40),(0,30), rowspan=1, colspan=9, frameon=False)

tree = Tree(tree_name, format=1)
tree.prune(ft_ra.index.values)
tree_name = tree_name.replace('.nwk', '_reduced.nwk')
tree.write(outfile=tree_name, format=1)
tree = Phylo.read(tree_name, "newick")
leaves = draw_tree(tree, axes=tree_ax, end_same=True, plot_labels=False)

ordering = []

for leaf in leaves[1:]:
  if leaf[0] in ft_ra.index.values:
    tx = tree_ax.text(leaf[1], leaf[2], '  $'+tax_rename[leaf[0]].replace('g__', '')+'$', ha='left', va='center')
    ordering.append(leaf[0])

plt.sca(tree_ax)
yl = plt.ylim([leaves[1][2]-0.5, leaves[-1][2]+0.5])

handles = [Line2D([0], [0], marker='s', color='w', label=name.replace('IBD Controls', 'Controls').replace('IBD Cases', 'Cases'), markerfacecolor=color_dict[name], markersize=8) for name in ['IBD Cases', 'IBD Controls']]
empty_marker = Line2D([0], [0], marker='s', color='w', label='', markerfacecolor='w', markeredgecolor='w', markersize=2)
#handles.append(empty_marker), handles.append(empty_marker), handles.append(empty_marker)

tree_ax.legend(handles=handles, loc='upper left', bbox_to_anchor=(0,1.08), ncols=2, fontsize=8)

vals = [[10, 12], [20, 22], [30, 32]]
axes = [[ibd_prev, ibd_abun, ibd_abun_box, ibd_label], [crohns_prev, crohns_abun, crohns_abun_box, crohns_label], [uc_prev, uc_abun, uc_abun_box, uc_label]]
on = ['CASE_CONTROL', 'Crohn_case_control', 'UC_case_control']
names = ['IBD', 'Crohns', 'UC']

ft_ra = ft_ra.loc[ordering, :].drop('Mean', axis=1)

for a in range(len(axes)):
  cases = md[md[on[a]] == 1].index.values
  controls = md[md[on[a]] == 0].index.values
  ft_ra_red = ft_ra.copy(deep=True)
  ft_ra_red_cases = ft_ra_red.loc[:, cases]
  ft_ra_red_controls = ft_ra_red.loc[:, controls]
  cases_prev = ft_ra_red_cases.copy(deep=True)
  controls_prev = ft_ra_red_controls.copy(deep=True)
  cases_prev[cases_prev > 0] = 1
  controls_prev[controls_prev > 0] = 1
  cases_prev['Cases'] = cases_prev.mean(axis=1)
  controls_prev['Controls'] = controls_prev.mean(axis=1)
  prev = pd.concat([cases_prev.loc[:, ['Cases']], controls_prev.loc[:, ['Controls']]]).fillna(value=0)
  prev = prev.groupby(by=prev.index, axis=0).sum().loc[ordering, :]
  ft_ra_red_cases['Cases'] = ft_ra_red_cases.mean(axis=1)
  ft_ra_red_controls['Controls'] = ft_ra_red_controls.mean(axis=1)
  relabun = pd.concat([ft_ra_red_cases.loc[:, ['Cases']], ft_ra_red_controls.loc[:, ['Controls']]]).fillna(value=0)
  relabun = relabun.groupby(by=relabun.index, axis=0).sum().loc[ordering, :]
  prev_hm = axes[a][0].pcolor(prev, edgecolor='k', cmap='Oranges', vmin=0.7, vmax=1)
  abun_hm = axes[a][1].pcolor(relabun, edgecolor='k', cmap='viridis', vmin=0, vmax=15)
  ft_ra_red_cases = ft_ra_red_cases.drop('Cases', axis=1)
  ft_ra_red_controls = ft_ra_red_controls.drop('Controls', axis=1)
  for r in range(len(prev.index.values)):
    vals_cases = ft_ra_red_cases.iloc[r, :].values
    vals_controls = ft_ra_red_controls.iloc[r, :].values
    sc = axes[a][2].scatter(vals_cases, np.random.normal(r+0.25, scale=0.05, size=len(vals_cases)), marker='o', color=color_dict['IBD Cases'], alpha=0.5, s=2)
    sc = axes[a][2].scatter(vals_controls, np.random.normal(r-0.25, scale=0.05, size=len(vals_controls)), marker='o', color=color_dict['IBD Controls'], alpha=0.5, s=2)
    box = axes[a][2].boxplot([vals_cases, vals_controls], positions=[r+0.25, r-0.25], widths=0.3, showfliers=False, vert=False)
    for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: bi = plt.setp(box[item], color='k')
    li = axes[a][2].plot([-5, 70], [r+0.5, r+0.5], 'k', linewidth=1)
    for c in range(len(prev.columns)):
      prev_val = prev.iloc[r, c]
      abun_val = relabun.iloc[r, c]
      if prev_val < 0.85: pc = 'k'
      else: pc = 'w'
      if abun_val < 7.5: ac = 'w'
      else: ac = 'k'
      if abun_val < 1: abun_val = round(abun_val, 2)
      elif abun_val < 10: abun_val = round(abun_val, 1)
      else: abun_val = int(abun_val)
      tx = axes[a][0].text(c+0.5, r+0.5, str(round(prev_val, 2)), ha='center', va='center', color=pc, fontsize=8)
      tx = axes[a][1].text(c+0.5, r+0.5, str(abun_val), ha='center', va='center', color=ac, fontsize=8)
  names_titles = ['Prev.', 'Rel.\nabun. (%)']
  for b in range(2):
    plt.sca(axes[a][b])
    xt = plt.xticks([])
    yt = plt.yticks([])
    ax = plt.subplot2grid((40,40),(3,vals[a][b]), rowspan=1, colspan=2)
    plt.sca(ax)
    ti = plt.title(names_titles[b], fontweight='bold', fontsize=8)
    xl = plt.xticks([])
    yl = plt.yticks([])
    ba = ax.bar([0,1], [1,1], color=[color_dict['IBD Cases'], color_dict['IBD Controls']], width=1, edgecolor='k')
    xl = plt.xlim([-0.5, 1.5])
    yl = plt.ylim([0, 1])
  plt.sca(axes[a][2])
  xt = plt.yticks([]), plt.title('Relative abundance (%)', fontweight='bold', fontsize=8), plt.xticks(fontsize=8)
  yl = plt.ylim([-0.5, 19.5])
  xl = plt.xlim([-2, 60])
  plt.sca(axes[a][3])
  ti = plt.text(0.5, 1, names[a], fontweight='bold', ha='center', va='bottom')
  li = plt.plot([0, 1], [0.9, 0.9], 'k')
  xl = plt.xlim([0, 1]), plt.ylim([0, 1])
  xt = plt.xticks([]), plt.yticks([])

plt.savefig(analysis_folder+'figures/abundance.png', dpi=600, bbox_inches='tight')

```

Plotting only significant with relative abundance:
```{python}
ft = pd.read_csv(analysis_folder+'files/genus_table_rare.csv', index_col=0, header=0)
tax = pd.read_csv(analysis_folder+'files/genus_taxonomy.tsv', index_col=0, header=0)
tree_name = analysis_folder+'files/genus_tree.nwk'
md = pd.read_csv(analysis_folder+'files/metadata_crohns_UC.csv', index_col=0, header=0)

results_df = list(results_df_for_next[:3])
names = ['IBD', 'Crohns', 'UC']
for r in range(len(results_df)):
  results_df[r][results_df[r] <= 0.1] = 0
  results_df[r][results_df[r] > 0.1] = 1
  results_df[r] = 1-results_df[r]
  results_df[r][names[r]] = results_df[r].sum(axis=1)
  results_df[r] = results_df[r].loc[:, [names[r]]]

da_results = pd.concat(results_df).fillna(value=0)
da_results = da_results.groupby(by=da_results.index, axis=0).sum()
#da_results = da_results.rename(index=tax_rename)
da_results = da_results[da_results.max(axis=1) >= 2]
da_results['Names'] = [tax_rename[d] for d in da_results.index.values]
da_results = da_results.sort_values(by=['Names'], ascending=False)
da_results = da_results.drop('Names', axis=1)

all_results = list(results_df_for_next[:3])

fig = plt.figure(figsize=(15,7))
da_ax = plt.subplot2grid((20,35), (0,0), rowspan=20, colspan=5)

da_hm = da_ax.pcolor(da_results, edgecolor='k', cmap='Blues', vmin=0, vmax=4)
plt.sca(da_ax)
yt = plt.yticks([a+0.5 for a in range(len(da_results.index.values))], [tax_rename[a] for a in da_results.index.values])
xt = plt.xticks([0.5, 1.5, 2.5], ['IBD', 'Crohns', 'UC'], fontweight='bold', rotation=90)
#ti = plt.title('Differential\nabundance', fontweight='bold')
tx = plt.text(0.5, 1.17, 'Differential\nabundance', fontweight='bold', transform=da_ax.transAxes, ha='center', va='center')
tt = da_ax.xaxis.tick_top()

markers = ['o', '>', '<', 's', 'P']
tests = ['aldex', 'ancombc2', 'ancombc', 'maaslin2', 'radEMU']
locs = [0.1, 0.3, 0.5, 0.7, 0.9]
test_names = ['ALDEx2', 'ANCOM-BC2', 'ANCOM-BC', 'MaAsLin2', 'radEmu']
for a in range(len(all_results)):
  all_results[a] = 1-all_results[a]
  all_results[a] = all_results[a].loc[da_results.index.values, :]
  for r in range(len(all_results[a].index.values)):
    for c in range(len(all_results[a].columns)):
      if all_results[a].iloc[r, c] in [1, 1.0, '1']:
        if sum(all_results[a].iloc[r, :].values) > 2: mc = 'w'
        else: mc = 'k'
        sc = da_ax.scatter(a+locs[c], r+0.5, marker=markers[c], color=mc, s=10)
        
handles = [Line2D([0], [0], marker=markers[h], color='w', label=test_names[h], markerfacecolor='k', markersize=8) for h in range(len(test_names))]
handles += [Line2D([0], [0], marker='s', color='w', label=name.replace('IBD Controls', 'Controls').replace('IBD Cases', 'Cases'), markerfacecolor=color_dict[name], markersize=8) for name in ['IBD Cases', 'IBD Controls']]
empty_marker = Line2D([0], [0], marker='s', color='w', label='', markerfacecolor='w', markeredgecolor='w', markersize=2)
handles.append(empty_marker), handles.append(empty_marker), handles.append(empty_marker)

da_ax.legend(handles=handles, loc='upper right', bbox_to_anchor=(-0.2,1.2), ncols=2, fontsize=8)

sr, sc = 0, 7
subplots = [[sr, sc], [sr+12, sc], [sr, sc+5], [sr+12, sc+5], [sr, sc+10], [sr+12, sc+10], [sr, sc+15], [sr+12, sc+15], [sr, sc+20], [sr+12, sc+20], [sr, sc+25], [sr+12, sc+25]]
on = ['CASE_CONTROL', 'Crohn_case_control', 'UC_case_control']

ft_ra = ft.copy(deep=True)
ft_ra = ft_ra.divide(ft_ra.sum(axis=0), axis=1).multiply(100)

da_results = da_results.iloc[::-1]
count = 0      
for r in range(len(da_results.index.values)):
  for c in range(len(da_results.columns)):
    if da_results.iloc[r, c] >= 2:
      ax = plt.subplot2grid((20,35), (subplots[count][0], subplots[count][1]), rowspan=8, colspan=3)
      if count < 2: yl = ax.set_ylabel('Relative abundance (%)', fontsize=8)
      count += 1
      name = tax_rename[da_results.index.values[r]]+'\n'
      name += da_results.columns[c]+' $vs$ controls'
      ti = ax.set_title(name, fontweight='bold', fontsize=8)
      cases = md[md[on[c]] == 1].index.values
      controls = md[md[on[c]] == 0].index.values
      ft_ra_red = ft_ra.copy(deep=True)
      vals_cases = ft_ra_red.loc[da_results.index.values[r], cases].values
      vals_controls = ft_ra_red.loc[da_results.index.values[r], controls].values
      sc = ax.scatter(np.random.normal(0, scale=0.1, size=len(vals_cases)), vals_cases, marker='o', color=color_dict['IBD Cases'], alpha=0.5, s=20)
      sc = ax.scatter(np.random.normal(1, scale=0.1, size=len(vals_controls)), vals_controls, marker='o', color=color_dict['IBD Controls'], alpha=0.5, s=20)
      box = ax.boxplot([vals_cases, vals_controls], positions=[0, 1], widths=0.6, showfliers=False)
      for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: bi = plt.setp(box[item], color='k')
      xt = plt.xticks([0, 1], ['Cases', 'Controls'], rotation=90, fontsize=8)
      

plt.savefig(analysis_folder+'figures/differential_abundance_with_abundance_of_significant.png', dpi=600, bbox_inches='tight')

```

Plotting only significant with CLR abundance:
```{python}
ft_ra = pd.read_csv(analysis_folder+'files/genus_table_clr.csv', index_col=0, header=0)
tax = pd.read_csv(analysis_folder+'files/genus_taxonomy.tsv', index_col=0, header=0)
tree_name = analysis_folder+'files/genus_tree.nwk'
md = pd.read_csv(analysis_folder+'files/metadata_crohns_UC.csv', index_col=0, header=0)

results_df = list(results_df_for_next[:3])
names = ['IBD', 'Crohns', 'UC']
for r in range(len(results_df)):
  results_df[r][results_df[r] <= 0.1] = 0
  results_df[r][results_df[r] > 0.1] = 1
  results_df[r] = 1-results_df[r]
  results_df[r][names[r]] = results_df[r].sum(axis=1)
  results_df[r] = results_df[r].loc[:, [names[r]]]

da_results = pd.concat(results_df).fillna(value=0)
da_results = da_results.groupby(by=da_results.index, axis=0).sum()
#da_results = da_results.rename(index=tax_rename)
da_results = da_results[da_results.max(axis=1) >= 2]
da_results['Names'] = [tax_rename[d] for d in da_results.index.values]
da_results = da_results.sort_values(by=['Names'], ascending=False)
da_results = da_results.drop('Names', axis=1)

all_results = list(results_df_for_next[:3])

fig = plt.figure(figsize=(15,7))
da_ax = plt.subplot2grid((20,35), (0,0), rowspan=20, colspan=5)

da_hm = da_ax.pcolor(da_results, edgecolor='k', cmap='Blues', vmin=0, vmax=4)
plt.sca(da_ax)
yt = plt.yticks([a+0.5 for a in range(len(da_results.index.values))], [tax_rename[a] for a in da_results.index.values])
xt = plt.xticks([0.5, 1.5, 2.5], ['IBD', 'Crohns', 'UC'], fontweight='bold', rotation=90)
#ti = plt.title('Differential\nabundance', fontweight='bold')
tx = plt.text(0.5, 1.17, 'Differential\nabundance', fontweight='bold', transform=da_ax.transAxes, ha='center', va='center')
tt = da_ax.xaxis.tick_top()

markers = ['o', '>', '<', 's', 'P']
tests = ['aldex', 'ancombc2', 'ancombc', 'maaslin2', 'radEMU']
locs = [0.1, 0.3, 0.5, 0.7, 0.9]
test_names = ['ALDEx2', 'ANCOM-BC2', 'ANCOM-BC', 'MaAsLin2', 'radEmu']
for a in range(len(all_results)):
  all_results[a] = 1-all_results[a]
  all_results[a] = all_results[a].loc[da_results.index.values, :]
  for r in range(len(all_results[a].index.values)):
    for c in range(len(all_results[a].columns)):
      if all_results[a].iloc[r, c] in [1, 1.0, '1']:
        if sum(all_results[a].iloc[r, :].values) > 2: mc = 'w'
        else: mc = 'k'
        sc = da_ax.scatter(a+locs[c], r+0.5, marker=markers[c], color=mc, s=10)
        
handles = [Line2D([0], [0], marker=markers[h], color='w', label=test_names[h], markerfacecolor='k', markersize=8) for h in range(len(test_names))]
handles += [Line2D([0], [0], marker='s', color='w', label=name.replace('IBD Controls', 'Controls').replace('IBD Cases', 'Cases'), markerfacecolor=color_dict[name], markersize=8) for name in ['IBD Cases', 'IBD Controls']]
empty_marker = Line2D([0], [0], marker='s', color='w', label='', markerfacecolor='w', markeredgecolor='w', markersize=2)
handles.append(empty_marker), handles.append(empty_marker), handles.append(empty_marker)

da_ax.legend(handles=handles, loc='upper right', bbox_to_anchor=(-0.2,1.2), ncols=2, fontsize=8)

sr, sc = 0, 7
subplots = [[sr, sc], [sr+12, sc], [sr, sc+5], [sr+12, sc+5], [sr, sc+10], [sr+12, sc+10], [sr, sc+15], [sr+12, sc+15], [sr, sc+20], [sr+12, sc+20], [sr, sc+25], [sr+12, sc+25]]
on = ['CASE_CONTROL', 'Crohn_case_control', 'UC_case_control']

da_results = da_results.iloc[::-1]
count = 0      
for r in range(len(da_results.index.values)):
  for c in range(len(da_results.columns)):
    if da_results.iloc[r, c] >= 2:
      ax = plt.subplot2grid((20,35), (subplots[count][0], subplots[count][1]), rowspan=8, colspan=3)
      if count < 2: yl = ax.set_ylabel('CLR abundance', fontsize=8)
      count += 1
      name = tax_rename[da_results.index.values[r]]+'\n'
      name += da_results.columns[c]+' $vs$ controls'
      ti = ax.set_title(name, fontweight='bold', fontsize=8)
      cases = md[md[on[c]] == 1].index.values
      controls = md[md[on[c]] == 0].index.values
      ft_ra_red = ft_ra.copy(deep=True)
      vals_cases = ft_ra_red.loc[da_results.index.values[r], cases].values
      vals_controls = ft_ra_red.loc[da_results.index.values[r], controls].values
      sc = ax.scatter(np.random.normal(0, scale=0.1, size=len(vals_cases)), vals_cases, marker='o', color=color_dict['IBD Cases'], alpha=0.5, s=20)
      sc = ax.scatter(np.random.normal(1, scale=0.1, size=len(vals_controls)), vals_controls, marker='o', color=color_dict['IBD Controls'], alpha=0.5, s=20)
      box = ax.boxplot([vals_cases, vals_controls], positions=[0, 1], widths=0.6, showfliers=False)
      for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: bi = plt.setp(box[item], color='k')
      xt = plt.xticks([0, 1], ['Cases', 'Controls'], rotation=90, fontsize=8)
      

plt.savefig(analysis_folder+'figures/differential_abundance_with_abundance_of_significant_clr.png', dpi=600, bbox_inches='tight')

```

Plotting only significant with rCLR abundance:
```{python}
ft_ra = pd.read_csv(analysis_folder+'files/genus_table_rclr.csv', index_col=0, header=0)
tax = pd.read_csv(analysis_folder+'files/genus_taxonomy.tsv', index_col=0, header=0)
tree_name = analysis_folder+'files/genus_tree.nwk'
md = pd.read_csv(analysis_folder+'files/metadata_crohns_UC.csv', index_col=0, header=0)

results_df = list(results_df_for_next[:3])
names = ['IBD', 'Crohns', 'UC']
for r in range(len(results_df)):
  results_df[r][results_df[r] <= 0.1] = 0
  results_df[r][results_df[r] > 0.1] = 1
  results_df[r] = 1-results_df[r]
  results_df[r][names[r]] = results_df[r].sum(axis=1)
  results_df[r] = results_df[r].loc[:, [names[r]]]

da_results = pd.concat(results_df).fillna(value=0)
da_results = da_results.groupby(by=da_results.index, axis=0).sum()
#da_results = da_results.rename(index=tax_rename)
da_results = da_results[da_results.max(axis=1) >= 2]
da_results['Names'] = [tax_rename[d] for d in da_results.index.values]
da_results = da_results.sort_values(by=['Names'], ascending=False)
da_results = da_results.drop('Names', axis=1)

all_results = list(results_df_for_next[:3])

fig = plt.figure(figsize=(15,7))
da_ax = plt.subplot2grid((20,35), (0,0), rowspan=20, colspan=5)

da_hm = da_ax.pcolor(da_results, edgecolor='k', cmap='Blues', vmin=0, vmax=4)
plt.sca(da_ax)
yt = plt.yticks([a+0.5 for a in range(len(da_results.index.values))], [tax_rename[a] for a in da_results.index.values])
xt = plt.xticks([0.5, 1.5, 2.5], ['IBD', 'Crohns', 'UC'], fontweight='bold', rotation=90)
#ti = plt.title('Differential\nabundance', fontweight='bold')
tx = plt.text(0.5, 1.17, 'Differential\nabundance', fontweight='bold', transform=da_ax.transAxes, ha='center', va='center')
tt = da_ax.xaxis.tick_top()

markers = ['o', '>', '<', 's', 'P']
tests = ['aldex', 'ancombc2', 'ancombc', 'maaslin2', 'radEMU']
locs = [0.1, 0.3, 0.5, 0.7, 0.9]
test_names = ['ALDEx2', 'ANCOM-BC2', 'ANCOM-BC', 'MaAsLin2', 'radEmu']
for a in range(len(all_results)):
  all_results[a] = 1-all_results[a]
  all_results[a] = all_results[a].loc[da_results.index.values, :]
  for r in range(len(all_results[a].index.values)):
    for c in range(len(all_results[a].columns)):
      if all_results[a].iloc[r, c] in [1, 1.0, '1']:
        if sum(all_results[a].iloc[r, :].values) > 2: mc = 'w'
        else: mc = 'k'
        sc = da_ax.scatter(a+locs[c], r+0.5, marker=markers[c], color=mc, s=10)
        
handles = [Line2D([0], [0], marker=markers[h], color='w', label=test_names[h], markerfacecolor='k', markersize=8) for h in range(len(test_names))]
handles += [Line2D([0], [0], marker='s', color='w', label=name.replace('IBD Controls', 'Controls').replace('IBD Cases', 'Cases'), markerfacecolor=color_dict[name], markersize=8) for name in ['IBD Cases', 'IBD Controls']]
empty_marker = Line2D([0], [0], marker='s', color='w', label='', markerfacecolor='w', markeredgecolor='w', markersize=2)
handles.append(empty_marker), handles.append(empty_marker), handles.append(empty_marker)

da_ax.legend(handles=handles, loc='upper right', bbox_to_anchor=(-0.2,1.2), ncols=2, fontsize=8)

sr, sc = 0, 7
subplots = [[sr, sc], [sr+12, sc], [sr, sc+5], [sr+12, sc+5], [sr, sc+10], [sr+12, sc+10], [sr, sc+15], [sr+12, sc+15], [sr, sc+20], [sr+12, sc+20], [sr, sc+25], [sr+12, sc+25]]
on = ['CASE_CONTROL', 'Crohn_case_control', 'UC_case_control']

da_results = da_results.iloc[::-1]
count = 0      
for r in range(len(da_results.index.values)):
  for c in range(len(da_results.columns)):
    if da_results.iloc[r, c] >= 2:
      ax = plt.subplot2grid((20,35), (subplots[count][0], subplots[count][1]), rowspan=8, colspan=3)
      if count < 2: yl = ax.set_ylabel('rCLR abundance', fontsize=8)
      count += 1
      name = tax_rename[da_results.index.values[r]]+'\n'
      name += da_results.columns[c]+' $vs$ controls'
      ti = ax.set_title(name, fontweight='bold', fontsize=8)
      cases = md[md[on[c]] == 1].index.values
      controls = md[md[on[c]] == 0].index.values
      ft_ra_red = ft_ra.copy(deep=True)
      vals_cases = ft_ra_red.loc[da_results.index.values[r], cases].values
      vals_controls = ft_ra_red.loc[da_results.index.values[r], controls].values
      sc = ax.scatter(np.random.normal(0, scale=0.1, size=len(vals_cases)), vals_cases, marker='o', color=color_dict['IBD Cases'], alpha=0.5, s=20)
      sc = ax.scatter(np.random.normal(1, scale=0.1, size=len(vals_controls)), vals_controls, marker='o', color=color_dict['IBD Controls'], alpha=0.5, s=20)
      box = ax.boxplot([vals_cases, vals_controls], positions=[0, 1], widths=0.6, showfliers=False)
      for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: bi = plt.setp(box[item], color='k')
      xt = plt.xticks([0, 1], ['Cases', 'Controls'], rotation=90, fontsize=8)
      

plt.savefig(analysis_folder+'figures/differential_abundance_with_abundance_of_significant_rclr.png', dpi=600, bbox_inches='tight')

```

## Look at medication data alpha diversity

Combine with other metadata:
```{python}
md = pd.read_csv(analysis_folder+'files/metadata_crohns_UC.csv', index_col=0, header=0)
med_df = pd.read_csv('/Users/robynwright/Dropbox/Langille_Lab_postdoc/AtPATH_IBD/IBD_medication_data_level2_plus_prospective.csv', index_col=1, header=0)

med_cols = ['ATC1_level2', 'ATC2_level2', 'ATC3_level2', 'ATC4_level2', 'ATC5_level2', 'ATC6_level2', 'ATC7_level2', 'ATC8_level2', 'ATC9_level2', 'ATC10_level2', 'ATC11_level2', 'ATC12_level2', 'ATC13_level2', 'ATC14_level2', 'ATC15_level2']

all_meds = []
for sample in med_df.index.values:
  for col in med_cols:
    all_meds.append(med_df.loc[sample, col])
    

all_meds = list(pd.Series(list(set(all_meds))).dropna())

for med in all_meds:
  md[med] = 'No'

for sample in md.index.values:
  if sample not in med_df.index.values:
    md.loc[sample, all_meds] = 'NA'
    print(sample)
  else:
    try:
      meds_taking = med_df.loc[sample, med_cols].values
      for med in meds_taking:
        if isinstance(med, str):
          md.loc[sample, med] = 'Yes'
        elif not math.isnan(med):
          md.loc[sample, med] = 'Yes'
    except:
      print(med_df.loc[sample, :])

md.to_csv(analysis_folder+'files/metadata_crohns_UC_meds_level2.csv')
    
```

Test stats:
```{python}
md = pd.read_csv(analysis_folder+'files/metadata_crohns_UC_meds_level2.csv', index_col=0, header=0)
alp_div = pd.read_csv(analysis_folder+'diversity/alpha_diversity_asv.csv', index_col=0, header=0)

meds_of_interest = ['A07', 'A02', 'N06', 'C09', 'C10', 'R03']
md = md[md['CASE_CONTROL'] == 1]

all_stats = []

for med in meds_of_interest:
  md_red = md.dropna(axis=0, subset=med)
  for metric in alp_div.columns:
    new_alpha = alp_div.loc[md_red.index.values, [metric]]
    new_alpha[med] = md_red[med]
    model = ols(metric+' ~ '+med, data=new_alpha).fit()
    result = sm.stats.anova_lm(model, typ=2)
    num_yes = md_red[md_red[med] == 'Yes'].shape[0]
    this_stat = [med+' (n='+str(num_yes)+')', metric, result.loc[med, 'F'], result.loc[med, 'PR(>F)']]
    all_stats.append(this_stat)
    
all_stats = pd.DataFrame(all_stats, columns=['Medication (Level 2)', 'Alpha diversity metric', 'F', 'p']).set_index('Medication (Level 2)')
all_stats.to_csv(analysis_folder+'stats/alpha_diversity_medication.csv')
```

Calculate number of people taking drugs:
```{python}
md = pd.read_csv(analysis_folder+'files/metadata_crohns_UC_meds_level2.csv', index_col=0, header=0)

md_cases = md[md['CASE_CONTROL'] == 1]
md_controls = md[md['CASE_CONTROL'] == 0]

all_meds = sorted(all_meds)

all_numbers = []

md_c = [md_controls, md_cases]
md_name = ['Controls', 'Cases']

for m in range(len(md_c)):
  for med in all_meds:
    this_med = list(md_c[m].loc[:, med].values)
    if m == 1:
      all_numbers.append(['IBD', med, this_med.count('Yes'), (this_med.count('Yes')/160)*100])
    else:
      all_numbers.append(['Controls', med, this_med.count('Yes'), (this_med.count('Yes')/160)*100])
  
all_numbers = pd.DataFrame(all_numbers, columns=['Group', 'Medication', 'n', '%']).set_index('Group')
all_numbers.to_csv(analysis_folder+'files/medication_level2_counts.csv')
  
```

Get files Python:
```{python}
md = pd.read_csv(analysis_folder+'files/metadata_crohns_UC_meds_level2.csv', index_col=0, header=0)
dm = pd.read_csv(analysis_folder+'diversity/phylo_pca_asv.csv', index_col=0, header=0)

md = md[md['CASE_CONTROL'] == 1]
dm = dm.loc[md.index.values, md.index.values]
```

```{R}
md = py$md
dm = py$dm

permanova = adonis2(dm ~ md$A07, data=dm, parallel=4, by="terms", permutations=999)
print(permanova)
permanova = adonis2(dm ~ md$A02, data=dm, parallel=4, by="terms", permutations=999)
print(permanova)
permanova = adonis2(dm ~ md$N06, data=dm, parallel=4, by="terms", permutations=999)
print(permanova)
permanova = adonis2(dm ~ md$C09, data=dm, parallel=4, by="terms", permutations=999)
print(permanova)
permanova = adonis2(dm ~ md$C10, data=dm, parallel=4, by="terms", permutations=999)
print(permanova)
```